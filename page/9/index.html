<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  
  
  <title>心咖</title>
  
  <meta name="author" content="dreamin" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="" />
  
  <meta name="description" content="生于尘埃，溺于人海，死于理想的高台">
<meta property="og:type" content="website">
<meta property="og:title" content="心咖">
<meta property="og:url" content="https://xinka.vercel.app/page/9/index.html">
<meta property="og:site_name" content="心咖">
<meta property="og:description" content="生于尘埃，溺于人海，死于理想的高台">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="dreamin">
<meta name="twitter:card" content="summary">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" media="all"></script>
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-color-dark.min.css" media="(prefers-color-scheme: dark)"></script>
    <script src="/js/kr-dark.min.js"></script>
  
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/night-eighties.min.css" media="all"></script>
  
  <link rel="stylesheet" id="fontawe-css" href="/vendors/font-awesome@4.7.0/css/font-awesome.min.css" media="all"></script>
  <link rel="stylesheet" id="nprogress-css" href="/vendors/nprogress@0.2.0/nprogress.css" media="all"></script>
  
  
    <link rel="stylesheet" href="/vendors/aplayer@1.10.1/dist/APlayer.min.css"></script>
  
  
    <link rel="stylesheet" href="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"></script>
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="/vendors/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="/vendors/qrcode_js@1.0.0/qrcode.min.js"></script>
  
  
  <style>
    
    
  </style>
  
<meta name="generator" content="Hexo 7.2.0"></head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">心咖</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>心咖</h2> <br />
                        <span>人生如此，方趁我心</span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        

            <section class="col-md-8">

        

            <!-- Breadcrumb for tag & category page -->




    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>![[Pasted image 20240303155734.png]]</p>
<p>ChatGPT基于循环神经网络（RNN）和注意力机制的模型架构。它是一个生成式模型，可以根据之前的聊天信息生成响应。</p>
<p>模型的原理如下：</p>
<ol>
<li><p>输入编码：在每个对话轮次中，聊天历史被编码为一个输入向量序列。这些向量可以是词向量、字符向量或其他表示形式，根据具体的实现方式而定。</p>
</li>
<li><p>上下文理解：模型使用编码后的输入向量序列，通过循环神经网络（如长短期记忆网络，LSTM）或变种（如GPT-3中的Transformer网络）来理解上下文。这些模型会捕捉到前面对话中的语义和语法结构，并对其进行建模。</p>
</li>
<li><p>注意力机制：模型使用注意力机制来关注历史上下文中与当前生成响应相关的部分。通过对不同部分的注意力分配权重，模型可以更好地理解和应答对话。</p>
</li>
<li><p>响应生成：模型将上下文理解与当前对话的目标进行合并，然后通过解码器生成响应。解码器会根据上下文和已生成内容预测下一个最有可能的词或子序列。</p>
</li>
<li><p>迭代训练：模型通过最大似然估计（MLE）或其他适当的训练目标进行训练，以使生成的响应与训练数据中的目标响应尽可能一致。</p>
</li>
<li><p>上下文维护：模型会维护一个有限的上下文窗口，以限制对话历史的长度。这有助于控制模型的记忆和计算需求，并防止信息过载。</p>
</li>
</ol>
<p>在每个对话轮次中，聊天历史被编码为一个输入向量序列。这些向量可以是词向量、字符向量或其他表示形式，根据具体的实现方式而定。模型使用编码后的输入向量序列，通过循环神经网络（如长短期记忆网络，LSTM）或变种（如GPT-3中的Transformer网络）来理解上下文，这些模型会捕捉到前面对话中的语义和语法结构，并对其进行建模。模型将上下文理解与当前对话的目标进行合并，然后通过解码器生成响应。模型会维护一个有限的上下文窗口，以限制对话历史的长度。这有助于控制模型的记忆和计算需求，并防止信息过载。</p>
<p>这里 memory 模块 保持一个聊天记录的列表，作为历史记录的缓冲区，并且每次都将这些消息与问题一起传递给聊天机器人。</p>
<p>在每个对话轮次中，ChatGPT通过将聊天历史编码为一个输入向量序列来处理上下文信息。这些向量可以采用词向量、字符向量或其他形式的表示，具体取决于实现的方式。</p>
<p>然后，通过使用神经网络（如GPT-3中的Transformer网络），模型能够全面理解上下文，并捕捉前面对话中的语义和语法结构。这样，模型可以建立起对对话历史的深入理解。</p>
<p>模型将上下文理解与当前对话目标相结合，然后通过解码器生成响应。解码器利用上下文信息和已经生成的内容来预测下一个最可能的词或子序列，从而生成连贯的回复。</p>
<p>为了控制模型的记忆和计算需求，并避免信息过载，ChatGPT维护一个有限的上下文窗口，限制对话历史的长度。这种方式确保模型在适应多轮对话时能够保持高效性，并生成准确、有逻辑的回应。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.525Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/RAG%20%E9%A1%B9%E7%9B%AE/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>Mixture  of Experts<br><a target="_blank" rel="noopener" href="https://baoyu.io/translations/llm/mixture-of-experts-explained">https://baoyu.io/translations/llm/mixture-of-experts-explained</a><br><a target="_blank" rel="noopener" href="https://www.aixinzhijie.com/article/6825966">https://www.aixinzhijie.com/article/6825966</a><br>深入理解混合专家模型</p>
<ol>
<li>相较于密集型模型，预训练速度更快</li>
<li>拥有比同等参数更快的推理速度</li>
<li>对显存要求高，因为需要将所有的专家模型都加载到内存中。</li>
<li>虽然在微调方面存在挑战，有光明前景<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.14705.pdf">https://arxiv.org/pdf/2305.14705.pdf</a></li>
</ol>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>在有限的计算资源下，相较于用更多步骤训练一个小型模型，训练一个大型模型即便步骤更少效果通常更好。<br>MoEs 让模型以远低于传统密集模型的计算成本进行预训练，这意味着你可以在相同的计算预算下显著扩大模型或数据集的规模。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h3><ol>
<li>稀疏 MoE 层：代替了传统的密集型前馈网络（FFN）层。包含若干“专家”，每个专家都是一个独立的神经网络。实际上，这些专家通常是FFN，但它们也可以是更复杂的网络，，甚至可以是 MoE 本身，形成一个层级结构的 MoE。</li>
<li>一个门控网络或路由器：用于决定那些 Token 分配给哪个专家。例如，在下图中，“More”这个 Token 被分配给第二个专家![[Pasted image 20240310201128.png]]<ol>
<li>一个 token 可以分配给多个专家，如何高效的将 Token 分配给合适的专家，是使用 MoE 技术时需要考虑的关键问题之一。</li>
<li>这个路由器由一系列可学习的参数构成。它与模型的其他部分一起进行训练。<br>总结：在 Transformer 中，我们将每一个 FFN（前馈网络）层替换为 MoE 层，由一个门控层和若干”专家“组成。</li>
</ol>
</li>
</ol>
<h1 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h1><ol>
<li>训练：在预训练阶段的计算效率极高，但在微调时往往难以适应新场景，容易造成过拟合现象。</li>
<li>推理：尽管 MoE 模型可能包含大量参数，但是在推理过程中只有部分参数被使用，（所以它的推理速度远快于参数相同的模型）但是所有参数都需加载到内存中，因此对内存的需求相当大。</li>
</ol>
<h1 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h1><ol>
<li>1991 提出</li>
<li>2010~2015 两个不同的领域推动了 MoE 发展<ol>
<li>专家作为主键</li>
<li>条件计算</li>
</ol>
</li>
<li>引入稀疏性概念在 NLP 领域 快速发展（本文重点），在计算机视觉等也有探索。</li>
</ol>
<h2 id="稀疏性"><a href="#稀疏性" class="headerlink" title="稀疏性"></a>稀疏性</h2><p>稀疏性基于条件计算的概念，不同于密集型模型中所有参数对所有输入都有效，稀疏性让我们能只激活系统的部分区域。</p>
<blockquote>
<p>条件计算（即网络的某些部分仅针对特定样本激活）的概念使得在不增加计算量的情况下扩大模型规模成为可能，从而在每层 MoE 中使用了数千名专家。<br>(密集型模型 + 稀疏性 &#x3D;&#x3D;&gt; 稀疏模型)</p>
</blockquote>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>在 MoE 中，当数据通过活跃的专家时，实际的批量大小会减小。例如，如果我们的批量输入包含 10 个 Token，<strong>可能有五个 Token 由一个专家处理，另外五个 Token 分别由五个不同的专家处理，这导致批量大小不均匀，资源利用率低下</strong>。下文中的 <a target="_blank" rel="noopener" href="https://baoyu.io/translations/llm/mixture-of-experts-explained#making-moes-go-brrr">优化 MoE 性能</a> 一节将讨论更多挑战及其解决方案。</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>那我们该如何解决这些问题呢？通过一个学习型的门控网络 (G)，决定将输入的哪些部分分配给哪些专家 (E)：</p>
<p>在这种设置中，所有专家都参与处理所有输入——这是一种加权乘法过程。但如果 G 的值为 0 呢？这种情况下，就无需计算相应专家的操作，从而节约了计算资源。那么，典型的门控函数是什么样的呢？在传统设置中，我们通常使用一个简单的网络配合 softmax 函数。这个网络会学习如何选择最合适的专家处理输入。</p>
<p>为了让门控学习如何路由到不同的专家，需要路由到一个以上的专家，因此至少需要选择两个专家。<a target="_blank" rel="noopener" href="https://baoyu.io/translations/llm/mixture-of-experts-explained#switch-transformers">Switch Transformers</a> 章节将重新审视这一决策。</p>
<p>我们为什么要加入噪声？这是为了实现负载均衡！</p>
<h2 id="为多专家系统-MoEs-负载均衡-tokens"><a href="#为多专家系统-MoEs-负载均衡-tokens" class="headerlink" title="为多专家系统 MoEs 负载均衡 tokens"></a>为多专家系统 MoEs 负载均衡 tokens</h2><p>如果所有的 tokens 都被发送到少数几个受欢迎的专家，这将导致训练效率低下。在标准的多专家系统训练中，门控网络倾向于主要激活相同的几位专家。这会形成自我加强的循环，因为得到优先训练的专家会被更频繁地选择。为了减轻这种情况，引入了一种<strong>辅助损失</strong>来鼓励平等对待所有专家。这种损失确保所有专家获得大致相同数量的训练样本。后续章节还将探讨“专家容量”的概念，这涉及到一个专家能处理的 tokens 数量上限。在 <code>transformers</code> 中，这种辅助损失可以通过 <code>aux_loss</code> 参数来调节。</p>
<h2 id="MoEs-和-Transformers"><a href="#MoEs-和-Transformers" class="headerlink" title="MoEs 和 Transformers"></a>MoEs 和 Transformers</h2><p>Transformers 模型展示了一个明显的趋势：增加参数的数量可以显著提高性能。Google 的 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.16668">GShard</a> 项目正是在这方面进行了深入探索，试图将 Transformers 模型扩展到超过 6000 亿个参数。</p>
<h2 id="专家在学习中角色和专长"><a href="#专家在学习中角色和专长" class="headerlink" title="专家在学习中角色和专长"></a>专家在学习中角色和专长</h2><p>解码器的专家倾向于特定的 Token 组或基础概念。例如可能形成专门处理标点符号或转悠名词的专家，而解码器的专家则在专业化方面表现的较为平均。</p>
<h2 id="增加专家数量对预训练的影响"><a href="#增加专家数量对预训练的影响" class="headerlink" title="增加专家数量对预训练的影响"></a>增加专家数量对预训练的影响</h2><p>增加更多的专家可以提高样本效率和加速训练过程，但增益逐渐减少（特别是在达到 256 或 512 个专家后），并且在推理过程中需要更多的 VRAM。在大规模应用中研究的 Switch Transformers 的特性，在小规模应用中也得到了验证，即便是每层只有 2、4 或 8 个专家</p>
<h2 id="微调-MoE-技术"><a href="#微调-MoE-技术" class="headerlink" title="微调 MoE 技术"></a>微调 MoE 技术</h2><p>Mixtral 软件已经在 transformers 4.36.0 版本中得到支持，您可以通过运行 <code>pip install &quot;transformers==4.36.0 --upgrade&quot;</code> 命令进行安装。<br>密集型模型和稀疏型模型在过拟合上表现出明显不同的特点。稀疏型模型更易于过拟合，因此我们可以尝试在专家系统内部应用更强的正则化手段，例如不同层次的 dropout 率——对密集层和稀疏层分别设置不同的 dropout 率。</p>
<p>在微调过程中，一个关键的决策是是否采用辅助损失。ST-MoE 的研究人员尝试关闭辅助损失，并发现即使高达 11% 的 Token 被丢弃，模型的质量也几乎不受影响。这表明 Token 丢弃可能是一种有效的防止过拟合的正则化策略。</p>
<p>另一个尝试是冻结所有非专家层的权重，结果如预期那样导致了性能大幅下降，因为 MoE 层占据了网络的大部分。相反，仅冻结 MoE 层的参数几乎能达到更新所有参数的效果。这种方法可以加速微调过程，同时减少内存使用。<br>通过仅冻结 MoE 层，我们不仅能加快训练速度，还能保持模型的质量。这些发现同样源于 ST-MoE 的研究论文。 </p>
<h2 id="何时选择稀疏-MoEs-和稠密模型？"><a href="#何时选择稀疏-MoEs-和稠密模型？" class="headerlink" title="何时选择稀疏 MoEs 和稠密模型？"></a>何时选择稀疏 MoEs 和稠密模型？</h2><p>在多机器、高吞吐量的场景中，专家系统是非常有效的。如果预训练的计算预算有限，那么稀疏模型将是更佳的选择。对于 VRAM 较少、吞吐量低的情况，稠密模型则更为合适。</p>
<p><strong>注意：</strong> 我们不能直接比较稀疏和稠密模型之间的参数数量，因为这两种模型代表的是完全不同的概念。</p>
<ol>
<li>稀疏模型：<ul>
<li>定义：稀疏模型是一种模型设计策略，其中模型结构被设计为具有少量的参数或专家（Experts），每个专家对应于模型中的一个子模型。</li>
<li>特点：<ul>
<li>模型结构简单，仅包含少量的专家。s</li>
<li>每个专家专注于处理特定的输入模式或任务。</li>
<li>专家之间在参数空间上是相互独立的。</li>
<li>在推理阶段，只有少量的专家被激活并参与预测，以提高计算效率。</li>
</ul>
</li>
<li>优点：<ul>
<li>可以处理复杂的输入模式，并对不同的任务进行专门化处理。</li>
<li>可以节省模型的参数量和计算资源。</li>
</ul>
</li>
<li>缺点：<ul>
<li>需要设计合适的选择机制和激活策略，以确保在不同输入情况下激活合适的专家。</li>
<li>对于一些特定的输入模式，可能需要较大的专家数量才能达到较好的性能。</li>
</ul>
</li>
</ul>
</li>
<li>稠密模型：<ul>
<li>定义：稠密模型是一种模型设计策略，其中模型结构被设计为具有更多的参数和层级，以便能够更全面地学习输入数据的特征和表示。</li>
<li>特点：<ul>
<li>模型结构相对更复杂，包含多个参数较多的层。</li>
<li>在训练过程中，模型可以通过反向传播算法端到端地学习输入数据的特征。</li>
<li>通常用于处理输入模式和任务较为均衡的情况。</li>
</ul>
</li>
<li>优点：<ul>
<li>可以捕获输入数据中更丰富的特征，并具有更强的表达能力。</li>
<li>可以适应不同的输入模式和任务，并在训练过程中自动学习特征的权重和表示。</li>
</ul>
</li>
<li>缺点：<ul>
<li>参数较多，需要更多的计算资源和内存空间。</li>
<li>在处理特定输入模式和任务时，可能存在过拟合的风险。</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>![[Pasted image 20240311104630.png]]</p>
<h1 id="最新进展"><a href="#最新进展" class="headerlink" title="最新进展"></a>最新进展</h1><ul>
<li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1701.06538">The Sparsely-Gated Mixture-of-Experts Layer (2017)</a><br>  <a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1701.06538">稀疏门控专家混合层（2017）</a></li>
<li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2006.16668">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding (2020)</a><br>  <a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2006.16668">GShard：通过条件计算和自动分片扩展巨型模型（2020）</a></li>
<li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2211.15841">MegaBlocks: Efficient Sparse Training with Mixture-of-Experts (2022)</a><br>  <a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2211.15841">MegaBlocks：高效稀疏训练与专家混合（2022）</a></li>
<li><a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2305.14705">Mixture-of-Experts Meets Instruction Tuning (2023)</a><br>  <a href="https://link.zhihu.com/?target=https://arxiv.org/abs/2305.14705">混合专家遇见指令调整（2023）</a></li>
</ul>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/674162664">万字长文详解 MoE - 超越ChatGPT的开源混合专家模型 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8">1. Diederik P. Kingma, Jimmy Ba. “Adam: A Method for Stochastic Optimization.” International Conference on Learning Representations(2014).</a> </p>
<p><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776">2. Ashish Vaswani, Noam M. Shazeer et al. “Attention is All you Need.” Neural Information Processing Systems(2017).</a> </p>
<p><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/97fb4e3d45bb098e27e0071448b6152217bd35a5">3. Jimmy Ba, J. Kiros et al. “Layer Normalization.” arXiv.org(2016).</a> </p>
<p><a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2308.14352">4. Rongjie Yi, Liwei Guo et al. “EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models.” arXiv.org (2023).</a> </p>
<p><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/23894a64bcd7db9007c90fd201264d113e67b6a7">5. Alexander Hauptmann. “From Syntax to Meaning in Natural Language Processing.” AAAI Conference on Artificial Intelligence (1991).</a> </p>
<p><a target="_blank" rel="noopener" href="https://doi.org/10.1145/3539597.3572720">6. Chenguang Zhu, Yichong Xu et al. “Knowledge-Augmented Methods for Natural Language Processing.” Annual Meeting of the Association for Computational Linguistics (2023).</a> </p>
<p><a target="_blank" rel="noopener" href="https://doi.org/10.48161/QAJ.V1N2A44">7. Dastan Hussen Maulud, Subhi R. M. Zeebaree et al. “State of Art for Semantic Analysis of Natural Language Processing.” Qubahan Academic Journal (2021).</a> </p>
<p><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/a1730ffaf9701f9bc66962fe3823f4c4404bccdd">8. Neha Yadav. “Applications Associated With Morphological Analysis And Generation In Natural Language Processing.” (2017). 284-286.</a></p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.524Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/MoEs/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>生物老师:<br>我想让你扮演一名生物老师。我将提供一些问题或概念，你的工作是用易于理解的术语来解释它们。这可能包括提供解决问题的分步说明、用视觉演示各种技术或建议在线资源以供进一步研究。</p>
<p>马屁精：<br>现在请你扮演一位马屁精，不管我说的内容有多么荒谬，你都能恰如其分的拍我的马屁</p>
<p>文学老师:<br>我想让你扮演一名大学文学老师。我将提供一些问题或概念，你的工作是精准回答我的问题，用易于理解的专业术语来解释它们。这可能包括提供解决问题的依据、纠正我的错误以及给出示例的等。</p>
<p>内容: 使用 GPT-4, 设计 Prompt 优化 <strong>图说数据库系统</strong> 的文本内容.</p>
<ul>
<li><p><strong>基本要求:</strong></p>
<ul>
<li><p>优化自己负责部分的一个小节, 丰富内容, 优化章节结构, 语言风格等.</p>
</li>
<li><p>采用将大问题分解为多个小问题的方式进行优化, 使用多个 Prompt 对比生成的结果. 最后, 对比丰富后与丰富前的文本. (保留优化前的文本)</p>
</li>
</ul>
</li>
</ul>
<p>提升文章的独特性：<br>Rewrite the existing document tomake it more imaginative, engaging, and unique.</p>
<p>将文档转为引|人入胜的故事：<br>Transform the existingdocument into a compelling story that highlights thechallenges faced and the solutions provided.</p>
<p>提升文档说服力：<br>Refine the existing document byincorporating persuasive language and techniques tomake it more convincing and impactful.</p>
<p>提升文档的吸引力：<br>Add emotional language and sensorydetails to the existing document to make it morerelatable and engaging.</p>
<p>使内容更加简洁：<br>Refine the existing document byremoving unnecessaryinformation and making it moreconcise and to-the-point.</p>
<p>强调急迫感：<br>Refine the existing document by adding asense of urgency and emphasizing the need forimmediate action.</p>
<p>突出重点：<br>Emphasize important information using boldor italic text.</p>
<p>让模型使用类比或比喻的方法解释复杂问题：<br>Explain complexideas using analogies or comparisons.</p>
<p>添加现实中的例子：<br>Include case studies or real-worldexamples to make concepts more relatable.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ChatGPT，我正在编辑一本名为《图说数据库》的专业书籍。我希望你能帮助我优化这本书中部分文本的内容和结构。以下是一些我需要你考虑的方面：</span><br><span class="line"></span><br><span class="line">1. 内容丰富：我希望你能根据我提供文字，结合文字的中心内容，把握住数据库的深入主题，进一步丰富专业表述，能够为读者提供更深入的理解和实践经验。</span><br><span class="line"></span><br><span class="line">2. 章节结构：我希望你能帮助我设计一个清晰、连贯的章节结构，这个结构应该能够帮助读者更好地理解和学习数据库的各个方面。</span><br><span class="line"></span><br><span class="line">3. 语言风格：我希望你能改进语言风格的建议，使得其中的内容既能够清晰地传达技术信息，又能够吸引和保持读者的兴趣。</span><br><span class="line"></span><br><span class="line">请你根据以上的要求，修改我之后给你发送的章节部分。</span><br></pre></td></tr></table></figure>

<p>我想让你担任心理健康顾问。我将为您提供一个寻求指导和建议的人，以管理他们的情绪、压力、焦虑和其他心理健康问题。您应该利用您的认知行为疗法、冥想技巧、正念练习和其他治疗方法的知识来制定个人可以实施的策略，以改善他们的整体健康状况。我的第一个请求是“我需要一个可以帮助我控制抑郁症状的人。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.524Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/Prompt/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="个人环境搭建"><a href="#个人环境搭建" class="headerlink" title="个人环境搭建"></a>个人环境搭建</h1><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="openai"><a href="#openai" class="headerlink" title="openai"></a>openai</h3><p><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/api-reference/chat-completions/create">api 使用文档</a></p>
<h2 id="wenxin"><a href="#wenxin" class="headerlink" title="wenxin"></a>wenxin</h2><p>[[微信项目]]<br>教程：<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_30299877/article/details/131917097">如何申请文心一言&amp;文心千帆大模型API调用资格、获取access_token，并使用SpringBoot接入文心一言API_文心一言api申请-CSDN博客</a></p>
<p>在线调试工具<br><a target="_blank" rel="noopener" href="https://console.bce.baidu.com/tools/#/api?product=AI&project=%E6%96%87%E5%BF%83%E5%8D%83%E5%B8%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B9%B3%E5%8F%B0&parent=%E9%89%B4%E6%9D%83%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6&api=oauth%2F2.0%2Ftoken&method=post">https://console.bce.baidu.com/tools/#/api?product=AI&amp;project=%E6%96%87%E5%BF%83%E5%8D%83%E5%B8%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%B9%B3%E5%8F%B0&amp;parent=%E9%89%B4%E6%9D%83%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6&amp;api=oauth%2F2.0%2Ftoken&amp;method=post</a></p>
<p>token<br>24.0339bde53ae4eed0ed979b9f9959b20e.2592000.1711684739.282335-53912329<br>申请：<a target="_blank" rel="noopener" href="https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application/create">https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application/create</a><br>[api 文档](<a target="_blank" rel="noopener" href="https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Rlkkt6kd7">使用网页调试工具获取access_token - 千帆大模型平台 | 百度智能云文档 (baidu.com)</a>)</p>
<h2 id="github-Copilot-免费使用-gpt-4"><a href="#github-Copilot-免费使用-gpt-4" class="headerlink" title="github Copilot 免费使用 gpt-4"></a>github Copilot 免费使用 gpt-4</h2><p><a target="_blank" rel="noopener" href="https://blog.geniucker.top/2024/01/26/%E9%80%9A%E8%BF%87-GitHub-Copilot-%E5%85%8D%E8%B4%B9%E4%BD%BF%E7%94%A8-gpt-4/">https://blog.geniucker.top/2024/01/26/%E9%80%9A%E8%BF%87-GitHub-Copilot-%E5%85%8D%E8%B4%B9%E4%BD%BF%E7%94%A8-gpt-4/</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/Geniucker/CoGPT?tab=readme-ov-file">https://github.com/Geniucker/CoGPT?tab=readme-ov-file</a></p>
<p>我希望你充当激励教练。我将为您提供一些关于某人的目标和挑战的信息，而您的工作就是想出可以帮助此人实现目标的策略。这可能涉及提供积极的肯定、提供有用的建议或建议他们可以采取哪些行动来实现最终目标。我的第一个请求是“我需要帮助来激励自己在为即将到来的考试学习时保持纪律”。</p>
<h1 id="常用的大模型应用技术"><a href="#常用的大模型应用技术" class="headerlink" title="常用的大模型应用技术"></a>常用的大模型应用技术</h1><h2 id="Prompt"><a href="#Prompt" class="headerlink" title="Prompt"></a>Prompt</h2><p>[[Prompt]]</p>
<h3 id="Course"><a href="#Course" class="headerlink" title="Course"></a>Course</h3><ul>
<li><p><strong><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/prompt-engineering">OpenAI Prompt 指南</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/courses/chatgpt-prompt-eng/lesson/1/introduction">ChatGPT Prompt Engineering for Developers</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1e8411o7NP?p=1&vd_source=31f1c950b5b95af0c48f188f0bc047c7">ChatGPT Prompt Engineering for Developers - 中文字幕版</a></strong></p>
</li>
</ul>
<h3 id="Project"><a href="#Project" class="headerlink" title="Project"></a>Project</h3><ul>
<li><p>内容: 使用 GPT-4, 设计 Prompt 优化 <strong>图说数据库系统</strong> 的文本内容.</p>
</li>
<li><p><strong>基本要求:</strong></p>
<ul>
<li><p>优化自己负责部分的一个小节, 丰富内容, 优化章节结构, 语言风格等.</p>
</li>
<li><p>采用将大问题分解为多个小问题的方式进行优化, 使用多个 Prompt 对比生成的结果. 最后, 对比丰富后与丰富前的文本. (保留优化前的文本)</p>
</li>
</ul>
</li>
<li><p>进阶:</p>
<ul>
<li><p>其他任意 Prompt 工作都可.</p>
</li>
<li><p>例如: 优化翻译结果, 优化特定领域结果(数据库专家, 文档编写专家等)</p>
</li>
</ul>
</li>
<li><p>实验室提供的 GPT-4 Web <a target="_blank" rel="noopener" href="https://chatgpt-next-web-mauve-five.vercel.app/#/chat">https://chatgpt-next-web-mauve-five.vercel.app/#/chat</a></p>
</li>
</ul>
<h3 id="其他资料"><a href="#其他资料" class="headerlink" title="其他资料"></a>其他资料</h3><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/linexjlin/GPTs">GPTs 的 Prompt, 可用于参考</a></li>
</ul>
<h2 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a>RAG</h2><p>[[RAG 检索增强]]</p>
<h3 id="Course-1"><a href="#Course-1" class="headerlink" title="Course"></a>Course</h3><ul>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11G411X7nZ?p=15&vd_source=31f1c950b5b95af0c48f188f0bc047c7">Retrieval Augmented Generation (RAG) 简介 - 中文字幕版</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/langchain-chat-with-your-data/lesson/2/document-loading">LangChain Chat with Your Data</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV148411D7d2/?spm_id_from=333.337.search-card.all.click&vd_source=31f1c950b5b95af0c48f188f0bc047c7">LangChain Chat with Your Data - 中文字幕版</a></strong></p>
</li>
</ul>
<h3 id="Project-1"><a href="#Project-1" class="headerlink" title="Project"></a>Project</h3><ul>
<li><p>利用指定的书籍文档, 构建 RAG 系统.</p>
</li>
<li><p>利用 RAG 系统优化 <strong>图说数据库系统</strong> 的文本内容.</p>
</li>
<li><p><strong>基本要求:</strong></p>
<ul>
<li>优化自己部分的一个小节, 丰富内容, 修正错误. 与原文本, Prompt 生成的文本进行对比.</li>
</ul>
</li>
<li><p>进阶:</p>
<ul>
<li>构建其他任意 RAG 系统.</li>
<li>例如: 分布式课程 RAG 系统, 实验室文档 RAG 系统, 医疗 RAG 系统等.</li>
</ul>
</li>
<li><p>实验室提供的 API-Key</p>
</li>
<li><p>可以用于 机器人的 聊天记录进行保存</p>
</li>
</ul>
<h3 id="其他资料-1"><a href="#其他资料-1" class="headerlink" title="其他资料"></a>其他资料</h3><ul>
<li><p><a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/building-evaluating-advanced-rag/lesson/1/introduction">Building and Evaluating Advanced RAG</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/functions-tools-agents-langchain/lesson/1/introduction">Functions, Tools and Agents with LangChain</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://twitter.com/tisoga/status/1731478506465636749?s=61&t=TVU99VOXdlAywAcBa_iuSg">devv.ai 是如何构建高效的 RAG 系统的</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://twitter.com/i/web/status/1737037970367283474">复杂 RAG 的技术考虑</a></p>
</li>
</ul>
<h2 id="MoE"><a href="#MoE" class="headerlink" title="MoE"></a>MoE</h2><p>[[MoEs]]</p>
<h3 id="Course-2"><a href="#Course-2" class="headerlink" title="Course"></a>Course</h3><ul>
<li><a target="_blank" rel="noopener" href="https://baoyu.io/translations/llm/mixture-of-experts-explained">深入理解混合专家模型</a></li>
</ul>
<h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><p>[[Finetuning]]</p>
<h3 id="Course-3"><a href="#Course-3" class="headerlink" title="Course"></a>Course</h3><ul>
<li><a target="_blank" rel="noopener" href="https://learn.deeplearning.ai/finetuning-large-language-models/lesson/1/introduction">Finetuning Large Language Models</a><br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Rz4y1T7wz/?spm_id_from=333.337.search-card.all.click&vd_source=59461060c1867e9bf731e467ae6f00b5">吴恩达《微调大型语言模型》| Finetuning Large Language Models（中英字幕）_哔哩哔哩_bilibili</a></li>
</ul>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.523Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/GAI%20%E7%9A%84%E5%BA%94%E7%94%A8/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11G411X7nZ/?p=2&vd_source=31f1c950b5b95af0c48f188f0bc047c7">https://www.bilibili.com/video/BV11G411X7nZ/?p=2&amp;vd_source=31f1c950b5b95af0c48f188f0bc047c7</a></p>
<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><p>分类：</p>
<ol>
<li>中间任务（序列标注）：中文分词，词性标注，NER，句法分析，指代消解，语义 Parser 等，</li>
<li>最终任务：文本分类，文本相似性计算，机器翻译，文本摘要。<ol>
<li>自然语言理解类任务：本质上是分类任务：分类任务、句子关系判断</li>
<li>自然语言生成类任务</li>
</ol>
</li>
</ol>
<h2 id="NLP-三大特征提取器（CNN-RNN-TF）"><a href="#NLP-三大特征提取器（CNN-RNN-TF）" class="headerlink" title="NLP 三大特征提取器（CNN|RNN|TF）"></a>NLP 三大特征提取器（CNN|RNN|TF）</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/54743941">https://zhuanlan.zhihu.com/p/54743941</a></p>
<ol>
<li><strong>一个特征抽取器是否适配问题领域的特点，有时候决定了它的成败，而很多模型改进的方向，其实就是改造得使得它更匹配领域问题的特性</strong></li>
<li><strong>解决 NLP 任务 最重要的就是 模型的特征提取能力</strong></li>
</ol>
<h3 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h3><ol>
<li>RNN 基本完成它的历史使命。</li>
<li>CNN 如果改造得当，有希望有自己在NLP领域的一席之地。</li>
<li>Transformer 最主流的特征提取器</li>
</ol>
<h3 id="RNN-现状"><a href="#RNN-现状" class="headerlink" title="RNN 现状"></a>RNN 现状</h3><h4 id="RNN-在-NLP-中的演进"><a href="#RNN-在-NLP-中的演进" class="headerlink" title="RNN 在 NLP 中的演进"></a>RNN 在 NLP 中的演进</h4><ol>
<li>RNN 采取线性序列结构不断从前往后输入信息，这种线性结构在反向传播时存在优化困难问题，因为反向传播路径太长，容易导致严重的梯度消失或者梯度爆炸问题。</li>
<li>引入 LSTM 和 GRU 模型，通过增加中间状态信息直接向后转播，以此缓解梯度消失问题，获得很好的效果。</li>
<li>不断优化，从图像领域引入 Attention 机制，叠加网络使得层更深。</li>
<li>引入 Encoder-Decoder 框架。</li>
</ol>
<h4 id="RNN-的优势"><a href="#RNN-的优势" class="headerlink" title="RNN 的优势"></a>RNN 的优势</h4><ol>
<li>RNN 的结构天然适配解决 NLP 问题，NLP 问题的输入往往是一个不定长的线性序列句子。</li>
<li>而 RNN 本身结构 就是一个可以接纳不定长输入的由前向后进行信息线性传导的网络结构</li>
<li>LSTM 引入三个门， 对于捕获长距离特征也是非常有效的</li>
</ol>
<h4 id="RNN-的问题"><a href="#RNN-的问题" class="headerlink" title="RNN 的问题"></a>RNN 的问题</h4><ol>
<li>老模型先天不如新来的 CNN Transformer 。</li>
<li>RNN 本身的序列依赖结构对于大规模并行计算来说相当不友好。而 CNN 和 Transformer 不存在这种问题。<br>本质：<br> 时间步有前后依赖</li>
</ol>
<h4 id="RNN-并行改造"><a href="#RNN-并行改造" class="headerlink" title="RNN 并行改造"></a>RNN 并行改造</h4><ol>
<li>保留连续时间步的隐层连接<ol>
<li>在隐层单元之间并行计算，</li>
</ol>
</li>
<li>部分打断连续时间步<ol>
<li>（这样改进之后有点像简化的 CNN）失去原本样貌</li>
</ol>
</li>
</ol>
<h3 id="CNN-现状"><a href="#CNN-现状" class="headerlink" title="CNN 现状"></a>CNN 现状</h3><h4 id="怀旧版-CNN"><a href="#怀旧版-CNN" class="headerlink" title="怀旧版 CNN"></a>怀旧版 CNN</h4><ol>
<li>输入层</li>
<li>卷积层：特征提取层，卷积核（filter）</li>
<li>pooling 层：对 Filter 的特征进行降维操作（从一个卷积核获得的特征向量里只选中并保留最强的那一个特征）</li>
<li>输出层</li>
</ol>
<h4 id="怀旧版-CNN-的问题"><a href="#怀旧版-CNN-的问题" class="headerlink" title="怀旧版 CNN 的问题"></a>怀旧版 CNN 的问题</h4><ol>
<li>卷积层如何捕获远距离特征<blockquote>
<p>CNN 卷积层捕获的实际上是单词 的 k-gram 片段信息，k 的大小决定了能捕获多远距离的特征</p>
</blockquote>
<ol>
<li>不是覆盖连续区域，在同样的滑动窗口大小的前提下，覆盖不连续区域</li>
<li>增加卷积层层数。</li>
</ol>
</li>
<li>Pooling 层<blockquote>
<p>Pooling的操作逻辑是：从一个卷积核获得的特征向量里只选中并保留最强的那一个特征，所以到了Pooling层，位置信息就被扔掉了，这在NLP里其实是有信息损失的。</p>
</blockquote>
 所以在 NLP 领域里，目前 CNN 的一个发展趋势是抛弃 Pooling 层，靠全卷积层来叠加网络深度</li>
</ol>
<h4 id="怀旧版-CNN-的优势"><a href="#怀旧版-CNN-的优势" class="headerlink" title="怀旧版 CNN 的优势"></a>怀旧版 CNN 的优势</h4><p>并行计算能力：单层卷积层，首先对于某个卷积核来说，每个滑动窗口位置之间没有依赖关系，所以完全可以并行计算；另外，不同的卷积核之间也没什么相互影响，所以也可以并行计算。</p>
<h3 id="Transformer-登场"><a href="#Transformer-登场" class="headerlink" title="Transformer 登场"></a>Transformer 登场</h3><p>[[Transformer]]<br>![[Pasted image 20240302135631.png]]<br>Transformer 模型由编码器（Encoder）和解码器（Decoder）两部分组成，这两部分都采用了多层的自注意力（Self-Attention）和前馈神经网络（Feed-Forward Neural Network）。</p>
<p><strong>编码器（Encoder）</strong>：编码器的主要任务是理解输入的信息，并将其转化为一种内部表示形式。在 Transformer 中，编码器接收一系列输入（比如一个句子中的每个词），并通过自注意力机制和前馈神经网络，将每个输入转化为一个向量。这个向量包含了输入的信息，以及它与其他输入的关系。编码器由多个这样的层堆叠在一起，每一层都会进一步提炼这些向量。</p>
<p><strong>解码器（Decoder）</strong>：解码器的主要任务是根据编码器的输出生成最终的输出。在 Transformer 中，解码器也是由多个自注意力机制和前馈神经网络的层组成。但解码器有两个自注意力层，一个是对自身的输入进行自注意力计算，另一个是对编码器的输出进行自注意力计算。这使得解码器在生成每个输出时，都能考虑到所有的输入和已经生成的输出。</p>
<p><strong>区别和联系</strong>：编码器和解码器的主要区别在于，编码器只需要理解输入，而解码器需要理解输入并生成输出。因此，解码器比编码器多了一个自注意力层，用于理解已经生成的输出。编码器和解码器的联系在于，它们都使用了自注意力机制和前馈神经网络，而且解码器在生成输出时，会使用编码器的输出。</p>
<p>在 GPT 中，只使用了 Transformer 的解码器部分，因为 GPT 的任务是生成文本，不需要理解输入。而在 BERT 中，只使用了 Transformer 的编码器部分，因为 BERT 的任务是理解文本，不需要生成输出。</p>
<blockquote>
<p>目前 Transformer 不仅统一了 NLP 诸多领域，也逐步替换图像处理各种任务被广泛使用的 CNN 等其他模型的进程之中；<br>类似的，多模态模型也目前 基本都采用了 Transformer 模型</p>
</blockquote>
<h4 id="Transformer-问题"><a href="#Transformer-问题" class="headerlink" title="Transformer 问题"></a>Transformer 问题</h4><p>因为输入的第一层网络是Muli-head self attention层，我们知道，Self attention会让当前输入单词和句子中任意单词发生关系，然后集成到一个embedding向量里，但是当所有信息到了embedding后，位置信息并没有被编码进去。</p>
<h4 id="Transformer-如何解决问题"><a href="#Transformer-如何解决问题" class="headerlink" title="Transformer 如何解决问题"></a>Transformer 如何解决问题</h4><ol>
<li>如何解决不定长问题：<br> 类似 CNN 假定输入的最大长度，不够用 padding 补充，</li>
<li>如何解决位置编码问题：<br> 必须要有一个位置编码。<ol>
<li>Transformer 用位置函数来进行编码；</li>
<li>Bert 模型则给每一个单词一个 Position embedding，和 单词 embedding 加起来形成单词的输入；</li>
</ol>
</li>
<li>如何解决长距离依赖问题。<br> elf attention天然就能解决这个问题，因为在集成信息的时候，当前单词和句子中任意单词都发生了联系，所以一步到位就把这个事情做掉了。不像RNN需要通过隐层节点序列往后传，也不像CNN需要通过增加网络深度来捕获远距离特征，Transformer在这点上明显方案是相对简单直观的。</li>
</ol>
<h3 id="三者比较"><a href="#三者比较" class="headerlink" title="三者比较"></a>三者比较</h3><ol>
<li>从语义特征提取能力来说，目前实验支持如下结论：Transformer在这方面的能力非常显著地超过RNN和CNN（在考察语义类能力的任务WSD中，Transformer超过RNN和CNN大约4-8个绝对百分点），RNN和CNN两者能力差不太多。</li>
<li>在长距离特征捕获能力方面，目前在特定的长距离特征捕获能力测试任务中（主语-谓语一致性检测，比如we……..are…），实验支持如下结论：原生CNN特征抽取器在这方面极为显著地弱于RNN和Transformer，Transformer微弱优于RNN模型(尤其在主语谓语距离小于13时)，能力由强到弱排序为Transformer&gt;RNN&gt;&gt;CNN; 但在比较远的距离上（主语谓语距离大于13），RNN微弱优于Transformer，所以综合看，可以认为Transformer和RNN在这方面能力差不太多，而CNN则显著弱于前两者。</li>
<li>从综合特征抽取能力角度衡量，Transformer显著强于RNN和CNN，而RNN和CNN的表现差不太</li>
<li>RNN在并行计算方面有严重缺陷，这是它本身的序列依赖特性导致的，所谓成也萧何败也萧何，它的这个线形序列依赖性非常符合解决NLP任务，这也是为何RNN一引入到NLP就很快流行起来的原因，但是也正是这个线形序列依赖特性，导致它在并行计算方面要想获得质的飞跃，看起来困难重重，近乎是不太可能完成的任务。而对于CNN和Transformer来说，因为它们不存在网络中间状态不同时间步输入的依赖关系，所以可以非常方便及自由地做并行计算改造，这个也好理解。并行计算能力由高到低排序如下：Transformer和CNN差不多，都远远远远强于RNN。</li>
</ol>
<h1 id="待完成！！！！https-zhuanlan-zhihu-com-p-54743941"><a href="#待完成！！！！https-zhuanlan-zhihu-com-p-54743941" class="headerlink" title="待完成！！！！https://zhuanlan.zhihu.com/p/54743941"></a>待完成！！！！<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/54743941">https://zhuanlan.zhihu.com/p/54743941</a></h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/597586623">https://zhuanlan.zhihu.com/p/597586623</a></p>
<h2 id="Bert-GPT-Transformer-区分"><a href="#Bert-GPT-Transformer-区分" class="headerlink" title="Bert|GPT|Transformer 区分"></a>Bert|GPT|Transformer 区分</h2><p>BERT（Bidirectional Encoder Representations from Transformers）、GPT（Generative Pretrained Transformer）和Transformer 是三种在自然语言处理（NLP）领域广泛使用的模型或模型架构。它们之间的关系可以从以下几个方面来理解：</p>
<ol>
<li><p><strong>Transformer</strong>：Transformer 是一种模型架构，它在 “Attention is All You Need” 这篇论文中首次被提出。Transformer 模型的主要特点是它完全放弃了传统的 RNN（循环神经网络）或 CNN（卷积神经网络）结构，而是完全依赖于 self-attention 机制来处理序列数据。这种结构使得 Transformer 模型在处理长距离依赖和并行计算方面具有优势。</p>
</li>
<li><p><strong>GPT</strong>：GPT 是 OpenAI 开发的一种基于 Transformer 的模型。GPT 使用了 Transformer 的解码器部分，并且采用了单向（从左到右）的自注意力机制。这使得 GPT 在生成文本（如写作、翻译等任务）方面表现出色。</p>
</li>
<li><p><strong>BERT</strong>：BERT 是 Google 开发的一种基于 Transformer 的模型。与 GPT 不同，BERT 使用了 Transformer 的编码器部分，并且采用了双向的自注意力机制。这使得 BERT 能够理解文本中的上下文信息，因此在理解、分类、问答等任务中表现优秀。</p>
</li>
</ol>
<p>总的来说，Transformer 是一种模型架构，而 GPT 和 BERT 都是基于这种架构的模型，但它们在具体实现和应用上有所不同。</p>
<h1 id="时间线前"><a href="#时间线前" class="headerlink" title="时间线前"></a>时间线前</h1><h2 id="范式转换1-0"><a href="#范式转换1-0" class="headerlink" title="范式转换1.0"></a>范式转换1.0</h2><ol>
<li>bert 和 gpt 模型出现以前，NLP 领域流行的技术是深度学习模型</li>
<li>NLP 领域的深度学习<ol>
<li>大量改进的 LSTM 模型 | 少量的改进 CNN 模型作为特征抽取器</li>
<li>以 sequence to sequence（encode-decoder）+ Attention 作为各种具体任务典型。</li>
<li>目标：如何有效增加模型深层或模型的参数容量。<br> 即：怎么才能往encoder 和decoder 里不断叠加更深的 LSTM 或 CNN 层，来达成增加层数和模型容量的目标。</li>
<li>分类：<ol>
<li>中间任务：中文分词，词性标注，NER，句法分析，指代消解，语义 Parser 等，</li>
<li>最终任务：文本分类，文本相似性计算，机器翻译，文本摘要。<ol>
<li>自然语言理解类任务：本质上是分类任务</li>
<li>自然语言生成类任务</li>
</ol>
</li>
</ol>
</li>
<li>评价：总体而言不是很成功，或者说和非深度学习方法相比，带来的优势i不算很大。</li>
<li></li>
</ol>
</li>
<li>NLP 深度学习不算成功的原因：<ol>
<li>训练数据总量的限制。</li>
<li>LSTM | CNN 特征提取器表达能力不强。</li>
</ol>
</li>
<li>Ber|GPT 这两个预训练模型的出现，代表 NLP 领域的飞跃<ol>
<li>NLP 研究子领域日渐消亡<ol>
<li>中间任务不应该出现，这是 NLP 技术发展水平不够高的一种体现。很难一步做好有难度的最终任务。</li>
<li>Bert|GPT 出现后没有必要做这些中间任务了，因为 Bert|GPT 已经把这些中间任务作为语言学特征，吸收到了 Transformer 的参数里，</li>
</ol>
</li>
<li>NLP 不同子领域技术方法和技术日渐统一。<ol>
<li>NLP 领域特征提取器都逐渐从 LSTM|CNN 统一到 Transformer 上。</li>
<li>大多数 NLP 子领域的研发模式切换到了两阶段模式，：<ol>
<li>模型预训练阶段</li>
<li>应用微调<br> 或者：</li>
<li>Zero Shot</li>
<li>Few Shot</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.523Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/GAI%20%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p><a target="_blank" rel="noopener" href="https://github.com/ninehills/blog/issues/92">https://github.com/ninehills/blog/issues/92</a></p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.522Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/Finetuning/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h3 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a>监督学习与无监督学习</h3><h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><p>任务：学习一个映射函数，给定任意输入响应做一个好的预测输出。<br>本质：学习输入到输出的映射的统计规律。<br>常见情景：回归，分类，标注。（区别在于变量的取值类型）<br>（1）当输入变量和输出变量均为连续值变量时得到回归任务，它主要用于学习输入变量和输出变量之间的数值映射关系，常见的回归任务有价格预测、趋势预测等，处理回归任务时常用的机器学习模型有最小二乘回归、非线性回归等。<br>（2）无论其输入变量为离散值还是连续值，当输出变量为有限个离散值时得到分类任务，分类任务是被人们讨论和应用最广泛的任务，它通常用于分门别类，常见的分类任务有图片类别识别、用户分类、文本分类等，处理分类任务时常用的机器学习模型有：k近邻、朴素贝叶斯、决策树、逻辑斯蒂回归模型、支持向量机、神经网络等。<br>（3）当输入变量和输出变量均为变量序列时得到标注任务，它是分类问题的一种推广，用于学习输入序列和输出序列的映射关系，典型的标注任务有自然语言处理中的词性标注、信息抽取等，处理标注任务时常用的机器学习模型有隐马尔科夫模型和条件随机场等</p>
<h5 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h5><p>监督学习是学习一个模型，然后利用该模型对给定的输入预测相应的输出，我们可将模型写成函数形式 Y&#x3D;f(X) 或条件概率分布形式 P(Y|X) 。</p>
<h6 id="判别模型-生成模型：根据条件概率的计算方式"><a href="#判别模型-生成模型：根据条件概率的计算方式" class="headerlink" title="判别模型&amp;生成模型：根据条件概率的计算方式"></a>判别模型&amp;生成模型：根据条件概率的计算方式</h6><ol>
<li>[[判别模型]]<ol>
<li>建模方式：直接对 P(Y|X)  进行建模，它试图描述在给定输入特征 X 的情况下，标签信息 Y 的分布，</li>
<li>典型判别模型包括： 近邻法、感知机、决策树、逻辑回归和条件随机场等。</li>
<li>评价：判别模型对条件概率模型直接建模，无法反映训练数据本身的概率特性，但是以分类问题为例，判别模型在寻找最优分类面的过程中，学习了不同类别数据之间的差异。另外，判别模型可以对数据进行各种程度上的抽象、降维，因此可以简化学习问题，学习准确率更高。</li>
</ol>
</li>
<li>[[生成模型]]<ol>
<li>对数据特征 X 和标签 Y 的联合分布 p(X,Y) 进行建模，然后利用条件概率公式，即可计算 p(Y|X) ，如下所示:<br> $p(Y|X) &#x3D; \frac {p(X,Y)}{p(X)}$<br> 一般将其转换为易为计算的方式，如下所示<br> $p(Y|X) &#x3D; \frac {p(X|Y)*p(Y)}{p(X)}$</li>
<li>举例：朴素贝叶斯方法和隐马尔科夫模型等。<ol>
<li>在朴素贝叶斯方法中，我们通过训练集学习到先验概率分布 p(Y) 和条件概率分布 p(Y|X)，则可得到联合概率分布 p(X,Y)；</li>
<li>隐马尔可夫模型中，我们通过训练集学习到初始概率分布、状态转移概率矩阵和观测概率矩阵，则得到了一个可以表示状态序列与观测序列联合分布的马尔可夫模型。</li>
</ol>
</li>
<li>评价：生成模型直接学习联合分布，可以更好地表示数据的分布，更好反映同类数据的相似度。当样本数量比较大时，生成模型往往可以更好地收敛到真实模型上，其收敛速度快。另外，生成模型可以处理含有隐变量的情况，而判别模型对此无能为力。生成模型也可以通过计算边缘分布而检测某些异常值。但实践中，生成模型计算开销一般比较大，而且多数情况下其效果不如判别模型。</li>
</ol>
</li>
</ol>
<h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><p>和监督学习比较：</p>
<ol>
<li>无监督学习和监督学习最大的区别就是标签的有无。在监督学习中，训练模型的任务是学习输入特征到标签的映射，</li>
<li>而无监督学习中只有样本的特征向量，故无监督学习的任务是对数据进行深入“挖掘”，其本质是学习数据中的统计规律或潜在结构。对于无监督学习的深入研究对深度学习的复兴上起到了关键的作用。</li>
<li>相比于无监督学习除了拥有额外的标签信息外，还需要有测试样本。机器学习模型在训练集中学习“规律”，然后对测试集使用这种“规律”来评价模型的效果，而无监督学习不需要测试样本，整个过程只需要训练集的参与。</li>
<li>另外，无监督学习相比于监督学习一般拥有更好的拓展性，它在完成训练目标的同时，通常还额外学习到了样本的表示，我们可以将这些表示直接用于其他的任务。<br>常见任务：降维、聚类、概率模型估计。<br>（1）降维任务主要用于处理数据的高维度问题，真实数据的特征维度过大容易造成模型的拟合度与可用性降低，我们可以通过降维算法对高维度数据进行“压缩”使之变成低维度向量，从而提高数据的可用性，常用的算法有主成分分析、因子分析、隐含狄利克雷分布等，包括早期的自编码器也可用于数据降维。<br>（2）聚类任务主要将样本依据一定的规则进行类别分配，即通过衡量样本之间的距离、密度等指标，将关系“近”的样本聚为同一类，以此实现样本的自动分类，常用的算法有层次聚类、k-means聚类、谱聚类等。<br> （3）在概率模型估计任务中，对于一个可以生成样本的概率模型，我们使用样本对概率模型的结构、参数进行学习，使得概率模型生成的样本与训练样本最相似。其中一种比较简单的概率密度估计任务便是对随机变量的概率密度函数进行学习，常用的算法有极大似然估计、对抗生成网络、变分自编码器等，这部分内容非常丰富。</li>
</ol>
<h4 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h4><p> 半监督学习是介于监督学习和无监督学习的一种方式，即只有小部分训练样本带有标签信息，而大多数训练样本的标签信息空缺。半监督学习包括直推和归纳两类模式，直推半监督学习只对给定的训练数据进行处理，它使用训练数据集中有类别标签和无类别标签的样本进行训练，预测其中无标签样本的标签信息；归纳半监督学习不仅预测训练数据集中无标签样本的标签，更主要的是预测未知样本的标签，两者的区别在于需要预测标签的样本是否出现在训练集中。半监督学习一般用于四类学习场景：半监督分类、半监督回归、半监督聚类、半监督降维等。</p>
<h3 id="上下文无关语法"><a href="#上下文无关语法" class="headerlink" title="上下文无关语法"></a>上下文无关语法</h3><p>上下文无关语法（Context-Free Grammar）和概率上下文无关语法（Probabilistic Context-Free Grammar）的概念。</p>
<p>上下文无关语法是一种形式语言描述方法，用于定义一类语言的语法结构。它由一组产生式规则组成，每个规则包含一个非终结符和一个由非终结符和终结符组成的字符串。其中，α是一个单变量，表示非终结符，而β是由变量或最终值组成的字符串。这些产生式规则定义了从一个起始样本开始，通过替换非终结符，逐步生成包含所有最终值的字符串集合。上下文无关语法的特点是，无论α出现在哪个上下文中，都可以自由地用β替换，而不需要考虑α的上下文。</p>
<p>概率上下文无关语法是在上下文无关语法的基础上引入了概率特性。每个产生式规则都被赋予一个概率值，表示该规则被应用的概率。这样，概率上下文无关语法可以用于建模具有统计特性的语言。例如，在自然语言处理中，可以使用概率上下文无关语法来生成句子或解析句子的结构，并为每个规则分配适当的概率。</p>
<p>总结来说，上下文无关语法是一种用于描述语言的语法结构的方法，其中产生式规则定义了从起始样本开始生成所有最终值的字符串。概率上下文无关语法在上下文无关语法的基础上引入了概率特性，使其适用于建模具有统计特性的语言。</p>
<h3 id="多视图学习"><a href="#多视图学习" class="headerlink" title="多视图学习"></a>多视图学习</h3><p>多视图学习（Multi-view Learning）是一种机器学习方法，旨在利用来自多个视图或多个特征表示的数据来改善学习性能。在多视图学习中，数据样本可以从不同的视角或特征空间中获取多个不同的表示。通过综合这些多个视图的信息，多视图学习可以提供更全面和准确的数据描述，从而改善模型的泛化能力和学习结果。</p>
<p>传统的机器学习方法通常假设数据特征是从单个视图或特征空间中提取的，因此忽略了不同视图之间的相关性和互补性。而多视图学习则通过融合多个视图的信息来克服这个限制。它可以应用于各种领域和任务，如模式识别、图像处理、文本分类、推荐系统等。</p>
<p>多视图学习的关键挑战是如何有效地利用不同视图之间的相关性。常见的多视图学习方法包括以下几种：</p>
<ol>
<li><p>基于特征融合的方法：将不同视图的特征进行融合，生成一个更综合和丰富的特征表示。常见的融合方法包括特征级融合、决策级融合和模型级融合等。</p>
</li>
<li><p>基于共享表示学习的方法：通过学习一个共享的低维表示空间，将不同视图的数据映射到该共享空间中。这样可以使不同视图之间的相关性更加明显，便于后续的学习和推理。</p>
</li>
<li><p>基于多示例学习的方法：将多个视图看作是一个示例的不同表示，通过多示例学习的方式来进行模型训练和预测。这种方法适用于存在不完全标注的数据集，其中每个示例可能有多个视图的表示。</p>
</li>
</ol>
<p>多视图学习方法可以提供更全面和准确的数据建模，从而改善学习性能。它可以利用不同视图的互补信息，提取更丰富的特征表示，并减少数据表示的不确定性。这使得多视图学习成为处理复杂数据和提高模型性能的有效工具。</p>
<h3 id="随机投影（SimHash）"><a href="#随机投影（SimHash）" class="headerlink" title="随机投影（SimHash）"></a>随机投影（SimHash）</h3><p>TODO：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/92155250">https://zhuanlan.zhihu.com/p/92155250</a></p>
<ol>
<li><p><strong>SimHash 算法</strong>：SimHash 是一种用于计算文本或数据的哈希值的算法。它的主要思想是将文本或数据转换为二进制向量，其中相似的文本或数据会产生相似的哈希值。这种相似性哈希算法被广泛应用于文本去重、相似文档聚类和相似性搜索等任务。</p>
</li>
<li><p><strong>随机投影</strong>：随机投影是一种降维技术，用于将高维数据映射到低维空间。在随机投影 SimHash 中，通过使用随机生成的投影矩阵将高维特征向量映射到低维二进制码。</p>
</li>
<li><p><strong>哈希函数</strong>：随机投影 SimHash 使用哈希函数来将投影后的低维向量转换为二进制码。常用的哈希函数是符号哈希函数，它根据投影后的特征向量的符号（正负）来决定对应二进制码的取值（0 或 1）。</p>
</li>
<li><p><strong>相似性匹配</strong>：通过计算 SimHash 值之间的汉明距离（Hamming Distance），可以判断文本或数据之间的相似性。汉明距离是指两个等长字符串之间相对位置不同的字符的个数。汉明距离越小，表示文本或数据之间越相似。</p>
</li>
</ol>
<h3 id="线性特征-非线性特征"><a href="#线性特征-非线性特征" class="headerlink" title="线性特征 &amp; 非线性特征"></a>线性特征 &amp; 非线性特征</h3><ol>
<li><p>线性特征：特征和目标的关系可以用一条直线来拟合。</p>
</li>
<li><p>非线性特征：特征和目标之间的关系不可以用一条直线来拟合</p>
</li>
</ol>
<h3 id="弱分类器-强分类器"><a href="#弱分类器-强分类器" class="headerlink" title="弱分类器 &amp; 强分类器"></a>弱分类器 &amp; 强分类器</h3><ol>
<li><p>弱分类器：准确率在 60% ~80%之间，即：比随即预测好，但是准确率不高。e.g. CART（分类与回归树）</p>
</li>
<li><p>强分类器：准确率在90%以上。</p>
</li>
</ol>
<h3 id="分类任务-回归任务"><a href="#分类任务-回归任务" class="headerlink" title="分类任务 &amp; 回归任务"></a>分类任务 &amp; 回归任务</h3><ol>
<li><p>分类任务（Classification）</p>
<ol>
<li><p>目标：将输入实例分配到预定义的类别中。</p>
</li>
<li><p>过程：模型通过学习输入特征与响应类别之间的关系，来预测新的未知示例所属类别。</p>
</li>
<li><p>输出：输出是离散的，通常是表示类别的标签或类别的概率分布。</p>
</li>
</ol>
</li>
<li><p>回归任务（Regression）</p>
<ol>
<li><p>目标：预测连续的数值输出。</p>
</li>
<li><p>过程：模型通过学习输入特征与响应输出值之间的关系，来预测新的未知示例的数值结果。</p>
</li>
<li><p>输出：这是一个连续的数值输出。</p>
</li>
</ol>
</li>
</ol>
<p>注意：有些机器学习算法可以同时用于分类和回归任务，例如决策树和支持向量机等。这些算法可以根据任务的要求进行适当的调整和配置。</p>
<h3 id="LR、DT、SVM的对比"><a href="#LR、DT、SVM的对比" class="headerlink" title="LR、DT、SVM的对比"></a>LR、DT、SVM的对比</h3><ol>
<li><p>所谓分类问题就是在特征空间内寻找决策边界线。而三种算法决定了生成的边界线的不同形状。</p>
</li>
<li><p>如何在多维特征空间中选择合适的算法：</p>
<ol>
<li><p>先选逻辑回归，如果效果不怎么样，可以将它的结果作为基准来参考</p>
</li>
<li><p>试试决策树（随机森林）是否可以大幅度提升模型性能。即使没有把它当作最终模型，也可以使用随机森林来移除噪声变量。</p>
</li>
<li><p>如果特征的数量和观测样本特别多，那么当资源和时间充足时，使用SVM不失为一种选择。</p>
</li>
</ol>
</li>
</ol>
<h3 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h3><ol>
<li><p>目的：解决分类问题。</p>
</li>
<li><p>核心：特征权重的线性组合、sigmoid 函数的计算和损失函数的最小化。</p>
</li>
<li><p>特点：逻辑回归的决策边界总是一条直线（或者一个平面，在更高维度上是超平面）。</p>
</li>
<li><p>优势：</p>
<ol>
<li><p>适用于处理接近线性可分的分类问题。</p>
</li>
<li><p>结果不是一个离散值或者确切的类别。而是一个与每个观测样本相关的概率列表，所以可以用不同的标准和常用的性能指标来分析这个概率分数，得到不同的分类结果。</p>
</li>
<li><p>时间和内存需求上相当高效。可以用于分布式数据，用较少的资源处理大型数据</p>
<blockquote>
<p>低内存消耗：逻辑回归模型只需要存储特征权重，而不需要存储大量的训练数据。相比之下，其他复杂的模型（如神经网络）可能需要存储大量的中间参数和计算图，导致更高的内存消耗。
 </p>
</blockquote>
</li>
<li><p>对数据中小噪声的棒鲁性很好。</p>
</li>
<li><p>逻辑回归广泛应用于工业问题上。</p>
</li>
</ol>
</li>
<li><p>地位：解决工业规模问题最流行的算法</p>
</li>
<li><p>缺点：</p>
<ol>
<li><p>在效率和算法实现的易用性方面并不出众。</p>
</li>
<li><p>当特征数目很大并且还丢失了大部分数据时，逻辑回归就会表现的力不从心。</p>
</li>
<li><p>当类别变量过多时也会力不从心</p>
</li>
<li><p>对于非线性特征，需要进行转换。</p>
</li>
<li><p>依赖于全部数据。</p>
</li>
</ol>
</li>
</ol>
<h3 id="决策树（Decisoin-Trees）"><a href="#决策树（Decisoin-Trees）" class="headerlink" title="决策树（Decisoin Trees）"></a>决策树（Decisoin Trees）</h3><ol>
<li><p>目的：解决分类问题 &amp; 逻辑回归问题。</p>
</li>
<li><p>结构：按照层次结构的规则生成的。</p>
</li>
<li><p>特性：对单向变换或者非线性特征并不关心。(不需要变换来捕获数据中的非线性相关性，可以用他的划分方式自适应处理非线性关系)。</p>
<blockquote>
<p>单向变换：如指数、对数变换。
 </p>
</blockquote>
</li>
<li><p>优势：如果边界是非线性的，并且能通过不断将特征空间分为矩形来模拟，那么决策树是比逻辑回归更好的选择。</p>
<ol>
<li><p>直观的决策规则；</p>
</li>
<li><p>可以处理非线性特征；</p>
</li>
<li><p>考虑了变量之间的相互作用；</p>
</li>
</ol>
</li>
<li><p>缺点：</p>
<ol>
<li><p>训练集上的效果高于测试集，即过拟合【随机森林克服了此缺点】；</p>
</li>
<li><p>没有将排名分数作为直接结果；</p>
</li>
</ol>
</li>
<li><p>针对离散数据的分类决策树</p>
<ol>
<li><p>定义：预测任务的输入和输出都是离散值</p>
</li>
<li><p>例子：ID3、C4.5</p>
</li>
<li><p>原始决策树：不断选择，优先选择信息熵最小的特征进行分组</p>
<blockquote>
<p>信息熵：越大，表示特征的信息量越大，越离散，按照这个特征分组之后，样本的混乱程度越大。e.g. 特征某个水平的值出现的概率与取对数的积和。
 </p>
</blockquote>
</li>
<li><p>ID3：使用信息增益来度量特征对分类的帮助大小</p>
<blockquote>
<p>信息增益：使用一个特征对数据进行分组之后各组样本的有序程度会更高，熵会降低，分组前后熵的差值就是这个特征带来的信息增益。信息增益越大，说明这个特征越有助于分组。分组之前算一次，分组之后算一次。
 </p>
</blockquote>
</li>
<li><p>C4.5 算法：在信息增益的基础上构造了一个新的特征质量度量指标：信息中增益比</p>
<blockquote>
<p>信息增益比：按照性别划分之后对成年的的信息增益&#x2F;分组之前对性别的信息增益</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h3 id="支持向量机（Support-Vector-Machine-SVM）"><a href="#支持向量机（Support-Vector-Machine-SVM）" class="headerlink" title="支持向量机（Support Vector Machine,SVM）"></a>支持向量机（Support Vector Machine,SVM）</h3><ol>
<li><p>目的：解决分类问题 &amp; 逻辑回归问题</p>
</li>
<li><p>特点：依靠边界样本来建立需要的分离曲线。它可以处理非线性决策边界。（对边界依赖）</p>
</li>
<li><p>结构：把特征空间映射到核空间，使得各个类别线性可分。把特征空间又增加一个维度。</p>
<blockquote>
<ol>
<li><p><strong>核函数</strong>：SVM使用核函数来将输入特征映射到高维特征空间，从而使得原本在低维空间中非线性可分的问题在高维空间中变得线性可分。核函数的作用是通过计算样本在高维空间中的内积来隐式地表示非线性特征之间的相互作用。常用的核函数包括多项式核函数、高斯核函数（径向基函数）等。</p>
</li>
<li><p><strong>大间隔原则</strong>：SVM的优化目标是找到一个最大间隔的超平面来划分不同类别的样本。通过最大化间隔，SVM能够在特征空间中找到一条边界，使得不同类别的样本尽可能分开。这种大间隔原则使得SVM对于非线性特征之间的相互作用更加鲁棒，能够更好地处理非线性关系。</p>
</li>
<li><p><strong>非线性核函数</strong>：除了线性核函数，SVM还可以使用非线性核函数，如多项式核函数和高斯核函数。这些核函数能够捕捉非线性特征之间的相互作用，将数据映射到高维特征空间中，并在高维空间中构建一个线性超平面来进行分类。这样，SVM能够处理非线性特征之间的相互作用，提高模型的表达能力。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>优点</p>
<ol>
<li><p>能够处理大型特征空间</p>
</li>
<li><p>能够处理非线性特征之间的相互作用</p>
</li>
<li><p>无需依赖整个数据</p>
</li>
</ol>
</li>
<li><p>缺点：</p>
<ol>
<li><p>当观测样本很多时，效率并不是很高</p>
</li>
<li><p>有时候很难找到一个合适的核函数</p>
</li>
</ol>
</li>
</ol>
<h3 id="分类与回归树（Classification-and-Regression-Tree-CART）"><a href="#分类与回归树（Classification-and-Regression-Tree-CART）" class="headerlink" title="分类与回归树（Classification and Regression Tree,CART）"></a>分类与回归树（Classification and Regression Tree,CART）</h3><ol>
<li><p>概念：一种经典决策树，可以用来处理涉及连续数据的分类或者回归任务。</p>
</li>
<li><p>思想：一些学者采用类似随机投影的思路，将自变量的取值空间切分为若干个碎块，并假设这个空间碎块内的所有样本的因变量取值接近(甚至相同)——在这种思想的指导下，出现了一种非常经典的回归模型，即CART回归树。</p>
</li>
<li><p>由来：</p>
<ol>
<li><p>特征为连续变量：不能直接使用特征取值，选择用于分割样本的特征取值</p>
</li>
<li><p>输出为连续变量：基尼系数和信息增益并不能作为分组质量的表征。使用！回归树！</p>
</li>
</ol>
</li>
<li><p>关键：设计一个标准，用来指导机器按照最有利于准确计算因变量的情况来切分特征空间。</p>
<ol>
<li>e.g.:切分特征空间的标准：MES</li>
</ol>
</li>
<li><p>代码：<a target="_blank" rel="noopener" href="https://github.com/lipengyuer/DataScience/blob/master/src/algoritm/CARTRegression.py">https://github.com/lipengyuer/DataScience/blob/master/src/algoritm/CARTRegression.py</a></p>
</li>
</ol>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p>概念：通过组合多个基本模型的预测结果，以获得更好的整体预测性能。</p>
<p>目的：组合多个弱分类器或者回归器来创建一个强分类器或者回归器。</p>
<ol>
<li><p>bagging</p>
<p> 通过对原数据集的抽样，得到多份采样数据集，使用弱学习器分别在这多份采样数据集上学习， 而后使用集成策略将结果整合起来（e.g. 分类问题用投票法，回归问题用加权法） e.g. 随机森林（Random Forest）</p>
</li>
<li><p>stacking</p>
<p> 使用不同的学习方法学习同一份数据，得到多个学习器， 而后使用另一个学习器，学习以上多个学习器的输出到真实标签的映射 boosting 按序处理多个弱学习器，排在后的学习器重点学习排在前的学习器无法处理好的那些数据 e.g. Ada</p>
</li>
<li><p>Boost</p>
<p> 一个学习器学完后，根据其对数据集分类的正确与否，调整下一个学习器学习时，数据集各条数据被采样到的概率，达成调整数据集分布的作用。而后多个学习器按照各自的正确率集成在一</p>
</li>
</ol>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><ol>
<li><p>是决策树一个非常优秀的扩展，同时也剥夺了商业规则和易解释性。</p>
<ol>
<li><p>树很多，使用多数投票规则使得模型变得更加复杂，</p>
</li>
<li><p>决策树变量之间也存在相互作用。</p>
</li>
</ol>
</li>
</ol>
<h3 id="变分贝叶斯方法"><a href="#变分贝叶斯方法" class="headerlink" title="变分贝叶斯方法"></a>变分贝叶斯方法</h3><p>参考：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">Variational Bayesian methods</a><br>变分贝叶斯方法是一系列用于逼近贝叶斯推理和机器学习中出现的棘手积分的技术。它们通常用于由观察变量（通常称为“数据”）以及未知参数和潜在变量组成的复杂统计模型，这三种类型的随机变量之间具有各种关系，正如图形模型所描述的那样。正如贝叶斯推理中的典型情况一样，参数和潜在变量被分组为“未观察到的变量”。变分贝叶斯方法主要用于两个目的：</p>
<ol>
<li>为未观测变量的后验概率提供分析近似，以便对这些变量进行统计推断。</li>
<li>导出观察数据的边际可能性（有时称为证据）的下限（即给定模型的数据的边际概率，对未观察的变量进行边缘化）。这通常用于执行模型选择，一般思想是给定模型的边际，可能性较高表明该模型对数据的拟合更好，因此所讨论的模型是生成数据的模型的概率更大。 （另请参阅贝叶斯因子文章。）<br>。。。。。</li>
</ol>
<h3 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h3><p>（Laplace smoothing），也称为加一平滑（Add-One smoothing），是一种用于处理概率估计中的零概率问题的技术。它是一种简单而常用的平滑方法，可用于解决在计算概率时可能出现的数据稀疏性和零概率的情况。</p>
<p>在概率估计中，当我们根据样本数据计算事件的概率时，有时会遇到某些事件在样本中未出现的情况，导致概率估计为零。这在实际应用中可能不太合理，因为我们不能简单地认为未观察到的事件的概率为零。</p>
<p>拉普拉斯平滑通过在计算概率时为每个事件的计数值（或频率）增加一个常数（通常为1），来解决零概率问题。这个常数被称为平滑因子或平滑参数。通过这种方法，即使某个事件在样本中未出现，它的概率仍然会被估计为一个非零值。</p>
<p>拉普拉斯平滑的概率估计公式如下：<br>P(x) &#x3D; (count(x) + 1) &#x2F; (N + V)</p>
<p>其中，P(x)表示事件x的平滑概率，count(x)表示在样本中观察到事件x的次数，N表示总观测次数，V表示事件的可能取值数量（即事件的种类数）。</p>
<p>应用方面，拉普拉斯平滑广泛用于自然语言处理（NLP）中的语言模型，特别是n-gram语言模型。在n-gram模型中，用于估计概率的数据通常是文本中的n个连续词语序列。拉普拉斯平滑可以解决在计算概率时可能出现的未观察到的n-gram序列的问题，提高语言模型的鲁棒性和泛化能力。</p>
<p>除了语言模型，拉普拉斯平滑还可以应用于其他概率估计问题，如朴素贝叶斯分类器、信息检索中的查询扩展和推荐系统等。它可以有效地处理数据稀疏性问题，并提供更合理的概率估计结果。</p>
<h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>当谈到强化学习（Reinforcement Learning，RL）时，我们在机器学习中讨论的是一种范例和方法。它主要用于描述和解决智能代理与环境交互的学习问题，目标是通过学习一种策略或行为序列来最大化累积的回报或实现特定目标。</p>
<p>在强化学习中，我们有一个智能代理（agent），它根据环境的状态（state）选择动作（action），并与环境进行交互。环境会根据代理采取的动作以及当前的状态，返回给代理一个奖励信号（reward）和下一个状态。代理的目标是通过与环境的交互，通过尝试和错误的方式来学习一个最佳策略，以使得长期累积的回报最大化。</p>
<p>在强化学习中，代理通过学习价值函数（value function）或策略函数（policy function）来指导其决策过程。价值函数可以评估给定状态或状态动作对的价值，而策略函数定义了在给定状态下选择动作的方式。代理通过与环境的交互不断更新这些函数，以改进其决策能力。</p>
<p>强化学习的一个重要概念是探索（exploration）与利用（exploitation）的权衡。探索是指代理通过尝试新的动作来发现更多的知识，而利用是指代理根据已知信息选择最优动作以获得最大回报。强化学习算法需要在探索和利用之间找到平衡，以达到最佳的学习效果。</p>
<p>总结起来，强化学习是一种机器学习方法，用于解决智能代理与环境交互的学习问题。代理通过学习策略或行为序列来最大化累积回报或实现特定目标。在这个过程中，代理通过与环境的交互不断更新价值函数和策略函数，以改进其决策能力。探索与利用的权衡是强化学习中需要解决的重要问题之一。</p>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ol>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/743cf2357b28">https://www.jianshu.com/p/743cf2357b28</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53183016">https://zhuanlan.zhihu.com/p/53183016</a></p>
</li>
<li><p>CART回归：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/128472955">https://zhuanlan.zhihu.com/p/128472955</a></p>
</li>
</ol>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.520Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h2 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h2><p><a target="_blank" rel="noopener" href="https://0809zheng.github.io/2020/04/24/self-attention.html">https://0809zheng.github.io/2020/04/24/self-attention.html</a></p>
<p>TODO</p>
<p>下面是关于NLP中常用的一些知识的简要说明：</p>
<ol>
<li><p>Attention（注意力机制）： Attention是一种<strong>用于提升神经网络模型性能的机制</strong>，特别是在序列任务中。它允许<strong>模型在处理输入序列时将重点放在相关的部分上。</strong>通过计算每个输入位置的权重，模型可以自适应地决定要关注哪些部分。注意力机制在机器翻译、文本摘要、问答系统等任务中得到广泛应用。</p>
</li>
<li><p>Transformer（变换器）： Transformer是一种基于注意力机制的神经网络架构，用于处理序列数据。它在自然语言处理任务中取得了重大突破，并成为许多最先进的模型的基础。Transformer通过自注意力机制（self-attention）来捕捉输入序列中的依赖关系，避免了传统循环神经网络中的顺序计算，并且能够并行处理输入。Transformer的典型应用包括机器翻译（如Google的Transformer模型）和语言模型。</p>
</li>
<li><p>BERT（Bidirectional Encoder Representations from Transformers）： BERT是一种预训练的语言表示模型，基于Transformer架构。通过在大规模文本数据上进行无监督的预训练，BERT可以学习出通用的语言表示，然后可以在各种下游任务上进行微调。BERT引入了掩码语言模型（Masked Language Model, MLM）和下一句预测（Next Sentence Prediction, NSP）等任务来训练模型。BERT的出现对各种NLP任务，如文本分类、命名实体识别、问答系统等都产生了显著影响。</p>
</li>
<li><p>GPT（Generative Pre-trained Transformer）： GPT是一种基于Transformer架构的预训练语言模型，用于生成文本。GPT通过在大规模文本数据上进行自监督的预训练，学习出对输入序列的概率分布建模能力。然后，可以使用该模型生成具有连贯性和语法正确性的文本。GPT模型在生成式任务中表现出色，如文本生成、对话系统、机器写作等。</p>
</li>
<li><p>Prompt（提示）： Prompt是指在进行自然语言处理任务时，向模型提供一种任务描述或问题陈述的方式。通过给定一个显式的提示文本，模型可以更好地理解任务需求和上下文，从而产生更准确的输出。Prompt工程化是近年来在NLP任务中的一种重要技术，它可以帮助改进模型的可控性、减少模型的偏见，并提高模型的性能。</p>
</li>
</ol>
<p>下面是这些概念之间的关系：</p>
<ol>
<li><p>Attention（注意力机制）是Transformer（变换器）模型的核心组件之一。Transformer通过自注意力机制实现了对输入序列的建模，其中每个位置可以根据其与其他位置的相关性来调整其重要性。</p>
</li>
<li><p>Transformer是一种神经网络架构，被广泛用于自然语言处理任务。它的设计中包含了多头注意力机制，可以同时关注不同位置的不同方面。Transformer的出现使得处理长序列数据变得更加高效，并在机器翻译、文本生成等任务中取得了显著的性能提升。</p>
</li>
<li><p>BERT（Bidirectional Encoder Representations from Transformers）是基于Transformer的预训练语言模型。它通过大规模的无监督预训练，在理解上下文和建模语言表示方面取得了巨大成功。BERT的预训练模型可以通过微调适应各种下游任务，如文本分类、命名实体识别等。</p>
</li>
<li><p>GPT（Generative Pre-trained Transformer）也是基于Transformer的预训练语言模型，但其目标是生成连贯的文本。GPT通过自监督学习来提前训练一个语言模型，然后可以用于生成各种文本，如文章、对话等。GPT模型在生成式任务中表现出色，可以产生具有语法正确性和连贯性的文本。</p>
</li>
<li><p>Prompt（提示）是在进行NLP任务时向模型提供任务描述或问题陈述的方式。Prompt的引入主要是为了改进模型的可控性和减少模型的偏见。通过设计合适的提示文本，可以引导模型在特定任务上产生更准确、更符合预期的输出。</p>
</li>
</ol>
<p>总体而言，Attention是一种机制，Transformer是一种基于Attention的网络架构，BERT和GPT是基于Transformer的预训练语言模型，而Prompt是一种用于指导模型输出的技术手段。它们在NLP领域中相互关联，相互借鉴，共同推动了自然语言处理技术的发展。</p>
<h2 id="深度卷积神经网络"><a href="#深度卷积神经网络" class="headerlink" title="深度卷积神经网络"></a>深度卷积神经网络</h2><p>至少在网络的一层中使用卷积运算来代替一般的矩阵乘法运算的神经网络，因此命名为卷积神经网络</p>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\b98e8b23b2eec30346b082aa1fbca27ca8c377ab.png@1256w_712h_!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<h3 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h3><p>卷积核（kernel） ，一个权重矩阵，逐步在二维输入数据上“扫描”，卷积核“滑动”的同时，计算权重矩阵和扫描所得的数据矩阵的乘积，然后把结果汇总成一个输出像素。</p>
<p><strong>大小一般为奇数：</strong>原因</p>
<ol>
<li><p>更容易 padding，计算结果为整数</p>
</li>
<li><p>使用奇数大小的卷积核还可以保持对称性。对称性在卷积操作中是重要的，因为它可以确保输出特征图的空间分辨率与输入特征图相同。如果使用偶数大小的卷积核，由于缺少中心像素，可能会导致输出特征图的空间分辨率减小。</p>
</li>
<li><p>在CNN中，进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。 卷积核大小为奇数时，它具有一个中心元素，这使得在进行卷积操作时，可以确保输入图像的每个像素都有对应的卷积核元素与之对齐。这种中心对齐的特性有助于提取局部特征，同时减少了信息丢失的可能性。</p>
</li>
</ol>
<h3 id="卷积（Convolution）"><a href="#卷积（Convolution）" class="headerlink" title="卷积（Convolution）"></a>卷积（Convolution）</h3><p>所谓的卷积运算，其实它被称为<strong>互相关（cross-correlation）运算：</strong>将图像矩阵中，从左到右，由上到下，取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，最后的结果组成一个矩阵，其中没有对核进行翻转。</p>
<blockquote>
<p>数学上，给定两个函数 f(x) 和 g(x) 的卷积运算表示为：</p>
<p>(f * g)(x) &#x3D; ∫[−∞,∞] f(t)g(x−t) dt</p>
<p>对于每一个 x 得到的值 是 g 在 x 偏移 t 处 的值乘以 f(t) (权重) 的累加值，</p>
</blockquote>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\d646245dc94d4788dc48d0fcf6cd358f9d29f2c6.gif@1256w_1334h_!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<p><strong>核心操作，用于提取特征</strong></p>
<p>卷积运算具有一些重要的性质，例如交换律、结合律和分配律。</p>
<p>深度学习里面所谓的卷积运算，其实它被称为<strong>互相关（cross-correlation）运算：</strong>将图像矩阵中，从左到右，由上到下，取与滤波器同等大小的一部分（f(x-t)），每一部分中的值与滤波器中的值（g(t)）对应相乘后求和，最后的结果组成一个矩阵，其中没有对核进行翻转。</p>
<h3 id="填充（Padding）"><a href="#填充（Padding）" class="headerlink" title="填充（Padding）"></a>填充（Padding）</h3><p><strong>避免信息损失</strong></p>
<p>输入图像与卷积核进行卷积后的结果中损失了部分值，输入图像的边缘被“修剪”掉了（边缘处只检测了部分像素点，丢失了图片边界处的众多信息）。这是因为边缘上的像素永远不会位于卷积核中心，而卷积核也没法扩展到边缘区域以外。</p>
<p>这个结果我们是不能接受的，有时我们还希望输入和输出的大小应该保持一致。为解决这个问题，可以在进行卷积操作前，对原矩阵进行边界<strong>填充（Padding）</strong>，也就是在矩阵的边界上填充一些值，以增加矩阵的大小，通常都用“”来进行填充的。</p>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\c883f882924c3bfe1784b2a8b1c507c3dbe42963.gif@1256w_1428h_!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<p>通过填充的方法，当卷积核扫描输入数据时，它能延伸到边缘以外的伪像素，从而使输出和输入size相同。</p>
<p>常用的两种padding：</p>
<p>（1）valid padding：不进行任何处理，只使用原始图像，不允许卷积核超出原始图像边界</p>
<p>（2）same padding：进行填充，允许卷积核超出原始图像边界，并使得卷积后结果的大小与原来的一致 作者：2kb的卷心菜 <a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv16432604/">https://www.bilibili.com/read/cv16432604/</a> 出处：bilibili</p>
<h3 id="步长-Stride"><a href="#步长-Stride" class="headerlink" title="步长(Stride)"></a>步长(Stride)</h3><p><strong>压缩一部分信息，或者使输出的尺寸小于输入的尺寸</strong></p>
<p><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1781826967010713030&wfr=spider&for=pc">每天五分钟计算机视觉：卷积步长(Stride) (baidu.com)</a></p>
<p><strong>滑动卷积核时</strong>，我们会先从输入的左上角开始，每次往左滑动一列或者往下滑动一行逐一计算输出，我们将<strong>每次滑动的行数和列数</strong>称为Stride，在之前的图片中，Stride&#x3D;1；在下图中，Stride&#x3D;2。</p>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\af6e5cdf758fc9f2b6ba30235eae9e1c8128576b.gif@!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv16432604/">https://www.bilibili.com/read/cv16432604/</a> 出处：bilibili-2kb的卷心菜</p>
<h3 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h3><p>比如 RGB 有 红绿蓝三个 通道</p>
<p>这里就要涉及到“卷积核”和“filter”这两个术语的区别。在只有一个通道的情况下，“卷积核”就相当于“filter”，这两个概念是可以互换的。但在一般情况下，它们是两个完全不同的概念。每个“filter”实际上恰好是“卷积核”的一个集合，在当前层，每个通道都对应一个卷积核，且这个卷积核是独一无二的。</p>
<p><strong>多通道卷积的计算过程</strong>：将矩阵与滤波器对应的每一个通道进行卷积运算，最后相加，形成一个单通道输出，加上偏置项后，我们得到了一个最终的单通道输出。如果存在多个filter，这时我们可以把这些最终的单通道输出组合成一个总输出。</p>
<p><strong>某一层输出特征图的通道数</strong>&#x3D;当前层滤波器的个数。如上图所示，当只有一个filter时，输出特征图（4×4）的通道数为1；当有2个filter时，输出特征图（4×4×2）的通道数为2。</p>
<h3 id="降采样"><a href="#降采样" class="headerlink" title="降采样"></a>降采样</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46633171">https://zhuanlan.zhihu.com/p/46633171</a></p>
<p>概念：降采样指的是成比例缩小特征图宽和高的过程</p>
<p>例子：比如从（W，H）变为（W&#x2F;2，H&#x2F;2）</p>
<p>方法：</p>
<ol>
<li><p>stride 大于 1 的 pooling</p>
</li>
<li><p>stride 大于 1 的 conv</p>
</li>
<li><p>stride 大于 1 的 reorg（在<a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1612.08242.pdf">YOLOv2的论文</a>里叫passthrough layer）</p>
</li>
</ol>
<p>比较：</p>
<ol>
<li><p>1 和 2 在深度卷积神经网络中使用非常普遍，3 比较小众，由Joseph Redmon在YOLOv2中首次提出。</p>
</li>
<li><p>1 和 2 的对比在<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1412.6806">Striving for Simplicity: The All Convolutional Net</a>中有详述</p>
<p> 用stride&#x3D;2的conv降采样的卷积神经网络效果与使用pooling降采样的卷积神经网络效果相当；<strong>卷积神经网络小的时候，使用pooling降采样效果可能更好</strong>，卷积神经网络大的时候，使用stride&#x3D;2的conv降采样效果可能更好。</p>
<p> pooling提供了一种非线性，这种非线性需要较深的conv叠加才能实现，因此当网络比较浅的时候，pooling有一定优势；但是当网络很深的时候，多层叠加的conv可以学到pooling所能提供的非线性，甚至能根据训练集学到比pooling更好的非线性，因此当网络比较深的时候，不使用pooling没多大关系，甚至更好。</p>
<p> pooling的非线性是固定的，不可学习的，这种非线性其实就是一种先验。</p>
</li>
<li><p>3 中降采样的优势在于能够较好的保留低层次的信息。<strong>1 和 2 的降采样方式，好处是抽取的特征具有更强的语义性，坏处是会丢失一些细节信息</strong>。而3这种降采样方式与1、2相反，<strong>3 提取的特征语义性不强，但是能保留大量细节信息</strong>。所以当我们既需要降采样，又需要不丢失细节信息的时候，3是一个非常合适的选择。</p>
</li>
</ol>
<h3 id="升采样"><a href="#升采样" class="headerlink" title="升采样"></a>升采样</h3><p><strong>将输入特征图的尺寸放大或增加分辨率。</strong></p>
<p>通常与卷积和池化等操作结合使用，用于逆向传播梯度、特征图的恢复或生成更高分辨率的输出。</p>
<p>基本目标是增加特征图的空间尺寸，以便更好地捕获细节信息、提高特征的表达能力或生成更高分辨率的输出。</p>
<p>方法：</p>
<ol>
<li><p>反卷积（Transpose Convolution）：反卷积是一种常见的升采样方式，也称为转置卷积、分数步长卷积。它通过在<strong>输入特征图之间插入零值</strong>，并<strong>使用带有适当步长的卷积核进行卷积操作来放大特征图的尺寸</strong>。反卷积操作可以增加特征图的空间尺寸，并在某种程度上恢复输入特征图的细节。</p>
</li>
<li><p>双线性插值（Bilinear Interpolation）：双线性插值是一种基于插值的升采样方法，通过<strong>对输入特征图中的每个像素进行插值计算来生成更大尺寸的特征图。</strong>它使用<strong>周围四个像素的权重进行插值，保持了图像的平滑性和连续性</strong>。</p>
</li>
<li><p>最近邻插值（Nearest Neighbor Interpolation）：最近邻插值是一种简单的升采样方法，它将输入特征图中每个像素的值复制到放大后的特征图的相应位置。它在放大时<strong>不进行插值计算，而是直接使用最近邻像素的值</strong>。这种方法简单高效，但可能<strong>会导致输出特征图的锯齿状边缘</strong>。</p>
</li>
<li><p>其他一些升采样技术，如子像素卷积（Subpixel Convolution）、转置卷积的变种（如反池化操作）、像素重排（Pixel Shuffle）等。这些方法在不同的应用场景中具有各自的优势和适用性。</p>
</li>
</ol>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>是一种常用的操作层，用于减小特征图的空间尺寸、降低计算量，并增强模型的平移不变性。输入特征图的局部区域进行聚合或采样来生成池化特征图。</p>
<p>池化操作：通常在每个输入特征图的局部区域上应用，通过对区域内的特征进行聚合或采样，生成一个单一的值或特征。这个聚合或采样过程可以是简单的求最大值（最大池化，Max Pooling）或求平均值（平均池化，Average Pooling），也可以是其他聚合方式，如Lp范数池化。</p>
<p>在池化操作中，可以通过调整池化窗口的大小和步幅来控制输出特征图的大小和感受野。池化窗口是应用池化操作的局部区域的大小，<strong>步幅</strong>是<strong>池化窗口</strong>在输入特征图上移动的距离。</p>
<p>常见的池化操作及其特点：</p>
<ol>
<li><p>最大池化（Max Pooling）：在池化窗口内选择最大值作为池化特征。最大池化有助于保留显著的特征，提高模型的平移不变性和鲁棒性。</p>
</li>
<li><p>平均池化（Average Pooling）：在池化窗口内求特征的平均值作为池化特征。平均池化可以减少特征图的空间维度，并平滑特征。</p>
</li>
<li><p>Lp范数池化（Lp-norm Pooling）：在池化窗口内对特征进行Lp范数归一化，得到池化特征。Lp范数池化可以对特征进行归一化，并引入更多非线性。</p>
</li>
</ol>
<p>池化操作在CNN中具有以下优势：</p>
<ul>
<li><p>减小特征图的空间尺寸，降低计算量和内存需求。</p>
</li>
<li><p>提取特征的局部不变性，使模型对目标在图像中的位置变化具有鲁棒性。</p>
</li>
<li><p>减少模型过拟合的风险，通过减少参数数量和引入局部平均化。</p>
</li>
</ul>
<p>池化层通常与卷积层交替使用，以构建深层次的卷积神经网络结构。它在图像分类、目标检测、图像分割等任务中广泛应用，并在提高模型性能和减少计算资源消耗方面发挥着重要作用。</p>
<h3 id="batch-size"><a href="#batch-size" class="headerlink" title="batch size"></a>batch size</h3><p>“batch size”（批大小）是指在一次训练迭代中同时输入模型的样本数量。批大小决定了在每一次参数更新时，模型所看到的样本数量。</p>
<p>理解批大小可以参考以下几点：</p>
<ol>
<li><p><strong>样本数量</strong>：批大小表示一次训练中同时处理的样本数量。例如，如果批大小为32，则在每次参数更新时，模型将同时处理32个样本。</p>
</li>
<li><p><strong>内存和计算效率</strong>：较大的批大小可以提高计算效率，因为同时处理多个样本可以充分利用并行计算的能力。然而，较大的批大小可能需要更多的内存存储模型的中间结果。</p>
</li>
<li><p><strong>梯度估计</strong>：在训练过程中，批大小还会影响对梯度的估计。较大的批大小可以提供更准确的梯度估计，因为它们包含了更多的样本信息。然而，较小的批大小可能导致模型收敛更快，因为它们更频繁地更新参数。</p>
</li>
<li><p><strong>泛化能力</strong>：较大的批大小可能会导致模型过度拟合训练数据，因为它们更倾向于记住样本特定的细节。较小的批大小可以提供更好的泛化能力，因为它们更强迫模型学习更一般化的特征。</p>
</li>
</ol>
<h3 id="epoch（时期）"><a href="#epoch（时期）" class="headerlink" title="epoch（时期）"></a>epoch（时期）</h3><pre><code>Epoch（时期）是指将整个训练数据集（包含多个批次）在模型中进行一次完整的训练。在一个epoch中，模型会对数据集中的每个样本都进行一次前向传播和反向传播，并根据损失函数计算的梯度来更新模型的参数。
</code></pre>
<p>训练过程通常涉及多个epoch，因为一次完整的训练可能不足以使模型达到最佳性能。通过进行多个epoch，模型可以多次观察和学习数据的不同方面，并逐渐改善其性能。每个epoch之间的样本顺序通常会被随机化，以避免模型对样本顺序的依赖。</p>
<h3 id="向前步骤"><a href="#向前步骤" class="headerlink" title="向前步骤"></a>向前步骤</h3><p><strong>向前步骤（Forward Propagation）</strong>：</p>
<ul>
<li><p>在向前步骤中，输入样本通过模型的前向计算过程，从输入层经过一系列的神经网络层传递，最终得到模型的输出预测结果。</p>
</li>
<li><p>在每一层中，通过对输入数据进行线性变换（加权和）和非线性变换（激活函数），将信息从前一层传递到后一层，直到到达输出层。</p>
</li>
<li><p>向前步骤的目的是计算出模型的预测结果，以便与真实标签进行比较，并计算出损失函数的值。</p>
</li>
</ul>
<h3 id="反向传播步骤"><a href="#反向传播步骤" class="headerlink" title="反向传播步骤"></a>反向传播步骤</h3><p><strong>反向传播步骤（Backpropagation）</strong>：</p>
<ul>
<li><p>在反向传播步骤中，根据向前步骤中计算得到的损失函数值，通过链式法则计算每个参数对损失的贡献度，并更新模型的参数。</p>
</li>
<li><p>反向传播通过对损失函数关于模型参数的偏导数进行计算，从输出层向输入层逐层传递，以确定每个参数的梯度。</p>
</li>
<li><p>梯度表示了损失函数对每个参数的变化率，利用梯度可以确定参数的更新方向和大小，以最小化损失函数</p>
</li>
</ul>
<h3 id="梯度的惩罚程度"><a href="#梯度的惩罚程度" class="headerlink" title="梯度的惩罚程度"></a>梯度的惩罚程度</h3><p>梯度的惩罚程度是指在计算梯度时对其进行的限制或惩罚的程度。在深度学习中，常用的梯度惩罚方法是通过添加正则化项或其他惩罚项来约束模型的参数更新。</p>
<h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>防止参数更新过大或过快，以避免模型的过拟合或不稳定情况。通过对梯度进行惩罚，可以限制参数更新的幅度，使其保持在合理的范围内。</p>
<p>梯度惩罚的程度可以通过调整惩罚项的权重或超参数来控制。增加梯度惩罚的程度意味着更强烈地限制梯度的大小或方向，从而减缓参数更新的速度。相反，减少梯度惩罚的程度会使梯度对参数更新的限制更加宽松。</p>
<p>惩罚程度的选择通常需要根据具体问题和数据集的特点进行调整。过强的梯度惩罚可能导致模型无法学习到有效的特征，而过弱的梯度惩罚可能导致模型过拟合或训练不稳定。因此，需要根据实际情况进行实验和调优，选择合适的梯度惩罚程度以获得最佳的模型性能。</p>
<h3 id="自动编码器"><a href="#自动编码器" class="headerlink" title="自动编码器"></a>自动编码器</h3><p>自动编码器（Autoencoder，AE）是一种无监督学习模型，用于学习数据的特征表示和压缩。它由编码器（Encoder）和解码器（Decoder）组成。</p>
<ol>
<li><p>欠完备自动编码器（Undercomplete Autoencoder）：<br> 欠完备自动编码器是指编码器的维度低于输入数据的维度。这种设置迫使模型学习数据的主要特征，因为编码器无法完全捕获原始数据的所有信息。通过限制编码器的容量，欠完备自动编码器可以捕捉数据中最显著的特征，从而实现特征选择和降维。</p>
</li>
<li><p>正则化自动编码器（Regularized Autoencoder）：<br> 正则化自动编码器通过在损失函数中引入额外的正则化项来约束模型的学习过程，以防止过拟合。常见的正则化方法包括L1正则化和L2正则化。L1正则化通过增加编码器的稀疏性，鼓励模型只使用输入数据的少数关键特征。L2正则化通过限制权重的大小，使模型对输入数据的小变化具有鲁棒性。</p>
</li>
<li><p>变分自动编码器（Variational Autoencoder，VAE）：<br> 变分自动编码器是一种生成性模型，与判别性模型（欠完备自动编码器和正则化自动编码器）不同，它可以生成新的数据样本。VAE通过在潜在空间中引入随机性，使得模型能够在潜在空间中进行随机采样，并通过解码器生成新的样本。在训练过程中，VAE通过最大化“证据下界”（evidence lower bound，ELBO）来优化模型参数，从而实现对潜在空间的建模。这使得VAE能够学习到数据的潜在分布，并通过从该分布中采样生成新的数据样本。</p>
</li>
</ol>
<h3 id="CIFAR-10-和-CIFAR-100"><a href="#CIFAR-10-和-CIFAR-100" class="headerlink" title="CIFAR-10 和 CIFAR-100"></a>CIFAR-10 和 CIFAR-100</h3><p>CIFAR<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E9%9B%86&spm=1001.2101.3001.7020">数据集</a>是 <a target="_blank" rel="noopener" href="http://groups.csail.mit.edu/vision/TinyImages/">Visual Dictionary (Teaching computers to recognize objects)</a> 的子集，由三个教授收集，主要来自google和各类搜索引擎的图片。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/disanda/article/details/90744243">cifar10和cifar100(简介&amp;可视化)_cifar10和cifar100区别-CSDN博客</a></p>
<h3 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Iron802/article/details/121826385">https://blog.csdn.net/Iron802/article/details/121826385</a></p>
<p>MNIST数据集是NIST（National Institute of Standards and Technology，美国国家标准与技术研究所）数据集的一个子集，MNIST 数据集可在 <a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 获取，主要包括四个文件：</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.520Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/675441597">2023年值得关注的十篇人工智能研究论文 - 知乎 (zhihu.com)</a></p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.519Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AI%20%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <table>
<thead>
<tr>
<th>数据集</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>密码</td>
<td><a target="_blank" rel="noopener" href="https://downloads.skullsecurity.org/passwords/">Index of &#x2F;passwords&#x2F; (skullsecurity.org)</a></td>
</tr>
<tr>
<td>WPA 密码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/berzerk0/Probable-Wordlists/tree/master/Real-Passwords/WPA-Length">https://github.com/berzerk0/Probable-Wordlists/tree/master/Real-Passwords/WPA-Length</a></td>
</tr>
<tr>
<td>密码</td>
<td><a target="_blank" rel="noopener" href="https://wiki.skullsecurity.org/index.php/Passwords">https://wiki.skullsecurity.org/index.php/Passwords</a></td>
</tr>
</tbody></table>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.519Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%95%B0%E6%8D%AE%E9%9B%86/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    



    <div class='text-center pagination'>
    <a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right"></i></a>
    </div>



    <div class="hidden">
        <!-- 加载文章阅读对应的统计功能，评论自带的那种 -->
        
    </div>



        

            </section>

        

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
        <div class="sticky-area">
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/avatar.webp" loading="lazy" decoding="auto" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center">生于尘埃，溺于人海，死于理想的高台</p>
    </div>
    <div class="site-meta">
        <a class="meta-item" href="/archives/">
            <span class="title">
                文章
            </span>
            <span class="count">
                98
            </span>
        </a>
        <a class="meta-item" href="/categories/">
            <span class="title">
                分类
            </span>
            <span class="count">
                0
            </span>
        </a>
        <a class="meta-item" href="/tags/">
            <span class="title">
                标签
            </span>
            <span class="count">
                1
            </span>
        </a>
    </div>
</aside>
            
                

            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>标签聚合</h4>
      <div class="tag-clouds">
        <a href="/tags/excalidraw/" style="font-size: 0.6em;">excalidraw</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>最新文章</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/2024/04/23/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D/"><i class="fa  fa-book"></i> Englislearning</a>
            
          
        
          
          
            <a class="list-group-item" href="/2024/04/23/hello-world/"><i class="fa  fa-book"></i> Hello Worldaaaaaaa</a>
            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        <!-- Keep for compatibility -->
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <!-- New links -->
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2024 心咖 版权所有.</li>
                            <li>本站已运行<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by dreamin.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.io" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="/vendors/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="/vendors/nprogress@0.2.0/nprogress.js"></script>
<script>
    if (!window.kr) {
        window.kr = {};
    }
    window.kr.notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));
    window.kr.siteRoot = "/";
</script>


    <script async src="/js/candy.min.js"></script>



    <script defer src="/vendors/aplayer@1.10.1/dist/APlayer.min.js"></script>
    
    <script defer src="/vendors/meting@2.0.1/dist/Meting.min.js"></script>
    <meting-js
        server="netease"
        type="playlist"
        id="3204190542"
        order="random"
        fixed="true"
    >
    </meting-js>



    <script defer src="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>



<!-- Extra support for third-party plguins  -->


    </body>
</html>