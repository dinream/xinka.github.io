<!DOCTYPE html>
<html lang="en">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  
  <meta name="author" content="John Doe" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="" />
  
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/page/5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" media="all"></script>
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-color-dark.min.css" media="(prefers-color-scheme: dark)"></script>
    <script src="/js/kr-dark.min.js"></script>
  
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/night-eighties.min.css" media="all"></script>
  
  <link rel="stylesheet" id="fontawe-css" href="/vendors/font-awesome@4.7.0/css/font-awesome.min.css" media="all"></script>
  <link rel="stylesheet" id="nprogress-css" href="/vendors/nprogress@0.2.0/nprogress.css" media="all"></script>
  
  
    <link rel="stylesheet" href="/vendors/aplayer@1.10.1/dist/APlayer.min.css"></script>
  
  
    <link rel="stylesheet" href="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"></script>
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="/vendors/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="/vendors/qrcode_js@1.0.0/qrcode.min.js"></script>
  
  
  <style>
    
    
  </style>
  
<meta name="generator" content="Hexo 7.2.0"></head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">Hexo</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>Hexo</h2> <br />
                        <span></span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        

            <section class="col-md-8">

        

            <!-- Breadcrumb for tag & category page -->




    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <table>
<thead>
<tr>
<th>数据集</th>
<th>网址</th>
</tr>
</thead>
<tbody><tr>
<td>密码</td>
<td><a target="_blank" rel="noopener" href="https://downloads.skullsecurity.org/passwords/">Index of &#x2F;passwords&#x2F; (skullsecurity.org)</a></td>
</tr>
<tr>
<td>WPA 密码</td>
<td><a target="_blank" rel="noopener" href="https://github.com/berzerk0/Probable-Wordlists/tree/master/Real-Passwords/WPA-Length">https://github.com/berzerk0/Probable-Wordlists/tree/master/Real-Passwords/WPA-Length</a></td>
</tr>
<tr>
<td>密码</td>
<td><a target="_blank" rel="noopener" href="https://wiki.skullsecurity.org/index.php/Passwords">https://wiki.skullsecurity.org/index.php/Passwords</a></td>
</tr>
</tbody></table>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%95%B0%E6%8D%AE%E9%9B%86/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h2 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h2><p><a target="_blank" rel="noopener" href="https://0809zheng.github.io/2020/04/24/self-attention.html">https://0809zheng.github.io/2020/04/24/self-attention.html</a></p>
<p>TODO</p>
<p>下面是关于NLP中常用的一些知识的简要说明：</p>
<ol>
<li><p>Attention（注意力机制）： Attention是一种<strong>用于提升神经网络模型性能的机制</strong>，特别是在序列任务中。它允许<strong>模型在处理输入序列时将重点放在相关的部分上。</strong>通过计算每个输入位置的权重，模型可以自适应地决定要关注哪些部分。注意力机制在机器翻译、文本摘要、问答系统等任务中得到广泛应用。</p>
</li>
<li><p>Transformer（变换器）： Transformer是一种基于注意力机制的神经网络架构，用于处理序列数据。它在自然语言处理任务中取得了重大突破，并成为许多最先进的模型的基础。Transformer通过自注意力机制（self-attention）来捕捉输入序列中的依赖关系，避免了传统循环神经网络中的顺序计算，并且能够并行处理输入。Transformer的典型应用包括机器翻译（如Google的Transformer模型）和语言模型。</p>
</li>
<li><p>BERT（Bidirectional Encoder Representations from Transformers）： BERT是一种预训练的语言表示模型，基于Transformer架构。通过在大规模文本数据上进行无监督的预训练，BERT可以学习出通用的语言表示，然后可以在各种下游任务上进行微调。BERT引入了掩码语言模型（Masked Language Model, MLM）和下一句预测（Next Sentence Prediction, NSP）等任务来训练模型。BERT的出现对各种NLP任务，如文本分类、命名实体识别、问答系统等都产生了显著影响。</p>
</li>
<li><p>GPT（Generative Pre-trained Transformer）： GPT是一种基于Transformer架构的预训练语言模型，用于生成文本。GPT通过在大规模文本数据上进行自监督的预训练，学习出对输入序列的概率分布建模能力。然后，可以使用该模型生成具有连贯性和语法正确性的文本。GPT模型在生成式任务中表现出色，如文本生成、对话系统、机器写作等。</p>
</li>
<li><p>Prompt（提示）： Prompt是指在进行自然语言处理任务时，向模型提供一种任务描述或问题陈述的方式。通过给定一个显式的提示文本，模型可以更好地理解任务需求和上下文，从而产生更准确的输出。Prompt工程化是近年来在NLP任务中的一种重要技术，它可以帮助改进模型的可控性、减少模型的偏见，并提高模型的性能。</p>
</li>
</ol>
<p>下面是这些概念之间的关系：</p>
<ol>
<li><p>Attention（注意力机制）是Transformer（变换器）模型的核心组件之一。Transformer通过自注意力机制实现了对输入序列的建模，其中每个位置可以根据其与其他位置的相关性来调整其重要性。</p>
</li>
<li><p>Transformer是一种神经网络架构，被广泛用于自然语言处理任务。它的设计中包含了多头注意力机制，可以同时关注不同位置的不同方面。Transformer的出现使得处理长序列数据变得更加高效，并在机器翻译、文本生成等任务中取得了显著的性能提升。</p>
</li>
<li><p>BERT（Bidirectional Encoder Representations from Transformers）是基于Transformer的预训练语言模型。它通过大规模的无监督预训练，在理解上下文和建模语言表示方面取得了巨大成功。BERT的预训练模型可以通过微调适应各种下游任务，如文本分类、命名实体识别等。</p>
</li>
<li><p>GPT（Generative Pre-trained Transformer）也是基于Transformer的预训练语言模型，但其目标是生成连贯的文本。GPT通过自监督学习来提前训练一个语言模型，然后可以用于生成各种文本，如文章、对话等。GPT模型在生成式任务中表现出色，可以产生具有语法正确性和连贯性的文本。</p>
</li>
<li><p>Prompt（提示）是在进行NLP任务时向模型提供任务描述或问题陈述的方式。Prompt的引入主要是为了改进模型的可控性和减少模型的偏见。通过设计合适的提示文本，可以引导模型在特定任务上产生更准确、更符合预期的输出。</p>
</li>
</ol>
<p>总体而言，Attention是一种机制，Transformer是一种基于Attention的网络架构，BERT和GPT是基于Transformer的预训练语言模型，而Prompt是一种用于指导模型输出的技术手段。它们在NLP领域中相互关联，相互借鉴，共同推动了自然语言处理技术的发展。</p>
<h2 id="深度卷积神经网络"><a href="#深度卷积神经网络" class="headerlink" title="深度卷积神经网络"></a>深度卷积神经网络</h2><p>至少在网络的一层中使用卷积运算来代替一般的矩阵乘法运算的神经网络，因此命名为卷积神经网络</p>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\b98e8b23b2eec30346b082aa1fbca27ca8c377ab.png@1256w_712h_!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<h3 id="卷积核"><a href="#卷积核" class="headerlink" title="卷积核"></a>卷积核</h3><p>卷积核（kernel） ，一个权重矩阵，逐步在二维输入数据上“扫描”，卷积核“滑动”的同时，计算权重矩阵和扫描所得的数据矩阵的乘积，然后把结果汇总成一个输出像素。</p>
<p><strong>大小一般为奇数：</strong>原因</p>
<ol>
<li><p>更容易 padding，计算结果为整数</p>
</li>
<li><p>使用奇数大小的卷积核还可以保持对称性。对称性在卷积操作中是重要的，因为它可以确保输出特征图的空间分辨率与输入特征图相同。如果使用偶数大小的卷积核，由于缺少中心像素，可能会导致输出特征图的空间分辨率减小。</p>
</li>
<li><p>在CNN中，进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。 卷积核大小为奇数时，它具有一个中心元素，这使得在进行卷积操作时，可以确保输入图像的每个像素都有对应的卷积核元素与之对齐。这种中心对齐的特性有助于提取局部特征，同时减少了信息丢失的可能性。</p>
</li>
</ol>
<h3 id="卷积（Convolution）"><a href="#卷积（Convolution）" class="headerlink" title="卷积（Convolution）"></a>卷积（Convolution）</h3><p>所谓的卷积运算，其实它被称为<strong>互相关（cross-correlation）运算：</strong>将图像矩阵中，从左到右，由上到下，取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，最后的结果组成一个矩阵，其中没有对核进行翻转。</p>
<blockquote>
<p>数学上，给定两个函数 f(x) 和 g(x) 的卷积运算表示为：</p>
<p>(f * g)(x) &#x3D; ∫[−∞,∞] f(t)g(x−t) dt</p>
<p>对于每一个 x 得到的值 是 g 在 x 偏移 t 处 的值乘以 f(t) (权重) 的累加值，</p>
</blockquote>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\d646245dc94d4788dc48d0fcf6cd358f9d29f2c6.gif@1256w_1334h_!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<p><strong>核心操作，用于提取特征</strong></p>
<p>卷积运算具有一些重要的性质，例如交换律、结合律和分配律。</p>
<p>深度学习里面所谓的卷积运算，其实它被称为<strong>互相关（cross-correlation）运算：</strong>将图像矩阵中，从左到右，由上到下，取与滤波器同等大小的一部分（f(x-t)），每一部分中的值与滤波器中的值（g(t)）对应相乘后求和，最后的结果组成一个矩阵，其中没有对核进行翻转。</p>
<h3 id="填充（Padding）"><a href="#填充（Padding）" class="headerlink" title="填充（Padding）"></a>填充（Padding）</h3><p><strong>避免信息损失</strong></p>
<p>输入图像与卷积核进行卷积后的结果中损失了部分值，输入图像的边缘被“修剪”掉了（边缘处只检测了部分像素点，丢失了图片边界处的众多信息）。这是因为边缘上的像素永远不会位于卷积核中心，而卷积核也没法扩展到边缘区域以外。</p>
<p>这个结果我们是不能接受的，有时我们还希望输入和输出的大小应该保持一致。为解决这个问题，可以在进行卷积操作前，对原矩阵进行边界<strong>填充（Padding）</strong>，也就是在矩阵的边界上填充一些值，以增加矩阵的大小，通常都用“”来进行填充的。</p>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\c883f882924c3bfe1784b2a8b1c507c3dbe42963.gif@1256w_1428h_!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<p>通过填充的方法，当卷积核扫描输入数据时，它能延伸到边缘以外的伪像素，从而使输出和输入size相同。</p>
<p>常用的两种padding：</p>
<p>（1）valid padding：不进行任何处理，只使用原始图像，不允许卷积核超出原始图像边界</p>
<p>（2）same padding：进行填充，允许卷积核超出原始图像边界，并使得卷积后结果的大小与原来的一致 作者：2kb的卷心菜 <a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv16432604/">https://www.bilibili.com/read/cv16432604/</a> 出处：bilibili</p>
<h3 id="步长-Stride"><a href="#步长-Stride" class="headerlink" title="步长(Stride)"></a>步长(Stride)</h3><p><strong>压缩一部分信息，或者使输出的尺寸小于输入的尺寸</strong></p>
<p><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1781826967010713030&wfr=spider&for=pc">每天五分钟计算机视觉：卷积步长(Stride) (baidu.com)</a></p>
<p><strong>滑动卷积核时</strong>，我们会先从输入的左上角开始，每次往左滑动一列或者往下滑动一行逐一计算输出，我们将<strong>每次滑动的行数和列数</strong>称为Stride，在之前的图片中，Stride&#x3D;1；在下图中，Stride&#x3D;2。</p>
<p><img src="file://D:\Users\fyn\Documents\Note\Typora%E5%AD%97%E5%85%B8%E7%94%9F%E6%88%90%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.assets\af6e5cdf758fc9f2b6ba30235eae9e1c8128576b.gif@!web-article-pic.webp?lastModify=1708588580" alt="img"></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/read/cv16432604/">https://www.bilibili.com/read/cv16432604/</a> 出处：bilibili-2kb的卷心菜</p>
<h3 id="通道"><a href="#通道" class="headerlink" title="通道"></a>通道</h3><p>比如 RGB 有 红绿蓝三个 通道</p>
<p>这里就要涉及到“卷积核”和“filter”这两个术语的区别。在只有一个通道的情况下，“卷积核”就相当于“filter”，这两个概念是可以互换的。但在一般情况下，它们是两个完全不同的概念。每个“filter”实际上恰好是“卷积核”的一个集合，在当前层，每个通道都对应一个卷积核，且这个卷积核是独一无二的。</p>
<p><strong>多通道卷积的计算过程</strong>：将矩阵与滤波器对应的每一个通道进行卷积运算，最后相加，形成一个单通道输出，加上偏置项后，我们得到了一个最终的单通道输出。如果存在多个filter，这时我们可以把这些最终的单通道输出组合成一个总输出。</p>
<p><strong>某一层输出特征图的通道数</strong>&#x3D;当前层滤波器的个数。如上图所示，当只有一个filter时，输出特征图（4×4）的通道数为1；当有2个filter时，输出特征图（4×4×2）的通道数为2。</p>
<h3 id="降采样"><a href="#降采样" class="headerlink" title="降采样"></a>降采样</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46633171">https://zhuanlan.zhihu.com/p/46633171</a></p>
<p>概念：降采样指的是成比例缩小特征图宽和高的过程</p>
<p>例子：比如从（W，H）变为（W&#x2F;2，H&#x2F;2）</p>
<p>方法：</p>
<ol>
<li><p>stride 大于 1 的 pooling</p>
</li>
<li><p>stride 大于 1 的 conv</p>
</li>
<li><p>stride 大于 1 的 reorg（在<a href="https://link.zhihu.com/?target=https://arxiv.org/pdf/1612.08242.pdf">YOLOv2的论文</a>里叫passthrough layer）</p>
</li>
</ol>
<p>比较：</p>
<ol>
<li><p>1 和 2 在深度卷积神经网络中使用非常普遍，3 比较小众，由Joseph Redmon在YOLOv2中首次提出。</p>
</li>
<li><p>1 和 2 的对比在<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1412.6806">Striving for Simplicity: The All Convolutional Net</a>中有详述</p>
<p> 用stride&#x3D;2的conv降采样的卷积神经网络效果与使用pooling降采样的卷积神经网络效果相当；<strong>卷积神经网络小的时候，使用pooling降采样效果可能更好</strong>，卷积神经网络大的时候，使用stride&#x3D;2的conv降采样效果可能更好。</p>
<p> pooling提供了一种非线性，这种非线性需要较深的conv叠加才能实现，因此当网络比较浅的时候，pooling有一定优势；但是当网络很深的时候，多层叠加的conv可以学到pooling所能提供的非线性，甚至能根据训练集学到比pooling更好的非线性，因此当网络比较深的时候，不使用pooling没多大关系，甚至更好。</p>
<p> pooling的非线性是固定的，不可学习的，这种非线性其实就是一种先验。</p>
</li>
<li><p>3 中降采样的优势在于能够较好的保留低层次的信息。<strong>1 和 2 的降采样方式，好处是抽取的特征具有更强的语义性，坏处是会丢失一些细节信息</strong>。而3这种降采样方式与1、2相反，<strong>3 提取的特征语义性不强，但是能保留大量细节信息</strong>。所以当我们既需要降采样，又需要不丢失细节信息的时候，3是一个非常合适的选择。</p>
</li>
</ol>
<h3 id="升采样"><a href="#升采样" class="headerlink" title="升采样"></a>升采样</h3><p><strong>将输入特征图的尺寸放大或增加分辨率。</strong></p>
<p>通常与卷积和池化等操作结合使用，用于逆向传播梯度、特征图的恢复或生成更高分辨率的输出。</p>
<p>基本目标是增加特征图的空间尺寸，以便更好地捕获细节信息、提高特征的表达能力或生成更高分辨率的输出。</p>
<p>方法：</p>
<ol>
<li><p>反卷积（Transpose Convolution）：反卷积是一种常见的升采样方式，也称为转置卷积、分数步长卷积。它通过在<strong>输入特征图之间插入零值</strong>，并<strong>使用带有适当步长的卷积核进行卷积操作来放大特征图的尺寸</strong>。反卷积操作可以增加特征图的空间尺寸，并在某种程度上恢复输入特征图的细节。</p>
</li>
<li><p>双线性插值（Bilinear Interpolation）：双线性插值是一种基于插值的升采样方法，通过<strong>对输入特征图中的每个像素进行插值计算来生成更大尺寸的特征图。</strong>它使用<strong>周围四个像素的权重进行插值，保持了图像的平滑性和连续性</strong>。</p>
</li>
<li><p>最近邻插值（Nearest Neighbor Interpolation）：最近邻插值是一种简单的升采样方法，它将输入特征图中每个像素的值复制到放大后的特征图的相应位置。它在放大时<strong>不进行插值计算，而是直接使用最近邻像素的值</strong>。这种方法简单高效，但可能<strong>会导致输出特征图的锯齿状边缘</strong>。</p>
</li>
<li><p>其他一些升采样技术，如子像素卷积（Subpixel Convolution）、转置卷积的变种（如反池化操作）、像素重排（Pixel Shuffle）等。这些方法在不同的应用场景中具有各自的优势和适用性。</p>
</li>
</ol>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>是一种常用的操作层，用于减小特征图的空间尺寸、降低计算量，并增强模型的平移不变性。输入特征图的局部区域进行聚合或采样来生成池化特征图。</p>
<p>池化操作：通常在每个输入特征图的局部区域上应用，通过对区域内的特征进行聚合或采样，生成一个单一的值或特征。这个聚合或采样过程可以是简单的求最大值（最大池化，Max Pooling）或求平均值（平均池化，Average Pooling），也可以是其他聚合方式，如Lp范数池化。</p>
<p>在池化操作中，可以通过调整池化窗口的大小和步幅来控制输出特征图的大小和感受野。池化窗口是应用池化操作的局部区域的大小，<strong>步幅</strong>是<strong>池化窗口</strong>在输入特征图上移动的距离。</p>
<p>常见的池化操作及其特点：</p>
<ol>
<li><p>最大池化（Max Pooling）：在池化窗口内选择最大值作为池化特征。最大池化有助于保留显著的特征，提高模型的平移不变性和鲁棒性。</p>
</li>
<li><p>平均池化（Average Pooling）：在池化窗口内求特征的平均值作为池化特征。平均池化可以减少特征图的空间维度，并平滑特征。</p>
</li>
<li><p>Lp范数池化（Lp-norm Pooling）：在池化窗口内对特征进行Lp范数归一化，得到池化特征。Lp范数池化可以对特征进行归一化，并引入更多非线性。</p>
</li>
</ol>
<p>池化操作在CNN中具有以下优势：</p>
<ul>
<li><p>减小特征图的空间尺寸，降低计算量和内存需求。</p>
</li>
<li><p>提取特征的局部不变性，使模型对目标在图像中的位置变化具有鲁棒性。</p>
</li>
<li><p>减少模型过拟合的风险，通过减少参数数量和引入局部平均化。</p>
</li>
</ul>
<p>池化层通常与卷积层交替使用，以构建深层次的卷积神经网络结构。它在图像分类、目标检测、图像分割等任务中广泛应用，并在提高模型性能和减少计算资源消耗方面发挥着重要作用。</p>
<h3 id="batch-size"><a href="#batch-size" class="headerlink" title="batch size"></a>batch size</h3><p>“batch size”（批大小）是指在一次训练迭代中同时输入模型的样本数量。批大小决定了在每一次参数更新时，模型所看到的样本数量。</p>
<p>理解批大小可以参考以下几点：</p>
<ol>
<li><p><strong>样本数量</strong>：批大小表示一次训练中同时处理的样本数量。例如，如果批大小为32，则在每次参数更新时，模型将同时处理32个样本。</p>
</li>
<li><p><strong>内存和计算效率</strong>：较大的批大小可以提高计算效率，因为同时处理多个样本可以充分利用并行计算的能力。然而，较大的批大小可能需要更多的内存存储模型的中间结果。</p>
</li>
<li><p><strong>梯度估计</strong>：在训练过程中，批大小还会影响对梯度的估计。较大的批大小可以提供更准确的梯度估计，因为它们包含了更多的样本信息。然而，较小的批大小可能导致模型收敛更快，因为它们更频繁地更新参数。</p>
</li>
<li><p><strong>泛化能力</strong>：较大的批大小可能会导致模型过度拟合训练数据，因为它们更倾向于记住样本特定的细节。较小的批大小可以提供更好的泛化能力，因为它们更强迫模型学习更一般化的特征。</p>
</li>
</ol>
<h3 id="epoch（时期）"><a href="#epoch（时期）" class="headerlink" title="epoch（时期）"></a>epoch（时期）</h3><pre><code>Epoch（时期）是指将整个训练数据集（包含多个批次）在模型中进行一次完整的训练。在一个epoch中，模型会对数据集中的每个样本都进行一次前向传播和反向传播，并根据损失函数计算的梯度来更新模型的参数。
</code></pre>
<p>训练过程通常涉及多个epoch，因为一次完整的训练可能不足以使模型达到最佳性能。通过进行多个epoch，模型可以多次观察和学习数据的不同方面，并逐渐改善其性能。每个epoch之间的样本顺序通常会被随机化，以避免模型对样本顺序的依赖。</p>
<h3 id="向前步骤"><a href="#向前步骤" class="headerlink" title="向前步骤"></a>向前步骤</h3><p><strong>向前步骤（Forward Propagation）</strong>：</p>
<ul>
<li><p>在向前步骤中，输入样本通过模型的前向计算过程，从输入层经过一系列的神经网络层传递，最终得到模型的输出预测结果。</p>
</li>
<li><p>在每一层中，通过对输入数据进行线性变换（加权和）和非线性变换（激活函数），将信息从前一层传递到后一层，直到到达输出层。</p>
</li>
<li><p>向前步骤的目的是计算出模型的预测结果，以便与真实标签进行比较，并计算出损失函数的值。</p>
</li>
</ul>
<h3 id="反向传播步骤"><a href="#反向传播步骤" class="headerlink" title="反向传播步骤"></a>反向传播步骤</h3><p><strong>反向传播步骤（Backpropagation）</strong>：</p>
<ul>
<li><p>在反向传播步骤中，根据向前步骤中计算得到的损失函数值，通过链式法则计算每个参数对损失的贡献度，并更新模型的参数。</p>
</li>
<li><p>反向传播通过对损失函数关于模型参数的偏导数进行计算，从输出层向输入层逐层传递，以确定每个参数的梯度。</p>
</li>
<li><p>梯度表示了损失函数对每个参数的变化率，利用梯度可以确定参数的更新方向和大小，以最小化损失函数</p>
</li>
</ul>
<h3 id="梯度的惩罚程度"><a href="#梯度的惩罚程度" class="headerlink" title="梯度的惩罚程度"></a>梯度的惩罚程度</h3><p>梯度的惩罚程度是指在计算梯度时对其进行的限制或惩罚的程度。在深度学习中，常用的梯度惩罚方法是通过添加正则化项或其他惩罚项来约束模型的参数更新。</p>
<h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>防止参数更新过大或过快，以避免模型的过拟合或不稳定情况。通过对梯度进行惩罚，可以限制参数更新的幅度，使其保持在合理的范围内。</p>
<p>梯度惩罚的程度可以通过调整惩罚项的权重或超参数来控制。增加梯度惩罚的程度意味着更强烈地限制梯度的大小或方向，从而减缓参数更新的速度。相反，减少梯度惩罚的程度会使梯度对参数更新的限制更加宽松。</p>
<p>惩罚程度的选择通常需要根据具体问题和数据集的特点进行调整。过强的梯度惩罚可能导致模型无法学习到有效的特征，而过弱的梯度惩罚可能导致模型过拟合或训练不稳定。因此，需要根据实际情况进行实验和调优，选择合适的梯度惩罚程度以获得最佳的模型性能。</p>
<h3 id="自动编码器"><a href="#自动编码器" class="headerlink" title="自动编码器"></a>自动编码器</h3><p>自动编码器（Autoencoder，AE）是一种无监督学习模型，用于学习数据的特征表示和压缩。它由编码器（Encoder）和解码器（Decoder）组成。</p>
<ol>
<li><p>欠完备自动编码器（Undercomplete Autoencoder）：<br> 欠完备自动编码器是指编码器的维度低于输入数据的维度。这种设置迫使模型学习数据的主要特征，因为编码器无法完全捕获原始数据的所有信息。通过限制编码器的容量，欠完备自动编码器可以捕捉数据中最显著的特征，从而实现特征选择和降维。</p>
</li>
<li><p>正则化自动编码器（Regularized Autoencoder）：<br> 正则化自动编码器通过在损失函数中引入额外的正则化项来约束模型的学习过程，以防止过拟合。常见的正则化方法包括L1正则化和L2正则化。L1正则化通过增加编码器的稀疏性，鼓励模型只使用输入数据的少数关键特征。L2正则化通过限制权重的大小，使模型对输入数据的小变化具有鲁棒性。</p>
</li>
<li><p>变分自动编码器（Variational Autoencoder，VAE）：<br> 变分自动编码器是一种生成性模型，与判别性模型（欠完备自动编码器和正则化自动编码器）不同，它可以生成新的数据样本。VAE通过在潜在空间中引入随机性，使得模型能够在潜在空间中进行随机采样，并通过解码器生成新的样本。在训练过程中，VAE通过最大化“证据下界”（evidence lower bound，ELBO）来优化模型参数，从而实现对潜在空间的建模。这使得VAE能够学习到数据的潜在分布，并通过从该分布中采样生成新的数据样本。</p>
</li>
</ol>
<h3 id="CIFAR-10-和-CIFAR-100"><a href="#CIFAR-10-和-CIFAR-100" class="headerlink" title="CIFAR-10 和 CIFAR-100"></a>CIFAR-10 和 CIFAR-100</h3><p>CIFAR<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E9%9B%86&spm=1001.2101.3001.7020">数据集</a>是 <a target="_blank" rel="noopener" href="http://groups.csail.mit.edu/vision/TinyImages/">Visual Dictionary (Teaching computers to recognize objects)</a> 的子集，由三个教授收集，主要来自google和各类搜索引擎的图片。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/disanda/article/details/90744243">cifar10和cifar100(简介&amp;可视化)_cifar10和cifar100区别-CSDN博客</a></p>
<h3 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Iron802/article/details/121826385">https://blog.csdn.net/Iron802/article/details/121826385</a></p>
<p>MNIST数据集是NIST（National Institute of Standards and Technology，美国国家标准与技术研究所）数据集的一个子集，MNIST 数据集可在 <a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a> 获取，主要包括四个文件：</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h3 id="监督学习与无监督学习"><a href="#监督学习与无监督学习" class="headerlink" title="监督学习与无监督学习"></a>监督学习与无监督学习</h3><h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><p>任务：学习一个映射函数，给定任意输入响应做一个好的预测输出。<br>本质：学习输入到输出的映射的统计规律。<br>常见情景：回归，分类，标注。（区别在于变量的取值类型）<br>（1）当输入变量和输出变量均为连续值变量时得到回归任务，它主要用于学习输入变量和输出变量之间的数值映射关系，常见的回归任务有价格预测、趋势预测等，处理回归任务时常用的机器学习模型有最小二乘回归、非线性回归等。<br>（2）无论其输入变量为离散值还是连续值，当输出变量为有限个离散值时得到分类任务，分类任务是被人们讨论和应用最广泛的任务，它通常用于分门别类，常见的分类任务有图片类别识别、用户分类、文本分类等，处理分类任务时常用的机器学习模型有：k近邻、朴素贝叶斯、决策树、逻辑斯蒂回归模型、支持向量机、神经网络等。<br>（3）当输入变量和输出变量均为变量序列时得到标注任务，它是分类问题的一种推广，用于学习输入序列和输出序列的映射关系，典型的标注任务有自然语言处理中的词性标注、信息抽取等，处理标注任务时常用的机器学习模型有隐马尔科夫模型和条件随机场等</p>
<h5 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h5><p>监督学习是学习一个模型，然后利用该模型对给定的输入预测相应的输出，我们可将模型写成函数形式 Y&#x3D;f(X) 或条件概率分布形式 P(Y|X) 。</p>
<h6 id="判别模型-生成模型：根据条件概率的计算方式"><a href="#判别模型-生成模型：根据条件概率的计算方式" class="headerlink" title="判别模型&amp;生成模型：根据条件概率的计算方式"></a>判别模型&amp;生成模型：根据条件概率的计算方式</h6><ol>
<li>[[判别模型]]<ol>
<li>建模方式：直接对 P(Y|X)  进行建模，它试图描述在给定输入特征 X 的情况下，标签信息 Y 的分布，</li>
<li>典型判别模型包括： 近邻法、感知机、决策树、逻辑回归和条件随机场等。</li>
<li>评价：判别模型对条件概率模型直接建模，无法反映训练数据本身的概率特性，但是以分类问题为例，判别模型在寻找最优分类面的过程中，学习了不同类别数据之间的差异。另外，判别模型可以对数据进行各种程度上的抽象、降维，因此可以简化学习问题，学习准确率更高。</li>
</ol>
</li>
<li>[[生成模型]]<ol>
<li>对数据特征 X 和标签 Y 的联合分布 p(X,Y) 进行建模，然后利用条件概率公式，即可计算 p(Y|X) ，如下所示:<br> $p(Y|X) &#x3D; \frac {p(X,Y)}{p(X)}$<br> 一般将其转换为易为计算的方式，如下所示<br> $p(Y|X) &#x3D; \frac {p(X|Y)*p(Y)}{p(X)}$</li>
<li>举例：朴素贝叶斯方法和隐马尔科夫模型等。<ol>
<li>在朴素贝叶斯方法中，我们通过训练集学习到先验概率分布 p(Y) 和条件概率分布 p(Y|X)，则可得到联合概率分布 p(X,Y)；</li>
<li>隐马尔可夫模型中，我们通过训练集学习到初始概率分布、状态转移概率矩阵和观测概率矩阵，则得到了一个可以表示状态序列与观测序列联合分布的马尔可夫模型。</li>
</ol>
</li>
<li>评价：生成模型直接学习联合分布，可以更好地表示数据的分布，更好反映同类数据的相似度。当样本数量比较大时，生成模型往往可以更好地收敛到真实模型上，其收敛速度快。另外，生成模型可以处理含有隐变量的情况，而判别模型对此无能为力。生成模型也可以通过计算边缘分布而检测某些异常值。但实践中，生成模型计算开销一般比较大，而且多数情况下其效果不如判别模型。</li>
</ol>
</li>
</ol>
<h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><p>和监督学习比较：</p>
<ol>
<li>无监督学习和监督学习最大的区别就是标签的有无。在监督学习中，训练模型的任务是学习输入特征到标签的映射，</li>
<li>而无监督学习中只有样本的特征向量，故无监督学习的任务是对数据进行深入“挖掘”，其本质是学习数据中的统计规律或潜在结构。对于无监督学习的深入研究对深度学习的复兴上起到了关键的作用。</li>
<li>相比于无监督学习除了拥有额外的标签信息外，还需要有测试样本。机器学习模型在训练集中学习“规律”，然后对测试集使用这种“规律”来评价模型的效果，而无监督学习不需要测试样本，整个过程只需要训练集的参与。</li>
<li>另外，无监督学习相比于监督学习一般拥有更好的拓展性，它在完成训练目标的同时，通常还额外学习到了样本的表示，我们可以将这些表示直接用于其他的任务。<br>常见任务：降维、聚类、概率模型估计。<br>（1）降维任务主要用于处理数据的高维度问题，真实数据的特征维度过大容易造成模型的拟合度与可用性降低，我们可以通过降维算法对高维度数据进行“压缩”使之变成低维度向量，从而提高数据的可用性，常用的算法有主成分分析、因子分析、隐含狄利克雷分布等，包括早期的自编码器也可用于数据降维。<br>（2）聚类任务主要将样本依据一定的规则进行类别分配，即通过衡量样本之间的距离、密度等指标，将关系“近”的样本聚为同一类，以此实现样本的自动分类，常用的算法有层次聚类、k-means聚类、谱聚类等。<br> （3）在概率模型估计任务中，对于一个可以生成样本的概率模型，我们使用样本对概率模型的结构、参数进行学习，使得概率模型生成的样本与训练样本最相似。其中一种比较简单的概率密度估计任务便是对随机变量的概率密度函数进行学习，常用的算法有极大似然估计、对抗生成网络、变分自编码器等，这部分内容非常丰富。</li>
</ol>
<h4 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h4><p> 半监督学习是介于监督学习和无监督学习的一种方式，即只有小部分训练样本带有标签信息，而大多数训练样本的标签信息空缺。半监督学习包括直推和归纳两类模式，直推半监督学习只对给定的训练数据进行处理，它使用训练数据集中有类别标签和无类别标签的样本进行训练，预测其中无标签样本的标签信息；归纳半监督学习不仅预测训练数据集中无标签样本的标签，更主要的是预测未知样本的标签，两者的区别在于需要预测标签的样本是否出现在训练集中。半监督学习一般用于四类学习场景：半监督分类、半监督回归、半监督聚类、半监督降维等。</p>
<h3 id="上下文无关语法"><a href="#上下文无关语法" class="headerlink" title="上下文无关语法"></a>上下文无关语法</h3><p>上下文无关语法（Context-Free Grammar）和概率上下文无关语法（Probabilistic Context-Free Grammar）的概念。</p>
<p>上下文无关语法是一种形式语言描述方法，用于定义一类语言的语法结构。它由一组产生式规则组成，每个规则包含一个非终结符和一个由非终结符和终结符组成的字符串。其中，α是一个单变量，表示非终结符，而β是由变量或最终值组成的字符串。这些产生式规则定义了从一个起始样本开始，通过替换非终结符，逐步生成包含所有最终值的字符串集合。上下文无关语法的特点是，无论α出现在哪个上下文中，都可以自由地用β替换，而不需要考虑α的上下文。</p>
<p>概率上下文无关语法是在上下文无关语法的基础上引入了概率特性。每个产生式规则都被赋予一个概率值，表示该规则被应用的概率。这样，概率上下文无关语法可以用于建模具有统计特性的语言。例如，在自然语言处理中，可以使用概率上下文无关语法来生成句子或解析句子的结构，并为每个规则分配适当的概率。</p>
<p>总结来说，上下文无关语法是一种用于描述语言的语法结构的方法，其中产生式规则定义了从起始样本开始生成所有最终值的字符串。概率上下文无关语法在上下文无关语法的基础上引入了概率特性，使其适用于建模具有统计特性的语言。</p>
<h3 id="多视图学习"><a href="#多视图学习" class="headerlink" title="多视图学习"></a>多视图学习</h3><p>多视图学习（Multi-view Learning）是一种机器学习方法，旨在利用来自多个视图或多个特征表示的数据来改善学习性能。在多视图学习中，数据样本可以从不同的视角或特征空间中获取多个不同的表示。通过综合这些多个视图的信息，多视图学习可以提供更全面和准确的数据描述，从而改善模型的泛化能力和学习结果。</p>
<p>传统的机器学习方法通常假设数据特征是从单个视图或特征空间中提取的，因此忽略了不同视图之间的相关性和互补性。而多视图学习则通过融合多个视图的信息来克服这个限制。它可以应用于各种领域和任务，如模式识别、图像处理、文本分类、推荐系统等。</p>
<p>多视图学习的关键挑战是如何有效地利用不同视图之间的相关性。常见的多视图学习方法包括以下几种：</p>
<ol>
<li><p>基于特征融合的方法：将不同视图的特征进行融合，生成一个更综合和丰富的特征表示。常见的融合方法包括特征级融合、决策级融合和模型级融合等。</p>
</li>
<li><p>基于共享表示学习的方法：通过学习一个共享的低维表示空间，将不同视图的数据映射到该共享空间中。这样可以使不同视图之间的相关性更加明显，便于后续的学习和推理。</p>
</li>
<li><p>基于多示例学习的方法：将多个视图看作是一个示例的不同表示，通过多示例学习的方式来进行模型训练和预测。这种方法适用于存在不完全标注的数据集，其中每个示例可能有多个视图的表示。</p>
</li>
</ol>
<p>多视图学习方法可以提供更全面和准确的数据建模，从而改善学习性能。它可以利用不同视图的互补信息，提取更丰富的特征表示，并减少数据表示的不确定性。这使得多视图学习成为处理复杂数据和提高模型性能的有效工具。</p>
<h3 id="随机投影（SimHash）"><a href="#随机投影（SimHash）" class="headerlink" title="随机投影（SimHash）"></a>随机投影（SimHash）</h3><p>TODO：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/92155250">https://zhuanlan.zhihu.com/p/92155250</a></p>
<ol>
<li><p><strong>SimHash 算法</strong>：SimHash 是一种用于计算文本或数据的哈希值的算法。它的主要思想是将文本或数据转换为二进制向量，其中相似的文本或数据会产生相似的哈希值。这种相似性哈希算法被广泛应用于文本去重、相似文档聚类和相似性搜索等任务。</p>
</li>
<li><p><strong>随机投影</strong>：随机投影是一种降维技术，用于将高维数据映射到低维空间。在随机投影 SimHash 中，通过使用随机生成的投影矩阵将高维特征向量映射到低维二进制码。</p>
</li>
<li><p><strong>哈希函数</strong>：随机投影 SimHash 使用哈希函数来将投影后的低维向量转换为二进制码。常用的哈希函数是符号哈希函数，它根据投影后的特征向量的符号（正负）来决定对应二进制码的取值（0 或 1）。</p>
</li>
<li><p><strong>相似性匹配</strong>：通过计算 SimHash 值之间的汉明距离（Hamming Distance），可以判断文本或数据之间的相似性。汉明距离是指两个等长字符串之间相对位置不同的字符的个数。汉明距离越小，表示文本或数据之间越相似。</p>
</li>
</ol>
<h3 id="线性特征-非线性特征"><a href="#线性特征-非线性特征" class="headerlink" title="线性特征 &amp; 非线性特征"></a>线性特征 &amp; 非线性特征</h3><ol>
<li><p>线性特征：特征和目标的关系可以用一条直线来拟合。</p>
</li>
<li><p>非线性特征：特征和目标之间的关系不可以用一条直线来拟合</p>
</li>
</ol>
<h3 id="弱分类器-强分类器"><a href="#弱分类器-强分类器" class="headerlink" title="弱分类器 &amp; 强分类器"></a>弱分类器 &amp; 强分类器</h3><ol>
<li><p>弱分类器：准确率在 60% ~80%之间，即：比随即预测好，但是准确率不高。e.g. CART（分类与回归树）</p>
</li>
<li><p>强分类器：准确率在90%以上。</p>
</li>
</ol>
<h3 id="分类任务-回归任务"><a href="#分类任务-回归任务" class="headerlink" title="分类任务 &amp; 回归任务"></a>分类任务 &amp; 回归任务</h3><ol>
<li><p>分类任务（Classification）</p>
<ol>
<li><p>目标：将输入实例分配到预定义的类别中。</p>
</li>
<li><p>过程：模型通过学习输入特征与响应类别之间的关系，来预测新的未知示例所属类别。</p>
</li>
<li><p>输出：输出是离散的，通常是表示类别的标签或类别的概率分布。</p>
</li>
</ol>
</li>
<li><p>回归任务（Regression）</p>
<ol>
<li><p>目标：预测连续的数值输出。</p>
</li>
<li><p>过程：模型通过学习输入特征与响应输出值之间的关系，来预测新的未知示例的数值结果。</p>
</li>
<li><p>输出：这是一个连续的数值输出。</p>
</li>
</ol>
</li>
</ol>
<p>注意：有些机器学习算法可以同时用于分类和回归任务，例如决策树和支持向量机等。这些算法可以根据任务的要求进行适当的调整和配置。</p>
<h3 id="LR、DT、SVM的对比"><a href="#LR、DT、SVM的对比" class="headerlink" title="LR、DT、SVM的对比"></a>LR、DT、SVM的对比</h3><ol>
<li><p>所谓分类问题就是在特征空间内寻找决策边界线。而三种算法决定了生成的边界线的不同形状。</p>
</li>
<li><p>如何在多维特征空间中选择合适的算法：</p>
<ol>
<li><p>先选逻辑回归，如果效果不怎么样，可以将它的结果作为基准来参考</p>
</li>
<li><p>试试决策树（随机森林）是否可以大幅度提升模型性能。即使没有把它当作最终模型，也可以使用随机森林来移除噪声变量。</p>
</li>
<li><p>如果特征的数量和观测样本特别多，那么当资源和时间充足时，使用SVM不失为一种选择。</p>
</li>
</ol>
</li>
</ol>
<h3 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h3><ol>
<li><p>目的：解决分类问题。</p>
</li>
<li><p>核心：特征权重的线性组合、sigmoid 函数的计算和损失函数的最小化。</p>
</li>
<li><p>特点：逻辑回归的决策边界总是一条直线（或者一个平面，在更高维度上是超平面）。</p>
</li>
<li><p>优势：</p>
<ol>
<li><p>适用于处理接近线性可分的分类问题。</p>
</li>
<li><p>结果不是一个离散值或者确切的类别。而是一个与每个观测样本相关的概率列表，所以可以用不同的标准和常用的性能指标来分析这个概率分数，得到不同的分类结果。</p>
</li>
<li><p>时间和内存需求上相当高效。可以用于分布式数据，用较少的资源处理大型数据</p>
<blockquote>
<p>低内存消耗：逻辑回归模型只需要存储特征权重，而不需要存储大量的训练数据。相比之下，其他复杂的模型（如神经网络）可能需要存储大量的中间参数和计算图，导致更高的内存消耗。
 </p>
</blockquote>
</li>
<li><p>对数据中小噪声的棒鲁性很好。</p>
</li>
<li><p>逻辑回归广泛应用于工业问题上。</p>
</li>
</ol>
</li>
<li><p>地位：解决工业规模问题最流行的算法</p>
</li>
<li><p>缺点：</p>
<ol>
<li><p>在效率和算法实现的易用性方面并不出众。</p>
</li>
<li><p>当特征数目很大并且还丢失了大部分数据时，逻辑回归就会表现的力不从心。</p>
</li>
<li><p>当类别变量过多时也会力不从心</p>
</li>
<li><p>对于非线性特征，需要进行转换。</p>
</li>
<li><p>依赖于全部数据。</p>
</li>
</ol>
</li>
</ol>
<h3 id="决策树（Decisoin-Trees）"><a href="#决策树（Decisoin-Trees）" class="headerlink" title="决策树（Decisoin Trees）"></a>决策树（Decisoin Trees）</h3><ol>
<li><p>目的：解决分类问题 &amp; 逻辑回归问题。</p>
</li>
<li><p>结构：按照层次结构的规则生成的。</p>
</li>
<li><p>特性：对单向变换或者非线性特征并不关心。(不需要变换来捕获数据中的非线性相关性，可以用他的划分方式自适应处理非线性关系)。</p>
<blockquote>
<p>单向变换：如指数、对数变换。
 </p>
</blockquote>
</li>
<li><p>优势：如果边界是非线性的，并且能通过不断将特征空间分为矩形来模拟，那么决策树是比逻辑回归更好的选择。</p>
<ol>
<li><p>直观的决策规则；</p>
</li>
<li><p>可以处理非线性特征；</p>
</li>
<li><p>考虑了变量之间的相互作用；</p>
</li>
</ol>
</li>
<li><p>缺点：</p>
<ol>
<li><p>训练集上的效果高于测试集，即过拟合【随机森林克服了此缺点】；</p>
</li>
<li><p>没有将排名分数作为直接结果；</p>
</li>
</ol>
</li>
<li><p>针对离散数据的分类决策树</p>
<ol>
<li><p>定义：预测任务的输入和输出都是离散值</p>
</li>
<li><p>例子：ID3、C4.5</p>
</li>
<li><p>原始决策树：不断选择，优先选择信息熵最小的特征进行分组</p>
<blockquote>
<p>信息熵：越大，表示特征的信息量越大，越离散，按照这个特征分组之后，样本的混乱程度越大。e.g. 特征某个水平的值出现的概率与取对数的积和。
 </p>
</blockquote>
</li>
<li><p>ID3：使用信息增益来度量特征对分类的帮助大小</p>
<blockquote>
<p>信息增益：使用一个特征对数据进行分组之后各组样本的有序程度会更高，熵会降低，分组前后熵的差值就是这个特征带来的信息增益。信息增益越大，说明这个特征越有助于分组。分组之前算一次，分组之后算一次。
 </p>
</blockquote>
</li>
<li><p>C4.5 算法：在信息增益的基础上构造了一个新的特征质量度量指标：信息中增益比</p>
<blockquote>
<p>信息增益比：按照性别划分之后对成年的的信息增益&#x2F;分组之前对性别的信息增益</p>
</blockquote>
</li>
</ol>
</li>
</ol>
<h3 id="支持向量机（Support-Vector-Machine-SVM）"><a href="#支持向量机（Support-Vector-Machine-SVM）" class="headerlink" title="支持向量机（Support Vector Machine,SVM）"></a>支持向量机（Support Vector Machine,SVM）</h3><ol>
<li><p>目的：解决分类问题 &amp; 逻辑回归问题</p>
</li>
<li><p>特点：依靠边界样本来建立需要的分离曲线。它可以处理非线性决策边界。（对边界依赖）</p>
</li>
<li><p>结构：把特征空间映射到核空间，使得各个类别线性可分。把特征空间又增加一个维度。</p>
<blockquote>
<ol>
<li><p><strong>核函数</strong>：SVM使用核函数来将输入特征映射到高维特征空间，从而使得原本在低维空间中非线性可分的问题在高维空间中变得线性可分。核函数的作用是通过计算样本在高维空间中的内积来隐式地表示非线性特征之间的相互作用。常用的核函数包括多项式核函数、高斯核函数（径向基函数）等。</p>
</li>
<li><p><strong>大间隔原则</strong>：SVM的优化目标是找到一个最大间隔的超平面来划分不同类别的样本。通过最大化间隔，SVM能够在特征空间中找到一条边界，使得不同类别的样本尽可能分开。这种大间隔原则使得SVM对于非线性特征之间的相互作用更加鲁棒，能够更好地处理非线性关系。</p>
</li>
<li><p><strong>非线性核函数</strong>：除了线性核函数，SVM还可以使用非线性核函数，如多项式核函数和高斯核函数。这些核函数能够捕捉非线性特征之间的相互作用，将数据映射到高维特征空间中，并在高维空间中构建一个线性超平面来进行分类。这样，SVM能够处理非线性特征之间的相互作用，提高模型的表达能力。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>优点</p>
<ol>
<li><p>能够处理大型特征空间</p>
</li>
<li><p>能够处理非线性特征之间的相互作用</p>
</li>
<li><p>无需依赖整个数据</p>
</li>
</ol>
</li>
<li><p>缺点：</p>
<ol>
<li><p>当观测样本很多时，效率并不是很高</p>
</li>
<li><p>有时候很难找到一个合适的核函数</p>
</li>
</ol>
</li>
</ol>
<h3 id="分类与回归树（Classification-and-Regression-Tree-CART）"><a href="#分类与回归树（Classification-and-Regression-Tree-CART）" class="headerlink" title="分类与回归树（Classification and Regression Tree,CART）"></a>分类与回归树（Classification and Regression Tree,CART）</h3><ol>
<li><p>概念：一种经典决策树，可以用来处理涉及连续数据的分类或者回归任务。</p>
</li>
<li><p>思想：一些学者采用类似随机投影的思路，将自变量的取值空间切分为若干个碎块，并假设这个空间碎块内的所有样本的因变量取值接近(甚至相同)——在这种思想的指导下，出现了一种非常经典的回归模型，即CART回归树。</p>
</li>
<li><p>由来：</p>
<ol>
<li><p>特征为连续变量：不能直接使用特征取值，选择用于分割样本的特征取值</p>
</li>
<li><p>输出为连续变量：基尼系数和信息增益并不能作为分组质量的表征。使用！回归树！</p>
</li>
</ol>
</li>
<li><p>关键：设计一个标准，用来指导机器按照最有利于准确计算因变量的情况来切分特征空间。</p>
<ol>
<li>e.g.:切分特征空间的标准：MES</li>
</ol>
</li>
<li><p>代码：<a target="_blank" rel="noopener" href="https://github.com/lipengyuer/DataScience/blob/master/src/algoritm/CARTRegression.py">https://github.com/lipengyuer/DataScience/blob/master/src/algoritm/CARTRegression.py</a></p>
</li>
</ol>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p>概念：通过组合多个基本模型的预测结果，以获得更好的整体预测性能。</p>
<p>目的：组合多个弱分类器或者回归器来创建一个强分类器或者回归器。</p>
<ol>
<li><p>bagging</p>
<p> 通过对原数据集的抽样，得到多份采样数据集，使用弱学习器分别在这多份采样数据集上学习， 而后使用集成策略将结果整合起来（e.g. 分类问题用投票法，回归问题用加权法） e.g. 随机森林（Random Forest）</p>
</li>
<li><p>stacking</p>
<p> 使用不同的学习方法学习同一份数据，得到多个学习器， 而后使用另一个学习器，学习以上多个学习器的输出到真实标签的映射 boosting 按序处理多个弱学习器，排在后的学习器重点学习排在前的学习器无法处理好的那些数据 e.g. Ada</p>
</li>
<li><p>Boost</p>
<p> 一个学习器学完后，根据其对数据集分类的正确与否，调整下一个学习器学习时，数据集各条数据被采样到的概率，达成调整数据集分布的作用。而后多个学习器按照各自的正确率集成在一</p>
</li>
</ol>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><ol>
<li><p>是决策树一个非常优秀的扩展，同时也剥夺了商业规则和易解释性。</p>
<ol>
<li><p>树很多，使用多数投票规则使得模型变得更加复杂，</p>
</li>
<li><p>决策树变量之间也存在相互作用。</p>
</li>
</ol>
</li>
</ol>
<h3 id="变分贝叶斯方法"><a href="#变分贝叶斯方法" class="headerlink" title="变分贝叶斯方法"></a>变分贝叶斯方法</h3><p>参考：<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">Variational Bayesian methods</a><br>变分贝叶斯方法是一系列用于逼近贝叶斯推理和机器学习中出现的棘手积分的技术。它们通常用于由观察变量（通常称为“数据”）以及未知参数和潜在变量组成的复杂统计模型，这三种类型的随机变量之间具有各种关系，正如图形模型所描述的那样。正如贝叶斯推理中的典型情况一样，参数和潜在变量被分组为“未观察到的变量”。变分贝叶斯方法主要用于两个目的：</p>
<ol>
<li>为未观测变量的后验概率提供分析近似，以便对这些变量进行统计推断。</li>
<li>导出观察数据的边际可能性（有时称为证据）的下限（即给定模型的数据的边际概率，对未观察的变量进行边缘化）。这通常用于执行模型选择，一般思想是给定模型的边际，可能性较高表明该模型对数据的拟合更好，因此所讨论的模型是生成数据的模型的概率更大。 （另请参阅贝叶斯因子文章。）<br>。。。。。</li>
</ol>
<h3 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h3><p>（Laplace smoothing），也称为加一平滑（Add-One smoothing），是一种用于处理概率估计中的零概率问题的技术。它是一种简单而常用的平滑方法，可用于解决在计算概率时可能出现的数据稀疏性和零概率的情况。</p>
<p>在概率估计中，当我们根据样本数据计算事件的概率时，有时会遇到某些事件在样本中未出现的情况，导致概率估计为零。这在实际应用中可能不太合理，因为我们不能简单地认为未观察到的事件的概率为零。</p>
<p>拉普拉斯平滑通过在计算概率时为每个事件的计数值（或频率）增加一个常数（通常为1），来解决零概率问题。这个常数被称为平滑因子或平滑参数。通过这种方法，即使某个事件在样本中未出现，它的概率仍然会被估计为一个非零值。</p>
<p>拉普拉斯平滑的概率估计公式如下：<br>P(x) &#x3D; (count(x) + 1) &#x2F; (N + V)</p>
<p>其中，P(x)表示事件x的平滑概率，count(x)表示在样本中观察到事件x的次数，N表示总观测次数，V表示事件的可能取值数量（即事件的种类数）。</p>
<p>应用方面，拉普拉斯平滑广泛用于自然语言处理（NLP）中的语言模型，特别是n-gram语言模型。在n-gram模型中，用于估计概率的数据通常是文本中的n个连续词语序列。拉普拉斯平滑可以解决在计算概率时可能出现的未观察到的n-gram序列的问题，提高语言模型的鲁棒性和泛化能力。</p>
<p>除了语言模型，拉普拉斯平滑还可以应用于其他概率估计问题，如朴素贝叶斯分类器、信息检索中的查询扩展和推荐系统等。它可以有效地处理数据稀疏性问题，并提供更合理的概率估计结果。</p>
<h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>当谈到强化学习（Reinforcement Learning，RL）时，我们在机器学习中讨论的是一种范例和方法。它主要用于描述和解决智能代理与环境交互的学习问题，目标是通过学习一种策略或行为序列来最大化累积的回报或实现特定目标。</p>
<p>在强化学习中，我们有一个智能代理（agent），它根据环境的状态（state）选择动作（action），并与环境进行交互。环境会根据代理采取的动作以及当前的状态，返回给代理一个奖励信号（reward）和下一个状态。代理的目标是通过与环境的交互，通过尝试和错误的方式来学习一个最佳策略，以使得长期累积的回报最大化。</p>
<p>在强化学习中，代理通过学习价值函数（value function）或策略函数（policy function）来指导其决策过程。价值函数可以评估给定状态或状态动作对的价值，而策略函数定义了在给定状态下选择动作的方式。代理通过与环境的交互不断更新这些函数，以改进其决策能力。</p>
<p>强化学习的一个重要概念是探索（exploration）与利用（exploitation）的权衡。探索是指代理通过尝试新的动作来发现更多的知识，而利用是指代理根据已知信息选择最优动作以获得最大回报。强化学习算法需要在探索和利用之间找到平衡，以达到最佳的学习效果。</p>
<p>总结起来，强化学习是一种机器学习方法，用于解决智能代理与环境交互的学习问题。代理通过学习策略或行为序列来最大化累积回报或实现特定目标。在这个过程中，代理通过与环境的交互不断更新价值函数和策略函数，以改进其决策能力。探索与利用的权衡是强化学习中需要解决的重要问题之一。</p>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ol>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/743cf2357b28">https://www.jianshu.com/p/743cf2357b28</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53183016">https://zhuanlan.zhihu.com/p/53183016</a></p>
</li>
<li><p>CART回归：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/128472955">https://zhuanlan.zhihu.com/p/128472955</a></p>
</li>
</ol>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p><a target="_blank" rel="noopener" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/</a></p>
<p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/yujianmin1990/article/details/85221271">https://blog.csdn.net/yujianmin1990/article/details/85221271</a></p>
<p>扩展 Attention 来加速训练，并且在特定任务上Transformer 表现比 Google NMT 模型还要好，最大好处是可并行 </p>
<h1 id="提出"><a href="#提出" class="headerlink" title="提出"></a>提出</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a><br>其中的 TF 应用是 Tensor2Tensor 的子模块。</p>
<h1 id="粗略概述"><a href="#粗略概述" class="headerlink" title="粗略概述"></a>粗略概述</h1><ol>
<li>编码组件<ol>
<li>六层编码器首尾相连：完全结构相同，但是不共享参数。</li>
<li>对于每一个编码器<ol>
<li>self-attention 层：帮助模型在编码某一个此时能看到别的单词</li>
<li>前向网络：每个self-attention的输出流向一个前向网络，每个输入位置对应的前向网络是独立互不干扰的。 <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这里的每个输入位置：其实是一个序列中的不同位置</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li>连接层</li>
<li>解码组件<ol>
<li>六层解码器首尾相连。每个输入位置对应的前向网络是独立互不干扰的。</li>
<li>对于每一个解码器：<ol>
<li>self-attention 层：</li>
<li>attention 层：该层有助于解码器能够关注到输入句子的相关部分，以便更好的生成与输入有关的输出。（生成每个输出时，根据输入序列的不同部分动态地分配注意力权重。）</li>
<li>前向网络：</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="待继续，有点累了。"><a href="#待继续，有点累了。" class="headerlink" title="待继续，有点累了。"></a>待继续，有点累了。</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yujianmin1990/article/details/85221271">https://blog.csdn.net/yujianmin1990/article/details/85221271</a></p>
<h1 id="Transformer有两个版本："><a href="#Transformer有两个版本：" class="headerlink" title="Transformer有两个版本："></a>Transformer有两个版本：</h1><p>Transformer base和Transformer Big。两者结构其实是一样的，主要区别是包含的Transformer Block数量不同，Transformer base包含12个Block叠加，而Transformer Big则扩张一倍，包含24个Block。无疑Transformer Big在网络深度，参数量以及计算量相对Transformer base翻倍，所以是相对重的一个模型，但是效果也最好。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Transformer/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><h2 id="关键"><a href="#关键" class="headerlink" title="关键"></a>关键</h2><ol>
<li>生成对抗网络（GANs）将当前用于判别机器学习的深度神经网络的进步转化为（隐式）生成建模。</li>
<li>GAN 训练一个生成式深度学习网络 G，将多维随机样本 z （来自高斯分布或者均匀分布）作为输入，从所需分布中生成一个样本。</li>
<li>GANs 将密度估计问题转换为 二元分类问题，其中对 G 参数的学习是通过能耐区分真假数据的判别深度神经网络 D 来实现的。</li>
<li>更正式地说，GAN 解决的优化问题可以概括如下：<br> ![[Pasted image 20240415162616.png]]<br>   HashCat Per position Markov Chains.</li>
</ol>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><ol>
<li>基于积分概率指标：IPM-based GAN<br> 为 GAN 训练 提供稳定性，学习过程中相对稳定，</li>
<li>基于非积分概率指标：non-IPM-based GAN</li>
</ol>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>在学习阶段不稳定，模型优化困难。</p>
<h1 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Arjovsky 等人 2017 提出的 WGAN 通过采用 Wasserstein 距离作为损失来提高标准 GAN 的训练稳定性。 这种方法的好处包括减少模式崩溃和有意义的学习曲线，这有助于确定最佳超参数。 WGAN 纳入了新的成本函数； 然而，WGAN 的实验重点是生成逼真的图像。 古尔拉贾尼等人。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>与传统的GAN相比，WGAN通过引入Wasserstein距离取代了传统GAN中使用的JS散度或KL散度，从而在训练过程中提供了更稳定的梯度信号。</p>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><p>为了实现Wasserstein距离的近似，WGAN引入了一个判别器的参数范数约束，即Lipschitz限制。这通过对判别器的权重进行剪裁或权重正则化来实现。然而，这种限制方法可能难以实施并且效果不稳定。</p>
<h1 id="IWGAN"><a href="#IWGAN" class="headerlink" title="IWGAN"></a>IWGAN</h1><p>可以更有效地找到全局最优值。 他们引入了梯度惩罚的概念来代替 WGAN 的梯度裁剪。 古尔拉贾尼等人。 提出使用IWGAN来解决文本生成问题。 在 Gulrajani 等人的 IWGAN 中，G 和 D 都由简单的残差 CNN 组成。 残差架构使得 GAN 的训练快速且稳定[30,31]。 G 将潜在噪声向量作为输入，通过将其转发到其卷积层来对其进行转换，并输出 32 个 one-hot 字符向量的序列。 G的输出层采用softmax非线性函数，并将其转发给D。假样本的每个输出特征由argmax函数的结果决定，argmax函数将G生成的每个输出向量作为输入。 </p>
<h2 id="Relativistic-Average-GAN"><a href="#Relativistic-Average-GAN" class="headerlink" title="Relativistic Average GAN"></a>Relativistic Average GAN</h2><p>相对论平均生成对抗网络（Relativistic Average GAN）是生成对抗网络（GAN）的一种变体，旨在改善生成对抗网络的训练和生成效果。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>传统的GAN中，生成器试图生成逼真的样本，而判别器则根据样本的真实性进行分类。然而，这种方式可能导致生成器和判别器陷入不稳定的训练过程，因为生成器的更新依赖于判别器的反馈，而判别器的反馈又依赖于生成器生成的样本。</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>相对论平均GAN通过引入相对论平均策略来解决这个问题。在这种策略下，生成器和判别器之间的对抗性比较被重新定义，以便更准确地反映出生成样本的真实性。具体而言，相对论平均GAN引入了两个新的损失函数：相对论平均生成器损失和相对论平均判别器损失。</p>
<ol>
<li><p>相对论平均生成器损失（Relativistic Average Generator Loss）是通过对真实样本和生成样本进行比较来度量生成器的性能。它通过计算生成样本在判别器给出真实样本的概率上的平均值来评估生成器的生成能力。</p>
</li>
<li><p>相对论平均判别器损失（Relativistic Average Discriminator Loss）用于度量判别器的性能。它通过比较真实样本和生成样本之间的相对概率来评估判别器的辨别能力。</p>
</li>
</ol>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><ol>
<li>从真实样本中随机采样。</li>
<li>使用生成器生成一批样本。</li>
<li>计算相对论平均生成器损失和相对论平均判别器损失。</li>
<li>更新生成器的参数以减小相对论平均生成器损失。</li>
<li>更新判别器的参数以减小相对论平均判别器损失。</li>
<li>重复步骤1-5，直到达到预定的训练轮数或生成样本达到所需的质量。</li>
</ol>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>改善了生成样本的质量和训练的稳定性。通过引入相对论平均策略，生成器和判别器能够更准确地估计样本的真实性，并促使它们相互逼近，提高生成样本的质量。这种模型在图像生成、文本生成和其他生成任务中都有应用。</p>
<h1 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN-GP"></a>WGAN-GP</h1><p>WGAN-GP通过引入梯度惩罚解决了WGAN中的限制问题。梯度惩罚是通过在判别器的输出和真实样本之间的采样点上计算梯度范数的平均值，并将其与预定义的惩罚因子相乘来实现的。这个惩罚项鼓励判别器在整个输入空间上保持平滑的梯度，从而使判别器满足Lipschitz连续性的要求。</p>
<p>具体来说，在WGAN-GP中，生成器和判别器的训练过程如下：</p>
<ol>
<li>从真实数据和生成器生成的样本中采样。</li>
<li>在采样点上计算判别器的输出。</li>
<li>计算判别器的梯度惩罚，并将其添加到判别器的损失函数中。</li>
<li>更新判别器的参数以最小化损失函数。</li>
<li>对生成器进行更新，最大化判别器对生成样本的输出。</li>
</ol>
<p>WGAN-GP相对于传统的GAN具有几个优点。首先，它提供了更稳定的训练过程，减少了训练中的模式崩溃和模式衍生问题。其次，通过梯度惩罚，WGAN-GP避免了对判别器权重的剪裁或正则化，使得模型的训练更简单和可靠。最后，WGAN-GP在生成器和判别器之间提供了更准确的梯度信号，从而改善了生成样本的质量和多样性。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GAN/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>Variational Auto-Encoders (VAEs) </p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>变分自编码器（Variational Autoencoders，VAEs）是一种生成模型，结合了自编码器和概率推断的思想。它被用于学习数据的潜在表示，并可以生成与原始数据相似的新样本。</p>
<h1 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h1><p>VAEs的基本结构由两部分组成：编码器（Encoder）和解码器（Decoder）。编码器将输入数据映射到一个潜在空间中的潜在变量（也称为编码），而解码器则将潜在变量映射回重构的输入数据。</p>
<p>与传统的自编码器不同，VAEs引入了概率推断的概念，其中潜在变量被建模为潜在空间中的概率分布。具体来说，VAEs假设潜在变量服从一个先验分布（通常是高斯分布），并通过编码器将输入数据映射到潜在空间的均值和方差参数上。然后，从该潜在分布中采样一个潜在变量，并通过解码器将其映射回重构的输入数据空间。</p>
<p>训练VAEs的过程涉及最大化观测数据的对数似然性，并最小化潜在变量与先验分布之间的差异，即最小化重构误差和潜在变量的KL散度。</p>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><p>VAEs的一个关键优点是它们提供了对潜在空间的连续、平滑的控制，这使得可以在潜在空间中进行插值和操作，生成具有多样性和连续变化的新样本。</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>VAEs在生成模型、数据压缩、数据降维和生成样本等任务中得到广泛应用，并成为深度学习领域中重要的模型之一。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总结起来，变分自编码器（VAEs）是一种结合了自编码器和概率推断的生成模型。它通过学习潜在变量的概率分布来表示数据，并可以生成与原始数据相似的新样本。VAEs提供了对潜在空间的平滑控制，具有广泛的应用潜力。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%98%E5%88%86%E7%BC%96%E7%A0%81%E5%99%A8/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/532402983">https://zhuanlan.zhihu.com/p/532402983</a></p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>指一类机器学习模型，其目标是学习数据的概率分布，并通过该概率分布生成新的样本数据。生成模型可以根据已知数据的统计特征，学习数据的分布模式，然后使用这个模式生成新的数据样本。生成模型被广泛应用于数据生成、图像合成、文本生成等领域。</p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><h2 id="按照概率密度函数的处理方式分类"><a href="#按照概率密度函数的处理方式分类" class="headerlink" title="按照概率密度函数的处理方式分类"></a>按照概率密度函数的处理方式分类</h2><p>![[Pasted image 20240412152711.png]]</p>
<h2 id="按照是否有监督"><a href="#按照是否有监督" class="headerlink" title="按照是否有监督"></a>按照是否有监督</h2><ol>
<li>有监督的生成模型。</li>
<li>无监督的生成模型。<ol>
<li>[[扩散模型]]</li>
</ol>
</li>
</ol>
<h1 id="基本任务"><a href="#基本任务" class="headerlink" title="基本任务"></a>基本任务</h1><ol>
<li>生成样本，例如生成逼真的人脸图片、生成高质量的语音等；</li>
<li>也可以通过改进生成模型从而实现样本之间的映射转换，例如图像风格迁移、语音增强等。</li>
</ol>
<h2 id="原理：生成样本"><a href="#原理：生成样本" class="headerlink" title="原理：生成样本"></a>原理：生成样本</h2><h3 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h3><p>生成模型接受随机噪声 z 作为输入，然后产生输出样本 x</p>
<h3 id="训练和推理过程"><a href="#训练和推理过程" class="headerlink" title="训练和推理过程"></a>训练和推理过程</h3><p><strong>分析</strong></p>
<ol>
<li>由 N 个样本构成的集合，假设它们是彼此独立都采样来源于某个未知的概率分布 q(X)；</li>
<li>问题：如何在不知道 q(X) 的情况下产生一个模型使得，生成的样本在分布中。</li>
<li>解决：构建生成模型 p(X,θ)，通过 N 个样本来学习到最好的参数 θ，使得 p(X,θ)&#x3D;q(X)<br><strong>两个问题</strong></li>
<li>如何设计模型<br> 不同的模型有各自的考虑，比如 玻尔兹曼机 使用基于能量的模型，完全可见置信网络对模型进行的链式解析等等。</li>
<li>如何训练<br> 显式生成模型使用的训练准则为极大似然估计。这里有分两种情况：<ol>
<li>对似然函数本身直接进行优化的精确推断方法。（例如流模型，自回归模型）</li>
<li>对似然函数近似值进行优化的近似推断方法。（例如VAE和玻尔兹曼机）<br> 隐式生成模型首先使用两类样本学习到了 p(X,θ) 和 q(X)  的距离，然后再以减少距离为目标训练生成模型。</li>
</ol>
</li>
</ol>
<h3 id="潜变量生成模型"><a href="#潜变量生成模型" class="headerlink" title="潜变量生成模型"></a>潜变量生成模型</h3><p>潜变量生成模型（Latent Variable Generative Model）是一种统计模型，用于描述数据的生成过程。它假设存在一组潜在的变量（也称为隐藏变量或潜变量），这些变量无法直接观测到，但对生成数据起到重要作用。</p>
<p>潜变量生成模型的基本思想是，通过学习数据中隐藏的潜在结构和变量，可以生成与观测数据相似的新样本。这种生成过程通常基于概率分布模型，如高斯混合模型（Gaussian Mixture Model，GMM）、隐马尔可夫模型（Hidden Markov Model，HMM）、变分自编码器（Variational Autoencoder，VAE）等。</p>
<p>在潜变量生成模型中，潜变量表示了数据中的潜在特征或隐含结构，它们对生成数据的分布产生影响。通过对潜变量和观测变量之间的关系进行建模，生成模型可以通过给定潜变量的取值来生成对应的观测数据。</p>
<p>潜变量生成模型的应用广泛，包括图像生成、文本生成、语音生成等。通过学习和探索数据中的潜在结构，潜变量生成模型可以生成具有多样性和创造性的新样本，进而用于数据增强、生成对抗网络（GAN）的训练、数据压缩和降维等任务。</p>
<p>总而言之，潜变量生成模型是一种通过建模潜在变量与观测数据之间的关系来生成数据的统计模型。它利用隐藏的潜在结构和变量来模拟数据的生成过程，并可用于生成新样本和数据分析中的其他任务。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>DDPMs DDIMs DiTs</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model">https://en.wikipedia.org/wiki/Diffusion_model</a><br>扩散模型，在机器学习领域，也被称为扩散概率模型，或者基于得分的生成模型，是一类潜变量生成模型。</p>
<p>扩散模型由三个主要部分组成：正向过程，反向过程和采样过程<br>扩散模型的目标是学习生成给定数据集概率分布的扩散过程。<br>她们通过对数据点在潜在空间中扩散的方式来进行建模并学习数据集的潜在结构。<br>就计算机视觉而言，扩散模型可以应用于各种任务，包括图像去噪、修复、超分辨率和图像生成。这通常涉及训练神经网络以顺序对高斯噪声模糊的图像进行去噪。 2(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-2">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-2</a>) 3(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-gu-3">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-gu-3</a>) 该模型经过训练可以逆转向图像添加噪声的过程。训练收敛后，它可以用于图像生成，从由随机噪声组成的图像开始，让网络迭代去噪。 OpenAI 于 2022 年 4 月 13 日发布的文本到图像模型 DALL-E 2 是一个示例，该示例将扩散模型用于模型的先验（在给定文本标题的情况下生成图像嵌入）和生成最终图像的解码器。 4(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-dalle2-4">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-dalle2-4</a>) 扩散模型最近在自然语言处理 (NLP) 中得到应用， 5(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-5">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-5</a>) 特别是在文本生成 6(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-6">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-6</a>) 7(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-7">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-7</a>) 和摘要等领域。 8(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-8">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-8</a>)</p>
<p>扩散模型通常被表述为马尔可夫链并使用变分推理进行训练。 9(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-ho-9">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-ho-9</a>) 计算机视觉中使用的通用扩散建模框架的示例包括去噪扩散概率模型、噪声条件评分网络和随机微分方程。 10(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-10">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-10</a>)</p>
<h1 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h1><p>属于无监督生成模型</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>扩散模型由三个主要部分组成：正向过程（扩散过程），反向过程和采样过程，生成过程（逆向过程、推断过程）<br>为了避免混淆，本文以 $x_1,x_2,…,x_T$ 表示不同的时间步中的样本，以 $X_1,X_2,…,X_T$ 表示不同时间步对应的随机变量， 以 $p(X_T)$ 表示随机变量的概率分布，以 $N(x_T,\mu,\sum)$ ，表示在分布 $N(\mu, \sum)$ 中 $X&#x3D;x_T$ 时的概率样本概率值。</p>
<h2 id="正向过程（扩散过程）"><a href="#正向过程（扩散过程）" class="headerlink" title="正向过程（扩散过程）"></a>正向过程（扩散过程）</h2><p>通过对任意的初始样本 $x_0$ 连续的添加 $T$ 次高斯噪声，可获得一条样本的轨迹 $x_1,x_2,…,x_T$ ，并且当 $T$ 趋于无穷时，原始样本 $x_0$ 的特征完全消失，成为标准高斯噪声。从概率分布的角度而言，如果定义初始样本（训练样本）的概率分布为 $q(X_0)$ 则通过无限次地扩散动作，时宪历从初始样本分布到高斯分布的映射，即 $q(X_T) &#x3D; N(0,I)$<br>。<br>当然扩散过程连续添加高斯噪声不是任意的，其具体的限定规则为<br>$q(X_t|x_t-1) &#x3D; N(\sqrt {1-\beta_t}x_{t-1},\beta_tI)$ ,其中 $\beta_1 &lt;\beta_2 &lt;…&lt; \beta_T$<br>由上式可知，在给定 $t-1$ 时刻的样本 $x_{t-1}$ 的情况下，t时刻样本的分布为高斯分布。<br>由此式可以看出，该调见高斯分布的均值参数只与 $x_{t-1}$ 有关， 与前面时间的样本无关，因而随机过程 ${X_t}$ 是一个马尔科夫过程。<br>TODO ：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/532402983">https://zhuanlan.zhihu.com/p/532402983</a></p>
<h2 id="反向过程"><a href="#反向过程" class="headerlink" title="反向过程"></a>反向过程</h2><h2 id="采样过程"><a href="#采样过程" class="headerlink" title="采样过程"></a>采样过程</h2>
                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:49.007Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="大模型基础"><a href="#大模型基础" class="headerlink" title="大模型基础"></a>大模型基础</h1><ul>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11G411X7nZ?p=2&vd_source=31f1c950b5b95af0c48f188f0bc047c7">Generative AI 的工作原理</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11G411X7nZ?p=8&vd_source=31f1c950b5b95af0c48f188f0bc047c7">LLM 可以做什么, 不能做什么</a></strong></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/597586623">LLM 技术精要</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/kebijuelun/Awesome-LLM-Learning/blob/main/3.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/3.%E7%BB%8F%E5%85%B8%E5%BC%80%E6%BA%90LLM%E4%BB%8B%E7%BB%8D.md">经典开源 LLM</a></p>
</li>
</ul>
<h2 id="GAI"><a href="#GAI" class="headerlink" title="GAI"></a>GAI</h2><p>[[GAI 的应用]]<br>[[GAI 的工作原理]]</p>
<h1 id="一些资料"><a href="#一些资料" class="headerlink" title="一些资料"></a>一些资料</h1><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV18G411q78w/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=59461060c1867e9bf731e467ae6f00b">https://www.bilibili.com/video/BV18G411q78w/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=59461060c1867e9bf731e467ae6f00b</a></p>
<p>chatgptwchat<br><a target="_blank" rel="noopener" href="https://github.com/a13120854557/Chatgptwchat/blob/main/README_ZH.md">https://github.com/a13120854557/Chatgptwchat/blob/main/README_ZH.md</a></p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:48.991Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a target="_blank" rel="noopener" href="https://github.com/zhayujie/chatgpt-on-wechat">https://github.com/zhayujie/chatgpt-on-wechat</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37215621/article/details/130517060">ChatGPT微信开发，轻松拿捏_keyerror: ‘wxsid-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://space.bilibili.com/4401694/dynamic">https://space.bilibili.com/4401694/dynamic</a></p>
<h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>nohup python3 app.py &amp; tail -f nohup.out<br>nohup .&#x2F;clash-linux-amd64 &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;<br>nohup docker compose up &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>[WARNING][2024-02-27 04:41:40][chat_gpt_bot.py:150] - [CHATGPT] APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host&#x3D;’api.openai.com’, port&#x3D;443): Max retries exceeded with url: &#x2F;v1&#x2F;chat&#x2F;completions (Caused by ProxyError(‘Cannot connect to proxy.’, NewConnectionError(‘&lt;urllib3.connection.HTTPSConnection object at 0x7f75d9c45e50&gt;: Failed to establish a new connection: [Errno 111] Connection refused’)))<br>[WARNING][2024-02-27 04:41:40][chat_gpt_bot.py:150] - [CHATGPT] APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host&#x3D;’api.openai.com’, port&#x3D;443): Max retries exceeded with url: &#x2F;v1&#x2F;chat&#x2F;completions (Caused by ProxyError(‘Cannot connect to proxy.’, NewConnectionError(‘&lt;urllib3.connection.HTTPSConnection object at 0x7f75d9c45fa0&gt;: Failed to establish a new connection: [Errno 111] Connection refused’)))<br>[INFO][2024-02-27 04:41:40][wechat_channel.py:218] - [WX] sendMsg&#x3D;Reply(type&#x3D;ERROR, content&#x3D;[ERROR]<br>我连接不到你的网络), receiver&#x3D;@dade582ddc06e63c6ec1175c680f90ff82f77df7c20d9450bfb147cb5a925968</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/T752462536/article/details/134164508">【完美解决：openai.error.APIConnectionError: Error communicating with OpenAI:】_openai.openaierror: the api_key client option must-CSDN博客</a></p>
<p><code>pip3 show openai</code>查看安装目录<br><code>cd /opt/conda/envs/fyn_python3_8/lib/python3.8/site-packages/openai</code></p>
<h1 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h1><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p>[INFO][2024-02-27 05:34:07][chat_gpt_bot.py:49] - [CHATGPT] query&#x3D;哈哈哈<br>[ERROR][2024-02-27 05:34:07][chat_gpt_bot.py:155] - [CHATGPT] Exception: local variable ‘proxy’ referenced before assignment<br>Traceback (most recent call last):<br>  File “&#x2F;root&#x2F;test&#x2F;GptWchat&#x2F;chatgpt-on-wechat&#x2F;bot&#x2F;chatgpt&#x2F;chat_gpt_bot.py”, line 123, in reply_text<br>    response &#x3D; openai.ChatCompletion.create(api_key&#x3D;api_key, messages&#x3D;session.messages, **args)<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_resources&#x2F;chat_completion.py”, line 25, in create<br>    return super().create(*args, **kwargs)<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_resources&#x2F;abstract&#x2F;engine_api_resource.py”, line 153, in create<br>    response, _, api_key &#x3D; requestor.request(<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_requestor.py”, line 288, in request<br>    result &#x3D; self.request_raw(<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_requestor.py”, line 609, in request_raw<br>    proxies&#x3D;proxy,<br>UnboundLocalError: local variable ‘proxy’ referenced before assignment<br>[INFO][2024-02-27 05:34:08][wechat_channel.py:218] - [WX] sendMsg&#x3D;Reply(type&#x3D;ERROR, content&#x3D;[ERROR]<br>我现在有点累了，等会再来吧), receiver&#x3D;@5dc3bf914f7a577d4798603da08adc85720678732d3a0413329ceebb3041f0b7</p>
<p>[bot] 这段代码是在Python中定义一个特殊的 <code>__setitem__</code> 方法，它是一个魔法方法或者叫做运算符重载。这个方法在我们试图给一个对象的实例分配值时被调用。这里看起来像是在实现一个优先级队列或者是一个以某种方式排序的字典。</p>
<p>下面是代码行的详细解释：</p>
<ol>
<li><p><code>def __setitem__(self, key, value):</code>: 定义一个名为 <code>__setitem__</code> 的方法，它接收三个参数：<code>self</code>（表示实例自身，类似于 Java 或 C++ 中的 <code>this</code>），<code>key</code>（字典中要设置的键），<code>value</code>（该键所对应的值）。</p>
</li>
<li><p><code>if key in self:</code>: 如果提供的键已经在字典中存在。</p>
</li>
<li><p><code>super().__setitem__(key, value)</code>: 使用超类（可能是 <code>dict</code> 或其它字典类型）的 <code>__setitem__</code> 方法来设置键值对。</p>
</li>
<li><p><code>for i, (priority, k) in enumerate(self.heap):</code>: 遍历 <code>heap</code> 列表中的每一项，<code>i</code> 是索引，<code>priority</code> 和 <code>k</code> 分别是元组中的两个项目，其中 <code>priority</code> 是优先级（或排序函数的结果），<code>k</code> 是键。</p>
</li>
<li><p><code>if k == key:</code>: 如果当前键等于要设置的键。</p>
</li>
<li><p><code>self.heap[i] = (self.sort_func(key, value), key)</code>: 使用 <code>sort_func</code> 函数计算新的优先级，并更新 <code>heap</code> 列表中对应的项。</p>
</li>
<li><p><code>heapq.heapify(self.heap)</code>: 重新调整 <code>heap</code> 列表以保持堆的特性（堆是完全二叉树，且任一节点的值都大于或等于其子节点的值）。</p>
</li>
<li><p><code>break</code>: 找到了正确的键，所以退出循环。</p>
</li>
<li><p><code>self.sorted_keys = None</code>: 重置 <code>sorted_keys</code>。</p>
</li>
<li><p><code>else:</code>: 如果字典中不存在这个键。</p>
</li>
<li><p><code>super().__setitem__(key, value)</code>: 使用超类的 <code>__setitem__</code> 方法来设置新的键值对。</p>
</li>
<li><p><code>heapq.heappush(self.heap, (self.sort_func(key, value), key))</code>: 在 <code>heap</code> 列表中添加新的元素，元素是一个元组，包含 <code>sort_func</code> 函数计算出的优先级和键。</p>
</li>
<li><p><code>self.sorted_keys = None</code>: 重置 <code>sorted_keys</code>。</p>
</li>
</ol>
<p>这段代码的主要目的是实现一个可以自我排序的字典或者类似结构，键值对的排序取决于 <code>sort_func</code> 函数的返回结果。</p>
<h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p>import ntwork<br>import pilk</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-22T13:14:48.991Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-22</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/22/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E9%A1%B9%E7%9B%AE/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    



    <div class='text-center pagination'>
    <a class="extend prev" rel="prev" href="/page/4/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/6/"><i class="fa fa-angle-right"></i></a>
    </div>



    <div class="hidden">
        <!-- 加载文章阅读对应的统计功能，评论自带的那种 -->
        
    </div>



        

            </section>

        

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
        <div class="sticky-area">
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/avatar.webp" loading="lazy" decoding="auto" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center"></p>
    </div>
    <div class="site-meta">
        <a class="meta-item" href="/archives/">
            <span class="title">
                文章
            </span>
            <span class="count">
                97
            </span>
        </a>
        <a class="meta-item" href="/categories/">
            <span class="title">
                分类
            </span>
            <span class="count">
                0
            </span>
        </a>
        <a class="meta-item" href="/tags/">
            <span class="title">
                标签
            </span>
            <span class="count">
                0
            </span>
        </a>
    </div>
</aside>
            
                

            
                
            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>最新文章</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
        
          
          
        
          
          
        
          
          
            <a class="list-group-item" href="/2024/04/22/TEMP%EF%BC%9A%E4%B8%AD%E9%93%81/"><i class="fa  fa-book"></i> Hello Worldaaaaaaa</a>
            
          
        
          
          
        
          
          
            <a class="list-group-item" href="/2024/04/22/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D/"><i class="fa  fa-book"></i> Englislearning</a>
            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
            <a class="list-group-item" href="/2024/04/22/hello-world/"><i class="fa  fa-book"></i> Hello Worldaaaaaaa</a>
            
          
        
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        <!-- Keep for compatibility -->
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <!-- New links -->
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2024 Hexo 版权所有.</li>
                            <li>本站已运行<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by John Doe.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.io" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="/vendors/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="/vendors/nprogress@0.2.0/nprogress.js"></script>
<script>
    if (!window.kr) {
        window.kr = {};
    }
    window.kr.notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));
    window.kr.siteRoot = "/";
</script>


    <script async src="/js/candy.min.js"></script>



    <script defer src="/vendors/aplayer@1.10.1/dist/APlayer.min.js"></script>
    
    <script defer src="/vendors/meting@2.0.1/dist/Meting.min.js"></script>
    <meting-js
        server="netease"
        type="playlist"
        id="3204190542"
        order="random"
        fixed="true"
    >
    </meting-js>



    <script defer src="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>



<!-- Extra support for third-party plguins  -->


    </body>
</html>