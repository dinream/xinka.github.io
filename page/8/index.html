<!DOCTYPE html>
<html lang="zh-CN">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  
  
  <title>心咖</title>
  
  <meta name="author" content="dreamin" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="" />
  
  <meta name="description" content="生于尘埃，溺于人海，死于理想的高台">
<meta property="og:type" content="website">
<meta property="og:title" content="心咖">
<meta property="og:url" content="https://xinka.vercel.app/page/8/index.html">
<meta property="og:site_name" content="心咖">
<meta property="og:description" content="生于尘埃，溺于人海，死于理想的高台">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="dreamin">
<meta name="twitter:card" content="summary">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" media="all"></script>
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-color-dark.min.css" media="(prefers-color-scheme: dark)"></script>
    <script src="/js/kr-dark.min.js"></script>
  
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/night-eighties.min.css" media="all"></script>
  
  <link rel="stylesheet" id="fontawe-css" href="/vendors/font-awesome@4.7.0/css/font-awesome.min.css" media="all"></script>
  <link rel="stylesheet" id="nprogress-css" href="/vendors/nprogress@0.2.0/nprogress.css" media="all"></script>
  
  
    <link rel="stylesheet" href="/vendors/aplayer@1.10.1/dist/APlayer.min.css"></script>
  
  
    <link rel="stylesheet" href="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"></script>
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="/vendors/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="/vendors/qrcode_js@1.0.0/qrcode.min.js"></script>
  
  
  <style>
    
    
  </style>
  
<meta name="generator" content="Hexo 7.2.0"></head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">心咖</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>心咖</h2> <br />
                        <span>人生如此，方趁我心</span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        

            <section class="col-md-8">

        

            <!-- Breadcrumb for tag & category page -->




    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="git-安装"><a href="#git-安装" class="headerlink" title="git 安装"></a>git 安装</h1><h2 id="Win-下载"><a href="#Win-下载" class="headerlink" title="Win 下载"></a>Win 下载</h2><p><a target="_blank" rel="noopener" href="https://git-scm.com/download/">https://git-scm.com/download/</a></p>
<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install git</span><br></pre></td></tr></table></figure>

<h1 id="git-配置"><a href="#git-配置" class="headerlink" title="git 配置"></a>git 配置</h1><pre><code>注意： win 在 Git Bash 下； linux 在 /bin/bash 即可
</code></pre>
<h5 id="生成公钥"><a href="#生成公钥" class="headerlink" title="生成公钥"></a>生成公钥</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;your_email@xxx.com&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="获取公钥"><a href="#获取公钥" class="headerlink" title="获取公钥"></a>获取公钥</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># linux:</span></span><br><span class="line"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub</span><br><span class="line"><span class="comment">#win: </span></span><br><span class="line">C:/user/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>

<h5 id="配置公钥"><a href="#配置公钥" class="headerlink" title="配置公钥"></a>配置公钥</h5><p>复制公钥到 gitee｜githbu 网页个人设置中的公钥之中；保存。</p>
<h5 id="终端环境配置"><a href="#终端环境配置" class="headerlink" title="终端环境配置"></a>终端环境配置</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ssh -T git@gitee.com</span><br><span class="line"></span><br><span class="line">git config --global user.name yourname  <span class="comment"># &quot;你码云的名字或昵称&quot;</span></span><br><span class="line"></span><br><span class="line">git config --global user.email youremail@xxx.com <span class="comment"># &quot;你码云的主邮箱&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="vscode-用一个远程库"><a href="#vscode-用一个远程库" class="headerlink" title="vscode 用一个远程库"></a>vscode 用一个远程库</h5><p><strong>初始化一个本次仓库</strong><br>ctrl+shift+p initialize repository:<br><strong>远程链接</strong><br>源代码管理库-》远程-》远程仓库-》粘贴.git 链接-》ok</p>
<h1 id="git-使用"><a href="#git-使用" class="headerlink" title="git 使用"></a>git 使用</h1><h5 id="远程仓库管理"><a href="#远程仓库管理" class="headerlink" title="远程仓库管理"></a>远程仓库管理</h5><p>git remote -v:列出所有远程仓库的别名和地址</p>
<p>git remote show &lt;远程仓库别名&gt;:查看远程仓库的详细信息</p>
<p>git remote add &lt;别名&gt; &lt;仓库地址&gt;:添加一个新的远程仓库</p>
<p>git remote remove &lt;别名&gt;:删除一个远程仓库</p>
<p>git remote rename &lt;原别名&gt; &lt;新别名&gt;:重命名一个远程仓库</p>
<p>git remote set-url &lt;别名&gt; &lt;新地址&gt;:修改某个远程仓库的地址</p>
<p>git remote set-head &lt;别名&gt; &lt;分支名&gt;:修改远程仓库的默认分支</p>
<p>git remote -v update:更新所有远程仓库</p>
<p>git remote prune &lt;别名&gt;:移除远程上已删除的tracking分支</p>
<p>git remote get-url &lt;别名&gt;:查看远程仓库的原始克隆URL</p>
<h4 id="查看跟踪远程分支"><a href="#查看跟踪远程分支" class="headerlink" title="查看跟踪远程分支"></a>查看跟踪远程分支</h4><p>git branch -vv (当前分支：hash：远程跟踪分支：注释)</p>
<h4 id="修改跟踪的远程分支"><a href="#修改跟踪的远程分支" class="headerlink" title="修改跟踪的远程分支"></a>修改跟踪的远程分支</h4><p>git branch –set-upstream-to&#x3D;origin&#x2F;remote-branch local-branch</p>
<p>这将为本地分支 <code>local-branch</code> 设置远程跟踪分支为 <code>origin/remote-branch</code>。</p>
<p>你也可以使用简化命令来设置远程跟踪分支：</p>
<p>git branch -u origin&#x2F;remote-branch local-branch</p>
<p>（这个命令用于现有本地分支，将其与远程分支相关联）</p>
<h4 id="创建新分支"><a href="#创建新分支" class="headerlink" title="创建新分支"></a>创建新分支</h4><p>git branch  origin&#x2F;serverfix</p>
<h4 id="切换本地分支"><a href="#切换本地分支" class="headerlink" title="切换本地分支"></a>切换本地分支</h4><p>git checkout master </p>
<p>  这里的master应该就是本地的分支</p>
<p>此外：</p>
<p>git checkout -b master origin&#x2F;master </p>
<p>  表示切换的分支是新建的（本地只有main，没有master），分支名：master； 来源：orgin&#x2F;master;</p>
<p>确定要删除的分支，并运行以下命令来删除该分支（假设要删除的分支名为 branch-name）：</p>
<p>git branch -d branch-name</p>
<p>如果分支上有未合并的更改，Git 会拒绝删除该分支，并显示一条警告消息。如果确实要强制删除分支，可以使用 -D 选项：</p>
<p>git branch -D branch-name</p>
<h4 id="拉取"><a href="#拉取" class="headerlink" title="拉取"></a>拉取</h4><p>源代码管理-》拉取</p>
<p>或者 pull 就行</p>
<p>git pull [远程仓库名] [远程分支]</p>
<h4 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h4><p>手动</p>
<p>添加消息-》提交-》同步</p>
<p>命令提交</p>
<p>暂存：git add * </p>
<h2 id="提交："><a href="#提交：" class="headerlink" title="提交："></a>提交：</h2><p>使用与当前分支关联的远程仓库和同名的远程分支：</p>
<p>git push<br>git push  xinka master</p>
<p>git push [&lt;远程仓库名&gt;] [&lt;本地分支名&gt;:]&lt;远程分支名&gt;</p>
<p>强制将当前分支 覆盖掉origin 的 master 分支：<br>git push origin +current-branch:master</p>
<p>（下面几个命令可以用来解决：refuse to merge unrelated histories）</p>
<h4 id="获取分支最新提交hash"><a href="#获取分支最新提交hash" class="headerlink" title="获取分支最新提交hash"></a>获取分支最新提交hash</h4><p>git log -1 main</p>
<p>从远程仓库获取最新的提交和分支信息，但不会自动将这些更改合并到你的本地分支中：</p>
<p>git fetch &lt;远程仓库名&gt;</p>
<p>使用其他命令（如git merge或git rebase）将这些更改合并到你的本地分支中。</p>
<h2 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h2><p>git merge –strategy&#x3D;ours <branch-to-merge></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这将执行合并操作，但将忽略其他分支（`&lt;branch-to-merge&gt;`）的更改，仅保留当前分支（主分支）的内容。任何冲突都会被自动解决为当前分支的更改。</span><br><span class="line"></span><br><span class="line">git merge --strategy=theirs &lt;branch-to-merge&gt;</span><br></pre></td></tr></table></figure>
<p>这将执行合并操作，但会忽略当前分支的更改，选择其他分支（<code>&lt;branch-to-merge&gt;</code>）的内容。冲突会被自动解决为其他分支的更改。</p>
<h1 id="放弃本地分支，重置到master分支的最新提交"><a href="#放弃本地分支，重置到master分支的最新提交" class="headerlink" title="放弃本地分支，重置到master分支的最新提交"></a>放弃本地分支，重置到master分支的最新提交</h1><ol>
<li><p>git fetch</p>
</li>
<li><p>git reset –hard <dev-latest-commit-hash></p>
</li>
</ol>
<p>或者</p>
<ol start="2">
<li>git reset –hard origin&#x2F;master</li>
</ol>
<p>另一种解释：放弃本地更改：</p>
<p>git reset –hard FETCH_HEAD，其中FETCH_HEAD表示上一次成功pull之后的commit点，然后git pull即可</p>
<h1 id="强制推送当前分支到远程分支"><a href="#强制推送当前分支到远程分支" class="headerlink" title="强制推送当前分支到远程分支"></a>强制推送当前分支到远程分支</h1><p>git push -f xinka master</p>
<p>这样就丢掉了 master 原来的历史。这样可以快速建立分支之间的关系，但是原有分支的历史提交会丢失。需要根据实际情况权衡是否使用这种破坏性的重置方式。<br>上面可能会出现：error: src refspec localagent does not match any ，此时，试试下面的操作。</p>
<p>git fetch<br>git push -f orign  HEAD:&lt;远程分支名&gt;</p>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>git pull 后 仓库  在本地的默认名称  就是  origin</p>
<p>查看：git remote -v </p>
<p>修改：git remote rename old new</p>
<p>比如： git push origin master 表示将本地 推到 master</p>
<p>永久修改默认名称：git config –global init.defaultBranch new_name;</p>
<h1 id="强制覆盖本地分支"><a href="#强制覆盖本地分支" class="headerlink" title="强制覆盖本地分支"></a>强制覆盖本地分支</h1><pre><code>git fetch --all

git reset --hard origin/master

git pull
</code></pre>
<h2 id="强制覆盖远程分支"><a href="#强制覆盖远程分支" class="headerlink" title="强制覆盖远程分支"></a>强制覆盖远程分支</h2><p>git push [&lt;远程仓库名&gt;] [&lt;本地分支名&gt;:]&lt;远程分支名&gt;</p>
<p>每次提交之后，必须点击：同步更改才能看到网页的变化。</p>
<h1 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h1><h2 id="connect-reset-问题，直接通过命令行配置解决"><a href="#connect-reset-问题，直接通过命令行配置解决" class="headerlink" title="connect reset 问题，直接通过命令行配置解决"></a>connect reset 问题，直接通过命令行配置解决</h2><p>git config –global http.sslBackend “openssl”</p>
<p>git config –global http.sslCAInfo “C:\Program Files\Git\mingw64\ssl\cert.pem”</p>
<h2 id="git-remote"><a href="#git-remote" class="headerlink" title="git remote"></a>git remote</h2><p>git remote [-v | –verbose]</p>
<p>显示所有远程仓库的名称，以及它们的 URL。<br>示例：git remote -v<br>git remote add [-t <branch>] [-m <master>] [-f] [–tags | –no-tags] [–mirror&#x3D;&lt;fetch|push&gt;] <name> <url></p>
<p>添加一个新的远程仓库。<br>示例：git remote add origin <a target="_blank" rel="noopener" href="https://github.com/user/repo.git">https://github.com/user/repo.git</a><br>git remote rename [–[no-]progress] <old> <new></p>
<p>重命名一个远程仓库。<br>示例：git remote rename origin upstream<br>git remote remove <name></p>
<p>移除指定名称的远程仓库。<br>示例：git remote remove origin<br>git remote set-head <name> (-a | –auto | -d | –delete | <branch>)</p>
<p>设置指定远程仓库的 HEAD 引用。<br>示例：git remote set-head origin master<br>git remote show [-n] <name></p>
<p>显示指定远程仓库的信息，包括分支和跟踪情况。<br>示例：git remote show origin<br>git remote prune [-n | –dry-run] <name></p>
<p>移除没有对应本地分支的指定远程仓库分支的引用。<br>示例：git remote prune origin<br>git remote update [-p | –prune] [(<group> | <remote>)…]</p>
<p>更新指定的远程仓库的引用。<br>示例：git remote update origin<br>git remote set-branches [–add] <name> <branch>…</p>
<p>设置指定远程仓库应该跟踪的分支。<br>示例：git remote set-branches origin main<br>git remote get-url [–push] [–all] <name></p>
<p>获取指定远程仓库的 URL。<br>示例：git remote get-url origin<br>git remote set-url [–push] <name> <newurl> [<oldurl>]</p>
<p>设置指定远程仓库的 URL。<br>示例：git remote set-url origin <a target="_blank" rel="noopener" href="https://github.com/user/new-repo.git">https://github.com/user/new-repo.git</a><br>git remote set-url –add <name> <newurl></p>
<p>添加一个新的 URL 到指定远程仓库。<br>示例：git remote set-url –add origin <a target="_blank" rel="noopener" href="https://github.com/user/old-repo.git">https://github.com/user/old-repo.git</a><br>git remote set-url –delete <name> <url></p>
<p>从指定远程仓库中删除指定的 URL。<br>示例：git remote set-url –delete origin <a target="_blank" rel="noopener" href="https://github.com/user/old-repo.git">https://github.com/user/old-repo.git</a></p>
<h1 id="创建一个新的分支来保留你所做的提交"><a href="#创建一个新的分支来保留你所做的提交" class="headerlink" title="创建一个新的分支来保留你所做的提交"></a>创建一个新的分支来保留你所做的提交</h1><p>git switch -c <new-branch-name>  :这将在当前提交处创建一个新的分支，并切换到该分支，让你可以在该分支上继续工作</p>
<p>如果放弃处于分离头指针状态下的更改，执行：git switch -  ：将切换回进入分离头指针状态之前所在的分支</p>
<h1 id="将一个本地仓库-提交到另一个本地仓库跟踪的远程分支"><a href="#将一个本地仓库-提交到另一个本地仓库跟踪的远程分支" class="headerlink" title="将一个本地仓库 提交到另一个本地仓库跟踪的远程分支"></a>将一个本地仓库 提交到另一个本地仓库跟踪的远程分支</h1><p>确保你当前在本地分支 pv 上。可以使用以下命令检查当前所在的分支：</p>
<p>git branch<br>确保 pv 分支前面有 * 标记。</p>
<p>首先，将本地分支 pv 推送到远程的 private&#x2F;master 分支。执行以下命令：</p>
<p>git push private pv:master<br>这将把本地分支 pv 推送到远程仓库的 private&#x2F;master 分支。</p>
<p>接下来，切换到本地分支 pv 并合并远程的 public&#x2F;master 分支。执行以下命令：</p>
<p>git checkout pv<br>git merge public&#x2F;master<br>这将切换到分支 pv 并将远程的 public&#x2F;master 分支合并到本地分支。</p>
<p>最后，将合并后的更改推送到远程的 public&#x2F;master 分支。执行以下命令：</p>
<p>git push public pv:master<br>这将把本地分支 pv 推送到远程仓库的 public&#x2F;master 分支。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.545Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/%E6%95%99%E7%A8%8B%EF%BC%9Agit/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>[[教程：Obsidian]]<br>[[教程：MD 数学公式语法]]<br>[[教程：Linux 指令]]<br>[[教程：Rime 输入法]]<br>[[配置：python 安装文档]]<br>[[配置：Linux 系统]]<br>[[配置：Windows]]</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.544Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/532402983">https://zhuanlan.zhihu.com/p/532402983</a></p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>指一类机器学习模型，其目标是学习数据的概率分布，并通过该概率分布生成新的样本数据。生成模型可以根据已知数据的统计特征，学习数据的分布模式，然后使用这个模式生成新的数据样本。生成模型被广泛应用于数据生成、图像合成、文本生成等领域。</p>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><h2 id="按照概率密度函数的处理方式分类"><a href="#按照概率密度函数的处理方式分类" class="headerlink" title="按照概率密度函数的处理方式分类"></a>按照概率密度函数的处理方式分类</h2><p>![[Pasted image 20240412152711.png]]</p>
<h2 id="按照是否有监督"><a href="#按照是否有监督" class="headerlink" title="按照是否有监督"></a>按照是否有监督</h2><ol>
<li>有监督的生成模型。</li>
<li>无监督的生成模型。<ol>
<li>[[扩散模型]]</li>
</ol>
</li>
</ol>
<h1 id="基本任务"><a href="#基本任务" class="headerlink" title="基本任务"></a>基本任务</h1><ol>
<li>生成样本，例如生成逼真的人脸图片、生成高质量的语音等；</li>
<li>也可以通过改进生成模型从而实现样本之间的映射转换，例如图像风格迁移、语音增强等。</li>
</ol>
<h2 id="原理：生成样本"><a href="#原理：生成样本" class="headerlink" title="原理：生成样本"></a>原理：生成样本</h2><h3 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h3><p>生成模型接受随机噪声 z 作为输入，然后产生输出样本 x</p>
<h3 id="训练和推理过程"><a href="#训练和推理过程" class="headerlink" title="训练和推理过程"></a>训练和推理过程</h3><p><strong>分析</strong></p>
<ol>
<li>由 N 个样本构成的集合，假设它们是彼此独立都采样来源于某个未知的概率分布 q(X)；</li>
<li>问题：如何在不知道 q(X) 的情况下产生一个模型使得，生成的样本在分布中。</li>
<li>解决：构建生成模型 p(X,θ)，通过 N 个样本来学习到最好的参数 θ，使得 p(X,θ)&#x3D;q(X)<br><strong>两个问题</strong></li>
<li>如何设计模型<br> 不同的模型有各自的考虑，比如 玻尔兹曼机 使用基于能量的模型，完全可见置信网络对模型进行的链式解析等等。</li>
<li>如何训练<br> 显式生成模型使用的训练准则为极大似然估计。这里有分两种情况：<ol>
<li>对似然函数本身直接进行优化的精确推断方法。（例如流模型，自回归模型）</li>
<li>对似然函数近似值进行优化的近似推断方法。（例如VAE和玻尔兹曼机）<br> 隐式生成模型首先使用两类样本学习到了 p(X,θ) 和 q(X)  的距离，然后再以减少距离为目标训练生成模型。</li>
</ol>
</li>
</ol>
<h3 id="潜变量生成模型"><a href="#潜变量生成模型" class="headerlink" title="潜变量生成模型"></a>潜变量生成模型</h3><p>潜变量生成模型（Latent Variable Generative Model）是一种统计模型，用于描述数据的生成过程。它假设存在一组潜在的变量（也称为隐藏变量或潜变量），这些变量无法直接观测到，但对生成数据起到重要作用。</p>
<p>潜变量生成模型的基本思想是，通过学习数据中隐藏的潜在结构和变量，可以生成与观测数据相似的新样本。这种生成过程通常基于概率分布模型，如高斯混合模型（Gaussian Mixture Model，GMM）、隐马尔可夫模型（Hidden Markov Model，HMM）、变分自编码器（Variational Autoencoder，VAE）等。</p>
<p>在潜变量生成模型中，潜变量表示了数据中的潜在特征或隐含结构，它们对生成数据的分布产生影响。通过对潜变量和观测变量之间的关系进行建模，生成模型可以通过给定潜变量的取值来生成对应的观测数据。</p>
<p>潜变量生成模型的应用广泛，包括图像生成、文本生成、语音生成等。通过学习和探索数据中的潜在结构，潜变量生成模型可以生成具有多样性和创造性的新样本，进而用于数据增强、生成对抗网络（GAN）的训练、数据压缩和降维等任务。</p>
<p>总而言之，潜变量生成模型是一种通过建模潜在变量与观测数据之间的关系来生成数据的统计模型。它利用隐藏的潜在结构和变量来模拟数据的生成过程，并可用于生成新样本和数据分析中的其他任务。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.538Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>DDPMs DDIMs DiTs</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model">https://en.wikipedia.org/wiki/Diffusion_model</a><br>扩散模型，在机器学习领域，也被称为扩散概率模型，或者基于得分的生成模型，是一类潜变量生成模型。</p>
<p>扩散模型由三个主要部分组成：正向过程，反向过程和采样过程<br>扩散模型的目标是学习生成给定数据集概率分布的扩散过程。<br>她们通过对数据点在潜在空间中扩散的方式来进行建模并学习数据集的潜在结构。<br>就计算机视觉而言，扩散模型可以应用于各种任务，包括图像去噪、修复、超分辨率和图像生成。这通常涉及训练神经网络以顺序对高斯噪声模糊的图像进行去噪。 2(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-2">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-song-2</a>) 3(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-gu-3">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-gu-3</a>) 该模型经过训练可以逆转向图像添加噪声的过程。训练收敛后，它可以用于图像生成，从由随机噪声组成的图像开始，让网络迭代去噪。 OpenAI 于 2022 年 4 月 13 日发布的文本到图像模型 DALL-E 2 是一个示例，该示例将扩散模型用于模型的先验（在给定文本标题的情况下生成图像嵌入）和生成最终图像的解码器。 4(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-dalle2-4">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-dalle2-4</a>) 扩散模型最近在自然语言处理 (NLP) 中得到应用， 5(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-5">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-5</a>) 特别是在文本生成 6(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-6">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-6</a>) 7(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-7">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-7</a>) 和摘要等领域。 8(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-8">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-8</a>)</p>
<p>扩散模型通常被表述为马尔可夫链并使用变分推理进行训练。 9(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-ho-9">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-ho-9</a>) 计算机视觉中使用的通用扩散建模框架的示例包括去噪扩散概率模型、噪声条件评分网络和随机微分方程。 10(<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Diffusion_model#cite_note-10">https://en.wikipedia.org/wiki/Diffusion_model#cite_note-10</a>)</p>
<h1 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h1><p>属于无监督生成模型</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>扩散模型由三个主要部分组成：正向过程（扩散过程），反向过程和采样过程，生成过程（逆向过程、推断过程）<br>为了避免混淆，本文以 $x_1,x_2,…,x_T$ 表示不同的时间步中的样本，以 $X_1,X_2,…,X_T$ 表示不同时间步对应的随机变量， 以 $p(X_T)$ 表示随机变量的概率分布，以 $N(x_T,\mu,\sum)$ ，表示在分布 $N(\mu, \sum)$ 中 $X&#x3D;x_T$ 时的概率样本概率值。</p>
<h2 id="正向过程（扩散过程）"><a href="#正向过程（扩散过程）" class="headerlink" title="正向过程（扩散过程）"></a>正向过程（扩散过程）</h2><p>通过对任意的初始样本 $x_0$ 连续的添加 $T$ 次高斯噪声，可获得一条样本的轨迹 $x_1,x_2,…,x_T$ ，并且当 $T$ 趋于无穷时，原始样本 $x_0$ 的特征完全消失，成为标准高斯噪声。从概率分布的角度而言，如果定义初始样本（训练样本）的概率分布为 $q(X_0)$ 则通过无限次地扩散动作，时宪历从初始样本分布到高斯分布的映射，即 $q(X_T) &#x3D; N(0,I)$<br>。<br>当然扩散过程连续添加高斯噪声不是任意的，其具体的限定规则为<br>$q(X_t|x_t-1) &#x3D; N(\sqrt {1-\beta_t}x_{t-1},\beta_tI)$ ,其中 $\beta_1 &lt;\beta_2 &lt;…&lt; \beta_T$<br>由上式可知，在给定 $t-1$ 时刻的样本 $x_{t-1}$ 的情况下，t时刻样本的分布为高斯分布。<br>由此式可以看出，该调见高斯分布的均值参数只与 $x_{t-1}$ 有关， 与前面时间的样本无关，因而随机过程 ${X_t}$ 是一个马尔科夫过程。<br>TODO ：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/532402983">https://zhuanlan.zhihu.com/p/532402983</a></p>
<h2 id="反向过程"><a href="#反向过程" class="headerlink" title="反向过程"></a>反向过程</h2><h2 id="采样过程"><a href="#采样过程" class="headerlink" title="采样过程"></a>采样过程</h2>
                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.538Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p><a target="_blank" rel="noopener" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/</a></p>
<p><a target="_blank" rel="noopener" href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/yujianmin1990/article/details/85221271">https://blog.csdn.net/yujianmin1990/article/details/85221271</a></p>
<p>扩展 Attention 来加速训练，并且在特定任务上Transformer 表现比 Google NMT 模型还要好，最大好处是可并行 </p>
<h1 id="提出"><a href="#提出" class="headerlink" title="提出"></a>提出</h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a><br>其中的 TF 应用是 Tensor2Tensor 的子模块。</p>
<h1 id="粗略概述"><a href="#粗略概述" class="headerlink" title="粗略概述"></a>粗略概述</h1><ol>
<li>编码组件<ol>
<li>六层编码器首尾相连：完全结构相同，但是不共享参数。</li>
<li>对于每一个编码器<ol>
<li>self-attention 层：帮助模型在编码某一个此时能看到别的单词</li>
<li>前向网络：每个self-attention的输出流向一个前向网络，每个输入位置对应的前向网络是独立互不干扰的。 <figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">这里的每个输入位置：其实是一个序列中的不同位置</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
<li>连接层</li>
<li>解码组件<ol>
<li>六层解码器首尾相连。每个输入位置对应的前向网络是独立互不干扰的。</li>
<li>对于每一个解码器：<ol>
<li>self-attention 层：</li>
<li>attention 层：该层有助于解码器能够关注到输入句子的相关部分，以便更好的生成与输入有关的输出。（生成每个输出时，根据输入序列的不同部分动态地分配注意力权重。）</li>
<li>前向网络：</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="待继续，有点累了。"><a href="#待继续，有点累了。" class="headerlink" title="待继续，有点累了。"></a>待继续，有点累了。</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yujianmin1990/article/details/85221271">https://blog.csdn.net/yujianmin1990/article/details/85221271</a></p>
<h1 id="Transformer有两个版本："><a href="#Transformer有两个版本：" class="headerlink" title="Transformer有两个版本："></a>Transformer有两个版本：</h1><p>Transformer base和Transformer Big。两者结构其实是一样的，主要区别是包含的Transformer Block数量不同，Transformer base包含12个Block叠加，而Transformer Big则扩张一倍，包含24个Block。无疑Transformer Big在网络深度，参数量以及计算量相对Transformer base翻倍，所以是相对重的一个模型，但是效果也最好。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.537Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/Transformer/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>Variational Auto-Encoders (VAEs) </p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>变分自编码器（Variational Autoencoders，VAEs）是一种生成模型，结合了自编码器和概率推断的思想。它被用于学习数据的潜在表示，并可以生成与原始数据相似的新样本。</p>
<h1 id="构成"><a href="#构成" class="headerlink" title="构成"></a>构成</h1><p>VAEs的基本结构由两部分组成：编码器（Encoder）和解码器（Decoder）。编码器将输入数据映射到一个潜在空间中的潜在变量（也称为编码），而解码器则将潜在变量映射回重构的输入数据。</p>
<p>与传统的自编码器不同，VAEs引入了概率推断的概念，其中潜在变量被建模为潜在空间中的概率分布。具体来说，VAEs假设潜在变量服从一个先验分布（通常是高斯分布），并通过编码器将输入数据映射到潜在空间的均值和方差参数上。然后，从该潜在分布中采样一个潜在变量，并通过解码器将其映射回重构的输入数据空间。</p>
<p>训练VAEs的过程涉及最大化观测数据的对数似然性，并最小化潜在变量与先验分布之间的差异，即最小化重构误差和潜在变量的KL散度。</p>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><p>VAEs的一个关键优点是它们提供了对潜在空间的连续、平滑的控制，这使得可以在潜在空间中进行插值和操作，生成具有多样性和连续变化的新样本。</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>VAEs在生成模型、数据压缩、数据降维和生成样本等任务中得到广泛应用，并成为深度学习领域中重要的模型之一。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总结起来，变分自编码器（VAEs）是一种结合了自编码器和概率推断的生成模型。它通过学习潜在变量的概率分布来表示数据，并可以生成与原始数据相似的新样本。VAEs提供了对潜在空间的平滑控制，具有广泛的应用潜力。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.537Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/%E5%8F%98%E5%88%86%E7%BC%96%E7%A0%81%E5%99%A8/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><h2 id="关键"><a href="#关键" class="headerlink" title="关键"></a>关键</h2><ol>
<li>生成对抗网络（GANs）将当前用于判别机器学习的深度神经网络的进步转化为（隐式）生成建模。</li>
<li>GAN 训练一个生成式深度学习网络 G，将多维随机样本 z （来自高斯分布或者均匀分布）作为输入，从所需分布中生成一个样本。</li>
<li>GANs 将密度估计问题转换为 二元分类问题，其中对 G 参数的学习是通过能耐区分真假数据的判别深度神经网络 D 来实现的。</li>
<li>更正式地说，GAN 解决的优化问题可以概括如下：<br> ![[Pasted image 20240415162616.png]]<br>   HashCat Per position Markov Chains.</li>
</ol>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><ol>
<li>基于积分概率指标：IPM-based GAN<br> 为 GAN 训练 提供稳定性，学习过程中相对稳定，</li>
<li>基于非积分概率指标：non-IPM-based GAN</li>
</ol>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>在学习阶段不稳定，模型优化困难。</p>
<h1 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Arjovsky 等人 2017 提出的 WGAN 通过采用 Wasserstein 距离作为损失来提高标准 GAN 的训练稳定性。 这种方法的好处包括减少模式崩溃和有意义的学习曲线，这有助于确定最佳超参数。 WGAN 纳入了新的成本函数； 然而，WGAN 的实验重点是生成逼真的图像。 古尔拉贾尼等人。</p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>与传统的GAN相比，WGAN通过引入Wasserstein距离取代了传统GAN中使用的JS散度或KL散度，从而在训练过程中提供了更稳定的梯度信号。</p>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><p>为了实现Wasserstein距离的近似，WGAN引入了一个判别器的参数范数约束，即Lipschitz限制。这通过对判别器的权重进行剪裁或权重正则化来实现。然而，这种限制方法可能难以实施并且效果不稳定。</p>
<h1 id="IWGAN"><a href="#IWGAN" class="headerlink" title="IWGAN"></a>IWGAN</h1><p>可以更有效地找到全局最优值。 他们引入了梯度惩罚的概念来代替 WGAN 的梯度裁剪。 古尔拉贾尼等人。 提出使用IWGAN来解决文本生成问题。 在 Gulrajani 等人的 IWGAN 中，G 和 D 都由简单的残差 CNN 组成。 残差架构使得 GAN 的训练快速且稳定[30,31]。 G 将潜在噪声向量作为输入，通过将其转发到其卷积层来对其进行转换，并输出 32 个 one-hot 字符向量的序列。 G的输出层采用softmax非线性函数，并将其转发给D。假样本的每个输出特征由argmax函数的结果决定，argmax函数将G生成的每个输出向量作为输入。 </p>
<h2 id="Relativistic-Average-GAN"><a href="#Relativistic-Average-GAN" class="headerlink" title="Relativistic Average GAN"></a>Relativistic Average GAN</h2><p>相对论平均生成对抗网络（Relativistic Average GAN）是生成对抗网络（GAN）的一种变体，旨在改善生成对抗网络的训练和生成效果。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>传统的GAN中，生成器试图生成逼真的样本，而判别器则根据样本的真实性进行分类。然而，这种方式可能导致生成器和判别器陷入不稳定的训练过程，因为生成器的更新依赖于判别器的反馈，而判别器的反馈又依赖于生成器生成的样本。</p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>相对论平均GAN通过引入相对论平均策略来解决这个问题。在这种策略下，生成器和判别器之间的对抗性比较被重新定义，以便更准确地反映出生成样本的真实性。具体而言，相对论平均GAN引入了两个新的损失函数：相对论平均生成器损失和相对论平均判别器损失。</p>
<ol>
<li><p>相对论平均生成器损失（Relativistic Average Generator Loss）是通过对真实样本和生成样本进行比较来度量生成器的性能。它通过计算生成样本在判别器给出真实样本的概率上的平均值来评估生成器的生成能力。</p>
</li>
<li><p>相对论平均判别器损失（Relativistic Average Discriminator Loss）用于度量判别器的性能。它通过比较真实样本和生成样本之间的相对概率来评估判别器的辨别能力。</p>
</li>
</ol>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><ol>
<li>从真实样本中随机采样。</li>
<li>使用生成器生成一批样本。</li>
<li>计算相对论平均生成器损失和相对论平均判别器损失。</li>
<li>更新生成器的参数以减小相对论平均生成器损失。</li>
<li>更新判别器的参数以减小相对论平均判别器损失。</li>
<li>重复步骤1-5，直到达到预定的训练轮数或生成样本达到所需的质量。</li>
</ol>
<h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>改善了生成样本的质量和训练的稳定性。通过引入相对论平均策略，生成器和判别器能够更准确地估计样本的真实性，并促使它们相互逼近，提高生成样本的质量。这种模型在图像生成、文本生成和其他生成任务中都有应用。</p>
<h1 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN-GP"></a>WGAN-GP</h1><p>WGAN-GP通过引入梯度惩罚解决了WGAN中的限制问题。梯度惩罚是通过在判别器的输出和真实样本之间的采样点上计算梯度范数的平均值，并将其与预定义的惩罚因子相乘来实现的。这个惩罚项鼓励判别器在整个输入空间上保持平滑的梯度，从而使判别器满足Lipschitz连续性的要求。</p>
<p>具体来说，在WGAN-GP中，生成器和判别器的训练过程如下：</p>
<ol>
<li>从真实数据和生成器生成的样本中采样。</li>
<li>在采样点上计算判别器的输出。</li>
<li>计算判别器的梯度惩罚，并将其添加到判别器的损失函数中。</li>
<li>更新判别器的参数以最小化损失函数。</li>
<li>对生成器进行更新，最大化判别器对生成样本的输出。</li>
</ol>
<p>WGAN-GP相对于传统的GAN具有几个优点。首先，它提供了更稳定的训练过程，减少了训练中的模式崩溃和模式衍生问题。其次，通过梯度惩罚，WGAN-GP避免了对判别器权重的剪裁或正则化，使得模型的训练更简单和可靠。最后，WGAN-GP在生成器和判别器之间提供了更准确的梯度信号，从而改善了生成样本的质量和多样性。</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.536Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%B8%B8%E8%A7%81%E6%A8%A1%E5%9E%8B/GAN/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h1><p><a target="_blank" rel="noopener" href="https://github.com/zhayujie/chatgpt-on-wechat">https://github.com/zhayujie/chatgpt-on-wechat</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37215621/article/details/130517060">ChatGPT微信开发，轻松拿捏_keyerror: ‘wxsid-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://space.bilibili.com/4401694/dynamic">https://space.bilibili.com/4401694/dynamic</a></p>
<h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>nohup python3 app.py &amp; tail -f nohup.out<br>nohup .&#x2F;clash-linux-amd64 &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;<br>nohup docker compose up &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>[WARNING][2024-02-27 04:41:40][chat_gpt_bot.py:150] - [CHATGPT] APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host&#x3D;’api.openai.com’, port&#x3D;443): Max retries exceeded with url: &#x2F;v1&#x2F;chat&#x2F;completions (Caused by ProxyError(‘Cannot connect to proxy.’, NewConnectionError(‘&lt;urllib3.connection.HTTPSConnection object at 0x7f75d9c45e50&gt;: Failed to establish a new connection: [Errno 111] Connection refused’)))<br>[WARNING][2024-02-27 04:41:40][chat_gpt_bot.py:150] - [CHATGPT] APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host&#x3D;’api.openai.com’, port&#x3D;443): Max retries exceeded with url: &#x2F;v1&#x2F;chat&#x2F;completions (Caused by ProxyError(‘Cannot connect to proxy.’, NewConnectionError(‘&lt;urllib3.connection.HTTPSConnection object at 0x7f75d9c45fa0&gt;: Failed to establish a new connection: [Errno 111] Connection refused’)))<br>[INFO][2024-02-27 04:41:40][wechat_channel.py:218] - [WX] sendMsg&#x3D;Reply(type&#x3D;ERROR, content&#x3D;[ERROR]<br>我连接不到你的网络), receiver&#x3D;@dade582ddc06e63c6ec1175c680f90ff82f77df7c20d9450bfb147cb5a925968</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/T752462536/article/details/134164508">【完美解决：openai.error.APIConnectionError: Error communicating with OpenAI:】_openai.openaierror: the api_key client option must-CSDN博客</a></p>
<p><code>pip3 show openai</code>查看安装目录<br><code>cd /opt/conda/envs/fyn_python3_8/lib/python3.8/site-packages/openai</code></p>
<h1 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h1><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p>[INFO][2024-02-27 05:34:07][chat_gpt_bot.py:49] - [CHATGPT] query&#x3D;哈哈哈<br>[ERROR][2024-02-27 05:34:07][chat_gpt_bot.py:155] - [CHATGPT] Exception: local variable ‘proxy’ referenced before assignment<br>Traceback (most recent call last):<br>  File “&#x2F;root&#x2F;test&#x2F;GptWchat&#x2F;chatgpt-on-wechat&#x2F;bot&#x2F;chatgpt&#x2F;chat_gpt_bot.py”, line 123, in reply_text<br>    response &#x3D; openai.ChatCompletion.create(api_key&#x3D;api_key, messages&#x3D;session.messages, **args)<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_resources&#x2F;chat_completion.py”, line 25, in create<br>    return super().create(*args, **kwargs)<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_resources&#x2F;abstract&#x2F;engine_api_resource.py”, line 153, in create<br>    response, _, api_key &#x3D; requestor.request(<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_requestor.py”, line 288, in request<br>    result &#x3D; self.request_raw(<br>  File “&#x2F;opt&#x2F;conda&#x2F;envs&#x2F;fyn_python3_8&#x2F;lib&#x2F;python3.8&#x2F;site-packages&#x2F;openai&#x2F;api_requestor.py”, line 609, in request_raw<br>    proxies&#x3D;proxy,<br>UnboundLocalError: local variable ‘proxy’ referenced before assignment<br>[INFO][2024-02-27 05:34:08][wechat_channel.py:218] - [WX] sendMsg&#x3D;Reply(type&#x3D;ERROR, content&#x3D;[ERROR]<br>我现在有点累了，等会再来吧), receiver&#x3D;@5dc3bf914f7a577d4798603da08adc85720678732d3a0413329ceebb3041f0b7</p>
<p>[bot] 这段代码是在Python中定义一个特殊的 <code>__setitem__</code> 方法，它是一个魔法方法或者叫做运算符重载。这个方法在我们试图给一个对象的实例分配值时被调用。这里看起来像是在实现一个优先级队列或者是一个以某种方式排序的字典。</p>
<p>下面是代码行的详细解释：</p>
<ol>
<li><p><code>def __setitem__(self, key, value):</code>: 定义一个名为 <code>__setitem__</code> 的方法，它接收三个参数：<code>self</code>（表示实例自身，类似于 Java 或 C++ 中的 <code>this</code>），<code>key</code>（字典中要设置的键），<code>value</code>（该键所对应的值）。</p>
</li>
<li><p><code>if key in self:</code>: 如果提供的键已经在字典中存在。</p>
</li>
<li><p><code>super().__setitem__(key, value)</code>: 使用超类（可能是 <code>dict</code> 或其它字典类型）的 <code>__setitem__</code> 方法来设置键值对。</p>
</li>
<li><p><code>for i, (priority, k) in enumerate(self.heap):</code>: 遍历 <code>heap</code> 列表中的每一项，<code>i</code> 是索引，<code>priority</code> 和 <code>k</code> 分别是元组中的两个项目，其中 <code>priority</code> 是优先级（或排序函数的结果），<code>k</code> 是键。</p>
</li>
<li><p><code>if k == key:</code>: 如果当前键等于要设置的键。</p>
</li>
<li><p><code>self.heap[i] = (self.sort_func(key, value), key)</code>: 使用 <code>sort_func</code> 函数计算新的优先级，并更新 <code>heap</code> 列表中对应的项。</p>
</li>
<li><p><code>heapq.heapify(self.heap)</code>: 重新调整 <code>heap</code> 列表以保持堆的特性（堆是完全二叉树，且任一节点的值都大于或等于其子节点的值）。</p>
</li>
<li><p><code>break</code>: 找到了正确的键，所以退出循环。</p>
</li>
<li><p><code>self.sorted_keys = None</code>: 重置 <code>sorted_keys</code>。</p>
</li>
<li><p><code>else:</code>: 如果字典中不存在这个键。</p>
</li>
<li><p><code>super().__setitem__(key, value)</code>: 使用超类的 <code>__setitem__</code> 方法来设置新的键值对。</p>
</li>
<li><p><code>heapq.heappush(self.heap, (self.sort_func(key, value), key))</code>: 在 <code>heap</code> 列表中添加新的元素，元素是一个元组，包含 <code>sort_func</code> 函数计算出的优先级和键。</p>
</li>
<li><p><code>self.sorted_keys = None</code>: 重置 <code>sorted_keys</code>。</p>
</li>
</ol>
<p>这段代码的主要目的是实现一个可以自我排序的字典或者类似结构，键值对的排序取决于 <code>sort_func</code> 函数的返回结果。</p>
<h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p>import ntwork<br>import pilk</p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.527Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%BE%AE%E4%BF%A1%E9%A1%B9%E7%9B%AE/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <h1 id="大模型基础"><a href="#大模型基础" class="headerlink" title="大模型基础"></a>大模型基础</h1><ul>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11G411X7nZ?p=2&vd_source=31f1c950b5b95af0c48f188f0bc047c7">Generative AI 的工作原理</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11G411X7nZ?p=8&vd_source=31f1c950b5b95af0c48f188f0bc047c7">LLM 可以做什么, 不能做什么</a></strong></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/597586623">LLM 技术精要</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/kebijuelun/Awesome-LLM-Learning/blob/main/3.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/3.%E7%BB%8F%E5%85%B8%E5%BC%80%E6%BA%90LLM%E4%BB%8B%E7%BB%8D.md">经典开源 LLM</a></p>
</li>
</ul>
<h2 id="GAI"><a href="#GAI" class="headerlink" title="GAI"></a>GAI</h2><p>[[GAI 的应用]]<br>[[GAI 的工作原理]]</p>
<h1 id="一些资料"><a href="#一些资料" class="headerlink" title="一些资料"></a>一些资料</h1><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV18G411q78w/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=59461060c1867e9bf731e467ae6f00b">https://www.bilibili.com/video/BV18G411q78w/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=59461060c1867e9bf731e467ae6f00b</a></p>
<p>chatgptwchat<br><a target="_blank" rel="noopener" href="https://github.com/a13120854557/Chatgptwchat/blob/main/README_ZH.md">https://github.com/a13120854557/Chatgptwchat/blob/main/README_ZH.md</a></p>

                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.526Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A5%E9%97%A8/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    

    
    
        <article class="kratos-hentry kratos-entry-border-new clearfix" itemscope itemtype="https://schema.org/Article">
            <div class="kratos-status">
                
                    <i class="fa fa-refresh"></i>
                
                <div class="kratos-status-inner">
                    <div class="kratos-status-content" itemprop="articleBody">
                        
                            <p>[[RAG 项目]]</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>检索增强生成（RAG——Retrieval <strong>Augmented</strong> Generation）是指对大型语言模型输出进行优化，使其能够在生成响应之前引用训练数据来源之外的权威知识库。大型语言模型（LLM）用海量数据进行训练，使用数十亿个参数为回答问题、翻译语言和完成句子等任务生成原始输出。在 LLM 本就强大的功能基础上，RAG 将其扩展为能访问特定领域或组织的内部知识库，所有这些都无需重新训练模型。这是一种经济高效地改进 LLM 输出的方法，让它在各种情境下都能保持相关性、准确性和实用性。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">会拿这个权威知识库进行训练嘛？</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>![[Pasted image 20240303130455.png]]<br>数据提取——embedding（向量化）——创建索引——检索——自动排序（Rerank）——LLM归纳生成</p>
<p>LLM 面临的已知挑战包括：</p>
<ul>
<li>在没有答案的情况下提供虚假信息。</li>
<li>当用户需要特定的当前响应时，提供过时或通用的信息。</li>
<li>从非权威来源创建响应。</li>
<li>由于术语混淆，不同的培训来源使用相同的术语来谈论不同的事情，因此会产生不准确的响应。</li>
</ul>
<h2 id="Lang-Chain-起源"><a href="#Lang-Chain-起源" class="headerlink" title="Lang Chain 起源"></a>Lang Chain 起源</h2><p>像 ChatGPT 这样的 大语言模型 或者 LLM 可以回答许多话题的问题，但是，一个孤立的 LLM 只知道它的训练内容，这并不包括某些个人信息数据，如果您可以和这些数据与 LLM 进行对话，就会非常有用</p>
<h2 id="Lang-Chain-介绍"><a href="#Lang-Chain-介绍" class="headerlink" title="Lang Chain 介绍"></a>Lang Chain 介绍</h2><p>用于构建 LLM 应用的开源开发框架</p>
<h2 id="Lang-Chain-组件"><a href="#Lang-Chain-组件" class="headerlink" title="Lang Chain 组件"></a>Lang Chain 组件</h2><ol>
<li>prompts 提示</li>
<li>models 模型</li>
<li>indexes 索引</li>
<li>chains 链</li>
<li>agents 代理</li>
</ol>
<h2 id="Lang-Chain-使用——如何与数据对话"><a href="#Lang-Chain-使用——如何与数据对话" class="headerlink" title="Lang Chain 使用——如何与数据对话"></a>Lang Chain 使用——如何与数据对话</h2><p>![[Pasted image 20240303174734.png]]<br>核心：</p>
<ol>
<li>向量存储<ol>
<li>加载数据</li>
<li>拆分为有意义的块</li>
</ol>
</li>
<li>索引–检索文档<ol>
<li>语义搜索：最简单的方式</li>
</ol>
</li>
<li>使得 LLM 能回答 文档相关内容</li>
<li>记忆功能</li>
</ol>
<h3 id="文档加载器"><a href="#文档加载器" class="headerlink" title="文档加载器"></a>文档加载器</h3><p>从不同格式和来源的数据中访问和转换数据的具体细节，转换为标准化格式，即加载到一个标准的文档对象中，该对象由内容和相关元数据组成。</p>
<blockquote>
<p>Lang Chain 中有 80 种 数据加载器</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例</span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> PyPDFLoader</span><br><span class="line">loader = PyPDFLoader(<span class="string">&quot;docs/cs229_lectures/MachineLearning-Lecture01.pdf&quot;</span>)</span><br><span class="line">pages = loader.load()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 例</span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> WebBaseLoader</span><br><span class="line"></span><br><span class="line">loader = WebBaseLoader(<span class="string">&quot;https://github.com/basecamp/handbook/blob/master/37signals-is-you.md&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br></pre></td></tr></table></figure>

<p>文档加载器之间可以组合为一个通用加载器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders.generic <span class="keyword">import</span> GenericLoader</span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders.parsers <span class="keyword">import</span> OpenAIWhisperParser</span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders.blob_loaders.youtube_audio <span class="keyword">import</span> YoutubeAudioLoader</span><br><span class="line"><span class="comment"># ! pip install yt_dlp</span></span><br><span class="line"><span class="comment"># ! pip install pydub</span></span><br><span class="line">url=<span class="string">&quot;https://www.youtube.com/watch?v=jGwO_UgTS7I&quot;</span></span><br><span class="line">save_dir=<span class="string">&quot;docs/youtube/&quot;</span></span><br><span class="line">loader = GenericLoader(</span><br><span class="line">    YoutubeAudioLoader([url],save_dir),</span><br><span class="line">    OpenAIWhisperParser()</span><br><span class="line">)</span><br><span class="line">docs = loader.load()</span><br><span class="line">docs[<span class="number">0</span>].page_content[<span class="number">0</span>:<span class="number">500</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以同时加载多个文件</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> PyPDFLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load PDF</span></span><br><span class="line">loaders = [</span><br><span class="line">    <span class="comment"># Duplicate documents on purpose - messy data</span></span><br><span class="line">    PyPDFLoader(<span class="string">&quot;docs/cs229_lectures/MachineLearning-Lecture01.pdf&quot;</span>),</span><br><span class="line">    PyPDFLoader(<span class="string">&quot;docs/cs229_lectures/MachineLearning-Lecture01.pdf&quot;</span>),</span><br><span class="line">    PyPDFLoader(<span class="string">&quot;docs/cs229_lectures/MachineLearning-Lecture02.pdf&quot;</span>),</span><br><span class="line">    PyPDFLoader(<span class="string">&quot;docs/cs229_lectures/MachineLearning-Lecture03.pdf&quot;</span>)</span><br><span class="line">]</span><br><span class="line">docs = []</span><br><span class="line"><span class="keyword">for</span> loader <span class="keyword">in</span> loaders:</span><br><span class="line">    docs.extend(loader.load())</span><br></pre></td></tr></table></figure>
<h3 id="字符切割"><a href="#字符切割" class="headerlink" title="字符切割"></a>字符切割</h3><blockquote>
<p>为什么需要字符切割</p>
</blockquote>
<p>RAG是一种基于检索的生成模型，它结合了检索和生成的能力。在RAG中，检索阶段用于从大型文本语料库中检索相关的上下文，然后再通过生成阶段生成响应或答案。</p>
<p>切割文本可以帮助RAG模型更好地处理长文本，并提高生成的效率和质量。长文本可能包含大量冗余信息或无关信息，这可能会对模型的性能产生负面影响。通过将文本切割成较小的片段，RAG模型可以在生成阶段更好地处理和理解这些部分，并减少不必要的计算。</p>
<p>另外，文本切割还可以帮助限制输入的长度，以满足模型的输入限制或资源限制。通过将文本切割成块，可以更好地管理模型的内存和计算需求。</p>
<p>总的来说，在转换为向量存储之前，还要对原始数据分为有意义的块，作为后续索引的单位？？。</p>
<p>![[Pasted image 20240303183026.png]]</p>
<h4 id="导入包"><a href="#导入包" class="headerlink" title="导入包"></a>导入包</h4><h5 id="第一类"><a href="#第一类" class="headerlink" title="第一类"></a>第一类</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例，还有其他分割器，基于文本</span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> RecursiveCharacterTextSplitter, CharacterTextSplitter</span><br></pre></td></tr></table></figure>

<p>RecursiveCharacterTextSplitter”和”CharacterTextSplitter”都是用于文本分割的类，但它们有不同的实现方式和适用场景。</p>
<ol>
<li><p>RecursiveCharacterTextSplitter（递归字符文本分割器）：</p>
<ul>
<li>递归字符文本分割器是基于递归的分割方法，它将文本逐层地切割成更小的片段。</li>
<li>它使用递归算法，将文本分割成单个字符或字符的子序列。例如，将”Hello”分割为[“H”, “e”, “l”, “l”, “o”]。</li>
<li>递归字符文本分割器适用于一些需要对文本进行字符级别处理的任务，例如生成文本的字符级别表示或字符级别的语言建模。</li>
</ul>
</li>
<li><p>CharacterTextSplitter（字符文本分割器）：</p>
<ul>
<li>字符文本分割器是将文本按照固定长度切割成块的方法。</li>
<li>它将文本按照指定的块大小分割成连续的字符序列。例如，将”Hello, world!”以块大小为5分割为[“Hello”, “, wor”, “ld!”]。</li>
<li>字符文本分割器适用于一些需要对文本进行块级别处理的任务，例如将文本输入模型进行批处理或限制输入长度。</li>
<li>默认的分隔符是‘\n’，如果没有这个分隔符，即使到达 长度也不会分隔。</li>
<li>带有回溯的正则表示</li>
</ul>
</li>
</ol>
<h5 id="第二类"><a href="#第二类" class="headerlink" title="第二类"></a>第二类</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于 token</span></span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> TokenTextSplitter</span><br><span class="line">text_splitter = TokenTextSplitter(chunk_size=<span class="number">1</span>, chunk_overlap=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>因为有许多基于 token 计数设计的 LLM 上下文窗口</p>
<h5 id="第三类"><a href="#第三类" class="headerlink" title="第三类"></a>第三类</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 会为块，添加元数据信息</span></span><br><span class="line"><span class="comment"># 例 </span></span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> NotionDirectoryLoader</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> MarkdownHeaderTextSplitter</span><br><span class="line">markdown_document = <span class="string">&quot;&quot;&quot;# Title\n\n \</span></span><br><span class="line"><span class="string">## Chapter 1\n\n \</span></span><br><span class="line"><span class="string">Hi this is Jim\n\n Hi this is Joe\n\n \</span></span><br><span class="line"><span class="string">### Section \n\n \</span></span><br><span class="line"><span class="string">Hi this is Lance \n\n </span></span><br><span class="line"><span class="string">## Chapter 2\n\n \</span></span><br><span class="line"><span class="string">Hi this is Molly&quot;&quot;&quot;</span></span><br><span class="line">headers_to_split_on = [</span><br><span class="line">    (<span class="string">&quot;#&quot;</span>, <span class="string">&quot;Header 1&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;##&quot;</span>, <span class="string">&quot;Header 2&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;###&quot;</span>, <span class="string">&quot;Header 3&quot;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">markdown_splitter = MarkdownHeaderTextSplitter(</span><br><span class="line">    headers_to_split_on=headers_to_split_on</span><br><span class="line">)</span><br><span class="line">md_header_splits = markdown_splitter.split_text(markdown_document)</span><br><span class="line"></span><br><span class="line">md_header_splits[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切割的  Hi this is Jim\n\n Hi this is Joe\n\n \ 的元数据中会有 head1 和 head2 </span></span><br></pre></td></tr></table></figure>
<h4 id="包的使用"><a href="#包的使用" class="headerlink" title="包的使用"></a>包的使用</h4><p>只有两个成员函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create_documents()</span><br><span class="line">split_documents()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回溯</span></span><br><span class="line">r_splitter = RecursiveCharacterTextSplitter(</span><br><span class="line">    chunk_size=<span class="number">150</span>,</span><br><span class="line">    chunk_overlap=<span class="number">0</span>,</span><br><span class="line">    separators=[<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n&quot;</span>, <span class="string">&quot;(?&lt;=\. )&quot;</span>, <span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>]</span><br><span class="line">)</span><br><span class="line">r_splitter.split_text(some_text)</span><br></pre></td></tr></table></figure>
<h3 id="嵌入"><a href="#嵌入" class="headerlink" title="嵌入"></a>嵌入</h3><p>将文本转为数字格式<br>将块放入索引之中 </p>
<h4 id="转换为向量"><a href="#转换为向量" class="headerlink" title="转换为向量"></a>转换为向量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings.openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line">embedding = OpenAIEmbeddings()</span><br><span class="line"></span><br><span class="line">sentence1 = <span class="string">&quot;i like dogs&quot;</span></span><br><span class="line">sentence2 = <span class="string">&quot;i like canines&quot;</span></span><br><span class="line">sentence3 = <span class="string">&quot;the weather is ugly outside&quot;</span></span><br><span class="line"></span><br><span class="line">embedding1 = embedding.embed_query(sentence1)</span><br><span class="line">embedding2 = embedding.embed_query(sentence2)</span><br><span class="line">embedding3 = embedding.embed_query(sentence3)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">np.dot(embedding1, embedding2)</span><br><span class="line">np.dot(embedding1, embedding3)</span><br><span class="line">np.dot(embedding2, embedding3)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="向量存储与使用"><a href="#向量存储与使用" class="headerlink" title="向量存储与使用"></a>向量存储与使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ! pip install chromadb</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line">persist_directory = <span class="string">&#x27;docs/chroma/&#x27;</span></span><br><span class="line">!rm -rf ./docs/chroma  <span class="comment"># remove old database files if any</span></span><br><span class="line">vectordb = Chroma.from_documents(</span><br><span class="line">    documents=splits,</span><br><span class="line">    embedding=embedding,</span><br><span class="line">    persist_directory=persist_directory</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(vectordb._collection.count())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 持久化存储</span></span><br><span class="line">vectordb.persist()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用，基本查询，寓意相似性查询</span></span><br><span class="line">question = <span class="string">&quot;is there an email i can ask for help&quot;</span></span><br><span class="line">docs = vectordb.similarity_search(question,k=<span class="number">3</span>) <span class="comment"># 3个最佳结果</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(docs)</span><br><span class="line">  </span><br><span class="line">docs[<span class="number">0</span>].page_content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="边缘情况检索的失效问题"><a href="#边缘情况检索的失效问题" class="headerlink" title="边缘情况检索的失效问题"></a>边缘情况检索的失效问题</h4><p>原因：基于语义进行查找。</p>
<ol>
<li>重复的查询结果</li>
<li>查询不能准确把握语义</li>
</ol>
<h3 id="高级检索"><a href="#高级检索" class="headerlink" title="高级检索"></a>高级检索</h3><h4 id="MMR-最大边际相关性"><a href="#MMR-最大边际相关性" class="headerlink" title="MMR 最大边际相关性"></a>MMR 最大边际相关性</h4><p>如果选择与嵌入空间中查询最相似的文档，实际上可能会错过一些多样化的信息<br>指定搜索源<br>这样做的代价是需要对语言模型进行更多的调用，但密非常适合将最终答案集中在最重要的内容上</p>
<h4 id="对话检索链"><a href="#对话检索链" class="headerlink" title="对话检索链"></a>对话检索链</h4><p>在检索问答链的基础上添加了一个新的部分，不仅有记忆，它将历史记录和新问题压缩成一个独立的问题以便传递给向量存储以查找相关文档</p>
<h3 id="记忆功能"><a href="#记忆功能" class="headerlink" title="记忆功能"></a>记忆功能</h3><p>保持一个聊天记录的列表，作为历史记录的缓冲区，并且每次都将这些消息与问题一起传递给聊天机器人。</p>
<p>Feel free to copy this code and modify it to add your own features. You can try alternate memory and retriever models by changing the configuration in <code>load_db</code> function and the <code>convchain</code> method. <a target="_blank" rel="noopener" href="https://panel.holoviz.org/">Panel</a> and <a target="_blank" rel="noopener" href="https://param.holoviz.org/">Param</a> have many useful features and widgets you can use to extend the GUI.<br>请随意复制此代码并对其进行修改以添加您自己的功能。 您可以通过更改“load_db”函数和“convchain”方法中的配置来尝试替代内存和检索器模型。 <a target="_blank" rel="noopener" href="https://panel.holoviz.org/">Panel</a> 和 <a target="_blank" rel="noopener" href="https://param.holoviz.org/">Param</a> 有许多有用的功能和小部件，可用于扩展 GUI。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3  install -U docarray</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pip3  install pydantic==<span class="number">1.10</span><span class="number">.9</span></span><br></pre></td></tr></table></figure>
                        
                    </div>
                </div>
            </div>
            
                <footer class="kratos-post-meta-new">
                    <span class="pull-left">
                        <time datetime="2024-04-23T03:05:06.525Z" itemprop="datePublished">
                            <a><i class="fa fa-calendar"></i> 2024-04-23</a>
                        </time>
                        
                        
                            <!-- 当前仅支持valine/waline自带的统计功能 -->
                            
                        
                        
                            <!-- 当前仅支持waline自带的统计功能 -->
                            
                        
                    </span>
                    
                    
                        <span class="pull-right">
                            <a class="read-more" href="/2024/04/23/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/RAG%20%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA/" title="留言">留言<i class="fa fa-chevron-circle-right"></i></a>
                        </span>
                    

                </footer>
            
        </article>
    



    <div class='text-center pagination'>
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right"></i></a>
    </div>



    <div class="hidden">
        <!-- 加载文章阅读对应的统计功能，评论自带的那种 -->
        
    </div>



        

            </section>

        

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
        <div class="sticky-area">
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/avatar.webp" loading="lazy" decoding="auto" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center">生于尘埃，溺于人海，死于理想的高台</p>
    </div>
    <div class="site-meta">
        <a class="meta-item" href="/archives/">
            <span class="title">
                文章
            </span>
            <span class="count">
                98
            </span>
        </a>
        <a class="meta-item" href="/categories/">
            <span class="title">
                分类
            </span>
            <span class="count">
                0
            </span>
        </a>
        <a class="meta-item" href="/tags/">
            <span class="title">
                标签
            </span>
            <span class="count">
                1
            </span>
        </a>
    </div>
</aside>
            
                

            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>标签聚合</h4>
      <div class="tag-clouds">
        <a href="/tags/excalidraw/" style="font-size: 0.6em;">excalidraw</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>最新文章</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/2024/04/23/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%8D%95%E8%AF%8D/"><i class="fa  fa-book"></i> Englislearning</a>
            
          
        
          
          
            <a class="list-group-item" href="/2024/04/23/hello-world/"><i class="fa  fa-book"></i> Hello Worldaaaaaaa</a>
            
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
          
          
        
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  class="ap-lrc"  >
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        <!-- Keep for compatibility -->
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <!-- New links -->
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2024 心咖 版权所有.</li>
                            <li>本站已运行<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by dreamin.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.io" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            
                            
                        </div>
                    </ul>
                </div>
            </div>
        </div>
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="/vendors/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="/vendors/nprogress@0.2.0/nprogress.js"></script>
<script>
    if (!window.kr) {
        window.kr = {};
    }
    window.kr.notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));
    window.kr.siteRoot = "/";
</script>


    <script async src="/js/candy.min.js"></script>



    <script defer src="/vendors/aplayer@1.10.1/dist/APlayer.min.js"></script>
    
    <script defer src="/vendors/meting@2.0.1/dist/Meting.min.js"></script>
    <meting-js
        server="netease"
        type="playlist"
        id="3204190542"
        order="random"
        fixed="true"
    >
    </meting-js>



    <script defer src="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>



<!-- Extra support for third-party plguins  -->


    </body>
</html>