# 背景

互联网和安全不断发展，互联网的开放性也带来了许多内在的安全隐患。

为了保护用户信息，当前已经产生了多种认证方式： 
身份认证的分类：
1. 用户知道的：密码，个人识别码
2. 用户拥有的：U盾，加密卡
3. 用户本身的：
	1. 生理特征：指纹，虹膜
	2. 行为特征：手写

对于上面这些认证方式，其中密码（即口令）破解是最常见的认证方式，原因主要有：
1. 互联网应用不断发展，人们不得不设置许多满足不同密码策略的密码来保护相应的软件应用程序。
2. 人的记忆能力有限。研究表明，人类只能记住五到七个密码，因此在设置密码时普遍会使用一些低信息熵的密码，比如：
	1. 在多个系统中使用相同密码
	2. 在密码中使用个人相关信息
3. 大量知名网站的密码文件被泄露：比如著名的 rockyou数据集就是2018年受黑客攻击而泄漏的。

且人工智能以及到现在 大模型的产生和发展更进一步增强了破解口令认证系统的能力，因此对于这方面的研究也显得更加迫切和重要。
（对口令认证系统攻击最严重的是口令猜测攻击）
# 口令猜测分类
（
密码猜测的角度|方法：
1. 启发式搜索
2. 概率模型
3. 深度学习
）

根据是否在线（也就是是否与服务器进行交互）：
1. 离线密码猜测
2. 在线密码猜测

（前一种攻击要求身份验证服务器存储用户帐户密码文件，然后攻击者在本地主机上猜测密码。在这种情况下，可以尝试的猜测次数仅受攻击者的计算资源的限制。后者不需要密码文件，攻击者只需要连接到网络即可。然而，可以尝试的猜测次数往往受到服务器安全策略的限制，例如美国国家身份标准NIST-800-63-3，其中规定政府网站系统一个月允许的最大登录失败次数为100次，如果超过100次，帐户将被锁定。）

根据是否利用用户的个人信息：
1. 拖网猜测。
2. 定向猜测，利用用户个人信息。
（拖网猜测主要利用用户选择流行密码的倾向，而定向猜测不仅利用普通用户使用流行密码的漏洞，还利用用户重复使用密码和使用个人信息构建密码的漏洞。在个人身份信息和历史密码等信息的帮助下，定向密码猜测的成功率明显高于相同猜测次数的拖网猜测）


是否使用人工智能：
1. 传统攻击
2. 神经攻击
（前者将密码猜测作为一项文本生成任务，依靠人工智能相关技术在大规模密码训练语料库上生成文本密码。后者封装了其他方法，不包括深度神经网络猜测方法。）


（几乎所有现有的工作都是离线猜测，而在线猜测太难在100个猜测内猜出一个密码。所以当前的分类方式主要为：传统的。。基于神经网络的。。）

（说一下如何比较生成密码的质量：
	1. 生成的唯一密码个数和比例；
	2. 生成密码的速度；
	3. 生成的密码和训练数据集之外其他数据集的匹配个数
   ）

### 拖网猜测

#### 传统拖网猜测
1. 启发式算法
	> 这些算法没有严格的理论体系，严重依赖于零散的奇思妙想，例如，基于开源软件使用精心设计的猜测序列构建独特的猜测词典。这些启发式方法很难重现，也很难相互公平地比较。因此，在这里，我们只介绍一些常用的启发式密码猜测工具。
	1. Jtr是一个密码猜测工具，专注于破解UNIX/Linux系统的弱密码。在JTR中有四种模式--简单破解模式、单词表模式、增量模式和外部模式。
	2. Hashcat是世界上速度最快、最先进的密码恢复实用程序，支持针对300多种高度优化的哈希算法的五种独特攻击模式。Hashcat目前支持Linux、Windows和MacOS上的CPU、GPU和其他硬件加速器，并具有帮助启用分布式密码破解的设施。
		> 彩虹攻击：
		> 一种基于预先计算和空间-时间折中的攻击方法。通过事先计算大量的密码和散列值之间的对应关系（彩虹表），以便在攻击时快速查找并破解散列值。彩虹表是一个预先计算的表格，其中包含了大量的密码和对应的散列值。通过在彩虹表中进行查找，攻击者可以找到与目标散列值匹配的原始密码。
2. 概率上下文无关语法
	该算法的核心假设是密码的字母段L、数字段D和特殊字符段S相互独立。该算法包括训练和猜测两个阶段。
	1. 在训练阶段，最关键的是根据泄露的密码数据集计算密码模式(结构)和字符成分(语义)的频率。
	2. 在猜测阶段，根据训练阶段得到的模式频率表和语义频率表生成具有频率猜测的集合，以模拟真实密码的概率分布。
	粒度太细，无法获得字符之间的语义关系，改进：
	1. 基于词的内聚力和自由度提取密码中的语义片段，并对基于语义片段的PCFG算法进行改进
	2. 密码视为由几个块组成，其中块是频繁出现在一起以模拟密码的相关字符的序列。
	3. 扩展字节对编码(BPE)算法，它使用块词汇表平均长度的可配置参数来替换合并操作的数量。
	4. 为了解决长密码猜测的困难，提出了一种改进的基于PCFG的LONG
3. 马尔可夫序列决策
	该算法的核心假设是用户从前到后依次构造口令。它不像PCFG那样分割密码，而是训练整个密码，并通过从左到右链接字符来计算密码的概率。
	1. 传统的马尔可夫模型因其结构简单、推理速度快而被广泛应用于口令猜测工作中。但是，它也有一定的缺陷，如过度拟合、重复率高、基于随机抽样生成的密码覆盖率低等。
	2. 过拟合：将拉普拉斯平滑和结束符号正则化技术应用于马尔可夫模型。平滑策略消除了数据集中的过拟合问题，正则化技术使攻击算法产生的猜测概率总是和为1。
	3. 重复率：设计了一种基于随机抽样的动态分配机制。该机制允许动态调整密码的概率分布，并在猜测过程中严格收敛到均匀分布。基于上述动态分布机制，提出了一种动态马尔可夫模型。
	4. 对口令中的语义段进行建模：提出了一个名为Word马尔可夫的模型，通过语义分段从密码中提取单词的凝聚力和自由度。

#### 神经拖网猜测算法
密码猜测任务视为文本生成问题，核心就是把密码数据集给神经网络进行训练，并利用训练好的模型生成候选密码。
1. 递归神经网络(RNN)：递归神经网络以序列数据为输入，在序列进化方向上递归，所有节点以链的形式连接。 RNN 有许多变体：如： LSTM，GRU，BiLSTM 等。
	1. 步骤：基于RNN的密码猜测方法通常有以下两个步骤：
		1. ·将训练集中的密码序列输入到RNN模型中，以进行顺序文本生成的训练。
		2. 训练好的 RNN 猜测模型旨在根据已有的密码字符生成下一个密码字符，直到输出终止字符位置。
	2. 在整个密码生成过程中，RNN计算任何字符作为下一个密码令牌的概率。对于给定的阈值，概率高于阈值的密码将被放入密码猜测集中作为有效密码。
	3. 一些变体：
		1. 对密码单词进行切分，在词段的基础上使用BiLSTM生成密码。
		2. 层次语义模型HSM，该模型将LSTM和语义分析相结合，用于挖掘用于密码猜测的词之间潜在的概率关系。
		3. 基于汉字音节的密码猜测方法。该方法将汉语音节作为整体元素对密码进行解析和处理。然后，在LSTM神经网络中对处理后的密码进行训练以生成密码。
		4. 特别是具有注意力机制的RNN来组合和内插同一组用户的信息，以定义比他们的密码分布更稳健和准确的优先级。推理时使用辅助数据来适应目标密码的分布。通过这种方式，开发了一种利用辅助信息并实例化上下文感知口令计量和猜测攻击的全自动方法，而不需要来自目标口令分布的任何明文样本。
2. 生成式对抗网络（GAN）：
	1. 基于GAN的密码猜测模型由密码生成器和鉴别器组成。这两个网络相互对抗，不断地调整参数。最终目的是使鉴别器网络无法判断生成网络的输出是否真实，从而达到口令生成的效果。
	2. 问题：离散密码数据的不可微性可能导致梯度反向传播失败，基于GAN的密码猜测模型训练难以收敛，由GAN模型生成的密码重复率较高。
	3. 离散数据不可微问题解决：
		1. 使用Gumbel-Softmax松弛技术来训练基于GAN的密码猜测模型。
		2. 使用通过附加的自动编码器获得的真实口令的平滑表示。
		3. 种基于SeqGAN的密码猜测方法RLPassGAN，该方法使用策略梯度来确保模型参数的持续优化。
	4. 收敛困难的问题解决：基于双向生成对抗网络的猜测算法，提高了算法的收敛速度。与传统的GaN相比，它可以在更短的时间内产生相同数量的样本
	5. 重复率高问题解决：
		1. 使用蒙特卡罗搜索来评估中间层输出处的不完整密码序列，减少冗余的合成密码。（此外，通过蒙特卡罗搜索来评估输出的不完整密码序列。蒙特卡罗是一种使用大量随机样本来了解特定系统的计算方法。）
		2. 使用鉴别器和控制器构建额外的控制器网络，以分别学习生成的密码分布与真实密码分布和均匀分布之间的度量。然后利用这两个度量对生成器进行训练，从而降低了口令生成的重复率。
		3.  RLPass：还创新性地将表征学习用于密码猜测。具体地，将密码投影到隐藏空间，并且使用隐藏空间中的密码表示之间的距离来定义密码的相似性。基于口令的强局部性和弱局部性现象，提出了一种动态口令猜测和条件口令算法。
	6. GAN的模型生成的长密码质量较低的问题解决：设计了一种基于DenseNet的GAN密码猜测结构DenseGAN，并提出了两种新的密码猜测DenseGAN模型，这两种模型都能生成高质量的密码猜测。
3. 自动编码器（AE）：它基于反向传播算法和优化方法，使用输入数据本身作为监督来指导神经网络学习映射关系，以获得重建的输出。AE 包括编码器和解码器两部分。根据学习范式，AE 可分为欠完备自动编码器、正则化自动编码器和变分自动编码器，其中前两种是判别性模型，后者是生成性模型。
	1. 在拖网密码猜测的研究中，通常使用**变分自动编码器**来生成密码猜测。将密码样本输入到VAE的编码器以获得表示，然后使用解码器基于该表示重建样本。基于输入和输出之间的重构损失来训练密码生成器。除了使用最经典的VAE框架来猜测密码，也提出来了许多优化。
		1. 优化 GAN：将VAE技术与GaN技术相结合，用VAE代替GaN生成器，旨在解决离散口令数据的反向传播问题。
		2. 轻量级问题：用门控卷积神经网络(GCNN)代替了复杂的RNN生成单元，降低了模型的复杂性。
4. Transformer.
	![[Pasted image 20240305201324.png]]
	Transformer 模型采用编解码器体系结构，并使用注意力机制替换 Seq2Seq 模型中的递归结构，以实现序列建模的并行化。这种并行化结构给自然语言处理 (NLP) 领域带来了巨大的冲击。随着研究的深入，相关技术逐渐从自然语言处理向计算机视觉 (CV)、语音、生物、化学等领域发展。同样，在拖网密码猜测的研究中也出现了一些基于Transformer的方法：
	1. 基于改进 Transformer 的口令猜测模型：将消息（个人信息和密码的相关性）权重引入到数据预处理中，并在模型中使用改进的波束搜索算法来快速搜索排名靠前的密码猜测。
	2. PassBERT：基于双向 Transformer 的猜测框架，首次将预训练/微调的范式应用于密码破解。具体地说，
		1. 首先，作者设计了包含一般密码分布知识的通用密码预训练模型。
		2. 然后，提出了三种特定于攻击的微调方法来定制预先训练的口令模型以适应以下真实攻击场景：条件口令猜测、目标口令猜测和基于自适应规则的口令猜测。最后，他们进一步提出了一种混合密码强度计来降低这三种攻击的风险。
5. Reinforcement Learning (RL) 强化学习
	1. RL是机器学习的范例和方法之一，用于描述和解决智能代理在与环境交互过程中最大化回报或实现特定目标的学习策略问题。密码生成器是代理，每个生成的密码序列代表一个完整的轨迹，生成过程中的每个字符都被视为一个操作。例如，由时间戳t生成的字符是action at。根据由所生成的不完整序列确定的关于当前状态ST的随机策略来生成每个动作At。生成器根据一组随机策略从任意字符生成密码，直到满足预定长度。
	2. RLPassGAN：遵循SeqGAN，将密码猜测视为一个连续决策，并使用策略梯度 来确保参数可以连续优化。
6. Flow： （一个强大的密度估计统计工具）流动模型的一个非常独特的特征是，它的转变通常是可逆的。流模型不仅找到了从分布Z转移到分布X的网络路径，而且该路径还允许X改变为Z。简而言之，流模型找到了分布Z和X之间的双向路径（Z和X的数据维度必须相同）。
	1. PassFlow：基于产生流模型的口令猜测方法。基于流的口令猜测模型使用精确的对数似然计算和优化，使潜在变量的推断更加准确。此外，还给出了潜在空间的一种有意义的表示，这使得探索潜在空间的特定子空间和内插等操作成为可能。（密码猜测方面优于现有的基于GAN的方法）

#### 另一种分类
根据泄露的数据集和目标密码是否来自同一数据源，拖网场景可以进一步分为站内场景和跨站场景。 虽然跨站密码猜测场景较为真实，但攻击者一般以掌握目标数据的部分分布信息为前提来猜测密码。


### 定向密码猜测
定向整体来说其实是对传统的优化，比如不改变核心思想的前提下修改嵌入，数据预处理等方面。
#### 神经定向密码猜测

随着自然语言处理技术的发展，一些复杂的神经网络被应用到目标密码猜测领域。
1. PG-PASS：由指针生成网络组成的有针对性的口令猜测模型。该工作创新性地将目标口令猜测作为一项摘要任务，并将智能摘要领域中常用的指针网络技术应用于该任务。需要注意的是，除了用户的人口统计相关信息(姓名、生日等)外，攻击者还可以利用用户在其他网站上泄露的密码进行有针对性的攻击。可以预期，这种利用用户密码重复使用这一易受攻击行为的定向攻击可能比基于人口统计相关信息的攻击更具危害性。
2. 重用模型：重用或微调旧密码来生成新密码的事实，引入深度学习技术来表征用户的密码重复使用行为。更具体地说，他们训练了序列到序列(Seq2seq)模型，以预测将现有密码转换为其姊妹密码所需的修改，并在大规模数据集(即4iQ数据集)上进行了验证。
3. PASS2EDIT：有针对性的密码猜测算法，用于模拟日益严重的凭据篡改攻击，在该攻击中，攻击者利用受害者泄露的密码来提高在其他站点猜测受害者密码的成功率。特别是，他们提出了一种多步决策训练机制，并建立了一个分类神经网络来学习一步编辑操作对现有密码的反应。由于每项工作使用的数据集不同，因此很难进行横断面比较。

#### 传统定向密码猜测
攻击者使用与目标人员相关的个人信息来增强猜测。

基于拖网马尔可夫攻击模型的定向攻击猜测方法：
1. 基本思想是，关于使用某些个人信息的人口的百分比，攻击目标也将具有相同的使用该个人信息的可能性百分比。
	1. 首先将PII划分为几种类型，如用户名-A、电子邮件前缀-E和名称-N，并根据所需的粒度进一步细分每种广泛的类型。然后，将训练集的每个密码中的所有PII替换为对应的PII类型。
	2. 训练阶段的其余步骤与行走马尔可夫模型的步骤相同。
	3. 猜测集生成阶段分为两个步骤。
		1. 在第一步中，运行马尔可夫模型以生成中间猜测集合，该中间猜测集合包含直接可用的猜测，
		2. 第二步用相应的PII信息替换中间猜测中的基本PII类型字符。

基于PCFG的定向攻击猜测方法：
1. --Personal-PCFG。。其基本思想与PCFG攻击模型相同：根据字符类型和长度对密码进行切片。为了实现这一思想，将六种PI字符类型 (即用户名-A、电子邮件前缀-E、姓名-N、生日-B、电话号码-P和ID-G)等同于拖网PCFG模型中的L、D和S，从而在个人PCFG中有九种类型的字符。然后，在训练过程中，与拖网PCFG攻击模型中一样，训练集中的每个密码根据相应的字符类型及其长度进行分段。
2. TarGuess Wang等人。提出了一个框架，它用四个数学概率模型系统地刻画了典型的定向猜测场景。
	1. 第一个场景TarGuess-I旨在利用用户的PII创建在线目标密码猜测。为了在密码中表示PII令牌，除了PCFG模型中的L、D和S标签外，作者还定义了基于个人信息类型的28个PII标签(例如，N1−N7和B1−B10)。对于每个PII标签，其下标编号表示该类型的PII使用的细分，而不是指示相应长度的下标编号，例如L、D和S标签。例如，N表示名称信息，而N1表示全名，而n2表示全名的缩写
	2. 第二个是Targuess-II，目的是根据用户在其他网站(例如Dodonew)中泄露的密码来猜测目标网站(例如CSDN)中的用户密码。具体地，作者提出了6种结构级和2种字符级助记转换来描述密码重用，并基于上述重用规则使用马尔可夫模型来刻画上下文无关的转换文法。
	3. 第三个是TarGuessIII，目的是使用姐妹密码和一些PII信息来猜测用户的密码。TarGuess-III将PII信息引入到TarGuess-II模型中，允许在结构级密码重用中嵌入PII信息。
	4. 与TarGuess-III相比，TarGuess-IV场景中的攻击者知道难以量化的额外PII(例如，性别、教育)。为了解决某些PII难以直接体现在口令中的问题，在这种难以量化的PII的基础上，巧妙地引入贝叶斯理论来计算口令的重用概率。

3. RFGuess-PII.在RFGuess的基础上，Wang et al.提出了一种新的目标口令猜测模型RFGuess-PII。密码训练和生成过程类似于拖网猜测场景。不同的是，通过新的PII匹配，密码中的PII字符串被替换为相应的数字标签。这种新的PII匹配旨在最小化信息熵，并试图准确地提取整个用户组的PII使用行为。PII匹配算法的第一步是细分PII的各种可能的变换，并使用数字标签来表示它们。第二步是为训练集中的每个密码列出具有PII标签的所有可能的表示。然后，按频率从高到低对表征进行排序。

4. RFGuess-重复使用。除了基于PII的针对性密码破解研究外，作者还专注于对用户的密码重复使用行为进行建模。他们还考虑了结构级和段级转换，如TarGuess-II。具体地，它们通过计算训练集中每个密码对的编辑矩阵来计算结构级转换，并训练基于随机森林的段级转换(即，相同类型的字符串内的转换，例如字母段中的密码→密码)模型。

5. TG-SPSR图谱。马尔可夫模型和PCFG模型转化为目标攻击，提出了一种基于结构划分和字符串重组的系统目标攻击模型，称为TG-SPSR。在结构划分阶段，除了将密码划分为类似于PCFG的基本结构外，还在基本语法模式中定义了基于轨迹的键盘，并引入了索引位来准确描述特殊字符的位置。此外，基于定义的9条修改规则，构造了一个BiLSTM分类器来重用和修改密码的行为。


# 可能的方向
总体来说还是做的工作挺多的，16-23年提出来了三十多种方法，2016年至2018年零星出版数量较少，2021年增至9种。。但是当前比较热门的还是基于深度学习的密码猜测方法。
1. 修改模型结构提高模型训练时的速度：在低资源的情况下快速执行密码猜测也是具有挑战性的。
2. 尝试大模型：预训练的语言模型近年来在自然语言处理领域应用很成熟。可以尝试关于密码猜测的预训练/精调范式，将预先训练的语言模型强大的通用语言建模功能与现有的密码猜测工作结合起来
3. 尝试更多模型：目前的神经密码猜测方法都有一个前提，即密码字符串是一个字符序列，使用序列编码对密码进行处理。比如根据密码的语义依赖将密码组织成图，并使用最新的图神经网络(GNN)相关技术进行采样和生成。
4. 传统猜测方法与深度学习方法相结合。比如用深度学习生成规则等。


# 之后的想法
1. 这两周涉及到了解一些背景所以读的也比较仔细，后面计划读快一些，重点关注方法和创新性。
2. 选择较新，效果较好，的论文尝试复现，分析数据，寻找优化的点。

