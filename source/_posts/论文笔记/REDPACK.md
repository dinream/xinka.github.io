# 摘要
1. 传统基于规则的方法依赖于专家知识
2. 最新的基于深度学习方法，passGAN rpassGAN 在某些方面不如 PCFG
3. 不同的深度学习方法有不同的候选密码空间，且无法重叠。
4. 本文提出 REDPACK ，解决了 GAN 方法的不足，以有效的方法集合了多个候选密码生成器模型。
	1. 使用 rPassGAN 的候选密码鉴别器作为密码选择器。
	2. 有选择的搜集密码，我们实现了更真实的密码字典。
5. 在符号，数字，大小写字母组成的密码字典上测试我们的系统。
	1. 优于 基于规则，GAN，PCFG，
	2. 生成候选密码减少 65% 时，破解性能仅损失 20%。

# 引言
1. 基于规则破解。基于专家的知识扩展性差。
2. 先进的密码破解很有用
	1. 防御角度：作为密码强度估计器
	2. 攻击角度：通过多种方式利用先进的密码破解方法。
		1. 个人角度：破解自己忘记了的密码。
		2. 社会层面：执法机构需要破解密码来收集犯罪证据。
## 旧的：Recurrent PassGAN
对 PassGAN 的改进，弥补基于规则的方法和数据驱动的方法，例如马尔科夫模型等。
1. 模型足够表示用户使用密码的模式和上下文结构。
2. 深度学习不需要密码属性和结构的先验知识，只从训练数据中学习特征。

普通 PassGAN：使用了Wasserstein GAN梯度惩罚（WGAN-GP）[11]模型。 WGAN-GP 的基础深度神经网络是基于卷积神经网络 (CNN) 的残差网络。

rPassGAN 通过修改PassGAN的基础神经网络类型和结构来提高密码破解性能。

rPassD2CGAN（rPassGAN 的双鉴别器版本）的性能优于 rPassGAN。然而，在rPassD2CGAN的训练过程中，它有时会变得不稳定。因此，我们通过使用另一个模型 rPassD2SGAN 来克服这个弱点。我们通过多个实验证明了 rPassGAN 生成的候选密码对于增强密码强度估计器的有效性。

与概率上下文无关语法（PCFG）和其他马尔可夫模型（例如 OMEN [1]）相比，rPassGAN 有时破解的密码较少。

## 新的：REDPACK

核心：通过少量猜测来最大化密码破解性能。
策略：
1. 有选择地收集更真实的候选密码，以提高密码破解的效率。如果可以使用各种模型的候选密码字典。
2. 相对论平均标准 GAN [13] 的判别器作为估计器运行，它评估来自各种预先生成的候选者的输入密码的真实性。
3. 强调：通常只使用 GAN 生成器，我们还使用了 GAN 鉴别器。
贡献：
1. GAN 判别器用于帮助生成密码。
2. REDPACK 能用多个预生成的候选密码制作更有效的候选字典。
3. 为 REDPACK 构建了一个自定义规则集。

## 文章结构
1. 第 2 节：相关密码猜测模型
2. 第 3 节：GANs 和 relativistic average GANs
3. 第 4 节：REDPACK 的概念和架构
4. 第 5 节：训练超参数的配置过程。实验结果
5. 第 6 节：结论


# 相关工作
1. 基于规则的方法：
	1. hashcat ，JTR 开源软件多种攻击方式。
	2. 马尔科夫模型。
	3. 缺点：有明确的密钥空间。
2. 马尔可夫和 PCFG。
	1. 使用符号：数字，字母，符号，单词。组合包含在特定概率分布中
	2. 使用马尔可夫过滤器消除滴概率密码
	3. 使用彩虹标加速。
	4. 图灵机处理特殊符号密码。
	5. 一些改进
	6. PCFG 使用学习语法结构，密码组合。
	7. 一些优化。
3. 深度学习方法
	1. PassGAN ：WGAN-GP 代价函数 + CNN
	2. rPassGAN：RNN
	效果：能破解 PCFG 等其他模型无法破解的密码。

# 背景知识
## GAN
1. [[GAN]] : GAN, WGAN, IWGAN 。其中 IWGAN 实验激发了 Hitaj 等人的兴趣。 [9]将IWGAN应用于密码猜测问题。 他们将创建的模型称为 PassGAN。
## Relativistic average GAN
1. GAN 可分为 IPM 和 non-IPM，
	1. non-IPM 在学习阶段不稳定，模型优化困难。
	2. IPM： Jolicoeur [13] 分析了 SGAN 的损失函数，以分析非基于 IPM 的 GAN 的局限性，并提出了一种相对论 GAN 来解决这个问题。 
2. 来源：
	1. 问题：古德费洛等人。 [10]证明，当判别器以 0.5 的概率对真实数据进行分类时，GAN 训练达到全局最优。 然而，在许多情况下，判别器将真实数据和假数据都分类为真实数据，这对于训练好的生成器来说是不利的。 
	2. 这是因为判别器没有意识到学习过程中一半的数据是假的； 
	3. 基于 IPM 的 GAN 在学习过程中相对稳定，因为它隐含地解释了这一事实。 
	4. 从散度最小化的角度来看，训练判别器以增加 D(xf)，而 D(xr) 不会相应减少，其中 xr 和 xf 分别表示真实数据和假数据。 为了解决这个问题，Jolicoeur [13] 设计了判别器的输出，使其依赖于真实数据和虚假数据。
3. relativistic GAN
	![[Pasted image 20240416105310.png]]
	其中 C(x) 是假定的批评者 (D(x) = σ(C(x)))。 方程（2）可以解释为判别器对给定真实数据比假数据更真实的概率的估计（D(xf, xr)可以以相反的方式解释）。 如果根据等式（2）设置判别器，则与 SGAN 的生成器仅依赖于假数据不同，相对论性 GAN 的生成器将同时依赖于真实数据和假数据。 然而，它在计算损失时具有 O(m2) 复杂度（m 表示小批量的大小），因为它计算小批量中真数据和假数据之间的批评家的成对差异。
4. RaGAN 
	 为了解决这个问题，Jolicoeur [13] 提出了一种相对论平均 GAN（RaGAN），它对某些给定数据取相反类型数据的期望。 RaGAN 使用以下损失函数来学习判别器和生成器：
	![[Pasted image 20240416105456.png]]
	其中 LD 和 LG 分别表示学习判别器和生成器的损失。 方程(3)的复杂度为O(m)。 RaGAN 的判别器平均估计某些给定数据比相反类型的数据更真实的概率。 Jolicoeur [13] 使用不同的数据集表明，与其他 GAN 模型相比，训练 RaGAN 更快、更可靠，并且 RaGAN 的生成器生成了高质量的假数据。

# 方法介绍：REDPACK

## 概述
1. 背景：之前 GAN 训练完成之后使用 GAN 生成器实现目的，作者在之前的论文中提到了基于 RNN 的 GAN 方法 rPassGAN ，本文使用的就是 rPassGAN 的 判别器
2. REDPACK：GAN 的判别器是在模型训练结束之后使用的。
	![[Pasted image 20240416111123.png]]
	训练阶段：
	1. 生成器生成假密码，鉴别器区分，对抗训练，直到收敛。
	选择阶段：
	1. 使用多个密码生成器产生候选密码。作为训练阶段的结果。（本文使用了 三个或者四个）
	2. 鉴别器计算每个候选密码真实程度的概率。
	3. 将高概率的候选密码提供给 Hashcat等密码破解工具。
## 鉴别器训练结构
架构：
![[Pasted image 20240416143214.png]]
优化基于 RNN 的 GAN （判别器优化：使用了 RaGAN 和 IWGAN 的概念来实现了更强大的判别器）的流程：
1. G 根据给定的任意噪声分布生成假密码，图中绿色路径；
2. 根据等式 (3) ，当且仅当假密码的批评值大于图中蓝色存储所描述的真实数据时，D 才确定假密码为真实密码。
3. 蓝色路径上的真实密码在相反情况下被视为真实的。(这里的相反可能是指的比较对象和)
4. D 给出梯度作为惩罚，鼓励 G 生成更真实的密码，用红色路径表示。
这样的流程使得 D 会生成比标准 GAN 更强大的判断。训练过程，算法描述如下：
 > 	梯度惩罚系数 λ、每个生成器的判别器迭代次数 ncritic 、每个判别器的生成器迭代次数 ngen 、批量大小 m 和 Adam 超参数 α、β1 和 β2。 Critic C 的参数 w 和生成器 G 的参数 θ。 真实密码 xr 和假密码 xf 之间直线上的随机样本 ˆx。
	![[Pasted image 20240416155902.png]]
1. 主要源自 IWGAN，但使用相对论平均 GAN 的损失函数。 大多数符号遵循方程 (3)。 主要区别在于第 9 行和第 15 行中的损失函数。
2. 这些损失函数取决于相对论判别器，估计一种类型密码的批评者相对于相反类型密码的平均批评者。 这种直接比较使 G 能够快速收敛到最佳点并产生高质量的假密码。
3. 此外，由于我们基于 RNN 的 GAN 采用​​ IWGAN，因此我们将梯度惩罚添加到判别器的损失函数中。 此惩罚迫使 ^x 的梯度 2-范数小于 1，其中 ^x 是点对 (xr, xf) 之间直线上的随机样本。 这为 GAN 的训练提供了极大的稳定性。 
4. 另一个重要因素是从第 13 行到第 16 行优化 G 的迭代。尽管大多数 GAN 都有一个在给定 G 上优化 D 的循环，但这不足以最大化 GAN 的性能。 因此，我们添加了训练 G 的循环来稳定和增强我们的 GAN。 根据我们在第 5 节中描述的实验，该因素对 REDPACK 的破解性能具有关键影响。 一般情况下，一旦模型被优化，生成器就被用作生成模型。 相反，我们利用鉴别器作为 REDPACK 的真实密码估计器。

## 密码生成器选择
流程图：
![[Pasted image 20240416171606.png]]
1. 多个候选密码生成器，比如：Hashcat、PCFG、rPassGAN 与 WGAN-GP 以及 rPassGAN 与 RaGAN-GP。
2. 注意：不同损失函数的 rPassGAN 可以作为不同的 生成器使用，因为它们有不同的密码破解结果。
3. 注意：单鉴别器 rPassGAN 和双鉴别器 rPassGAN 也是。
4. 每个候选密码生成器生成的 10 亿个候选密码从字符串转换为张量，传递给鉴别器（D），估计密码真实性。
5. 由最大概率选择器选择最高的密码，转换为 字符串形式。
6. 这些候选者被传输给 Hashcat 破解。

# 评估
## 实验数据准备
1. 大多数之前的研究使用的是 Rockyou 和 Linkedln。
2. 但是本文在性能测试中使用到了包含长密码和 4 级密码的额外密码字典。所以使用 Melicher 等人的密码分类。 [27]。总共有七个训练和破解数据集：
	1. Rockyou 和 LinkedIn 包含一些 4 级密码。 
	2. 我们还使用了来自 Hashes.org 的四个破解密码字典，其中提供了多个破解和泄露的明文密码。 
	![[Pasted image 20240416194910.png]]

## 超参数配置
1. G:D：RaSGAN 通常使用 1:1 或者 1:10 
2. 批次大小： 通常使用 128。使用 64 的批量大小可以来应对训练不稳定。
3. epoch
具体如下图：
![[Pasted image 20240416201514.png]]

## 实验环境
Tensorflow-gpu 1.10.1 和 Python 版本 3.5.4 进行 GPU 计算。 所有实验均在韩国大学NMLab的OpenHPC系统上进行。 发达。 OpenHPC的每个节点运行在具有32GB内存的CentOS 7服务器上； 这些节点使用 Intel Xeon E5 2.20GHz CPU(x2) 和 Nvidia TitanXP 12GB GPU(x4)。


## 实验过程
1. 根据我们之前的研究[8,12]推断，决定破解性能的主要因素是epoch、G/D比和循环神经网络（RNN）细胞类型。
2. 如果 Epoch 过大，会导致过拟合。如图 4a 所示。
3. 提高破解性能，需要在模型中应用较大范围的 G/D 比，但是比较费时。从而退一步：
	因此，我们对RaSGAN-GP成本函数使用1:1和1:10的G/D比进行了实验，如图4b所示。 虽然两者都可能不是最优值，但它们足以说明模型的有效性。 
4. 最后要考虑的因素是神经单元类型。对于基于 RNN 的相对论判别器，有必要确定长短期记忆 (LSTM) [28] 和门控循环单元 (GRU) [33] 之间哪个更好。
![[Pasted image 20240416202041.png]]
结论：整个实验中，200k 训练周期、1:10 G/D 比率和 GRU 单元类型被确定为密码破解的最佳设置并确保通用性，如图 5 所示。
![[Pasted image 20240416202513.png]]


## 实验结果
所有实验，我们的结果都优于其他模型。
1. REDPACK 在数据集 2 到数据集 7 上的破解性能比任何单一密码猜测模型高出 5-20%。 在数据集1（短长密码）的情况下，PCFG在早期破解阶段表现出了很强的性能。 下半程的破解，REDPACK最终反超了PCFG。 然而，随着密码长度变长（从 dataset3 到 dataset7），REDPACK 的性能明显优于 PCFG 和其他密码候选生成器。 也就是说，对于复杂且长的密码，REDPACK的有效性得到了明显的体现。
2. 对于数据集 6 和 7，由于训练数据量较小，我们的团队无法创建 10 亿个 Hashcat 候选者。
3.  在表3中，最大概率选择器从图3中选择的每个模型的候选数量与单个模型的密码破解性能成正比。 这个结果表明REDPACK不是随机选择候选者而是选择性地选择候选者。 此外，这意味着 REDPACK 的鉴别器可以正确评估生成真实密码的概率。

## REDPACK 的限制
1. 选择了更现实的密码候选者。 然而，更现实的密码候选选择并不总是能保证有效的密码破解。将候选密码的数量压缩了，但它也遗漏了一些对密码破解可能很重要的候选密码。
2. 将 OMEN 作为密码候选生成器组件时EDPACK 的候选字典的破解性能恶化。
	原因： OMEN 和 PCFG 都有相似的特性。 它们都以高阶概率生成候选密码（本身就筛选了一些密码）
	对 OMEN 和 PCFG 中的密码候选集应用随机洗牌。 这种简单的方法不能完全消除破解性能的损失。
1. 基于三种不同方法（Hashcat：基于规则、PCFG：基于概率、rPassGAN：基于深度学习）的模型用作生成器时，REDPACK 在我们的实验中效率最高。

## 后续工作
自定义了一套规则集。
1. base64 是 hashcat 最高效的规则集。
2. 搜集：将7条Hashcat规则（best64、dive、specific、generate、InsidePro-PasswordPro、Incisive-leetspeak、T0X1Cv1）组合成一个巨大的规则文件。
3. 测试：每条规则记录有助于密码破解的机会数量。
4. 选择：对于REDPACKU4的自定义Hashcat规则集，选择了100条规则（与best64相同的数量）
试验证明有效的。

