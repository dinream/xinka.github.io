在本文中，我们对学习密码中的语言模式进行了细致入微的研究，并使用最新的评估方法更新了语义 PCFG 的性能，以提供更长的猜测会话的结果 [7]。,我们通过部署在高性能计算基础设施上的大参数扫描实验来实现这一点。,在以下部分中，我们报告了比较 PCFG 性能的实验结果 
	(a) 使用和不使用语义符号（WordNet 含义和专有名称）进行训练； 
	(b) 经过不同级别的语义概括训练； 
	(c) 使用不同大小的密码列表进行训练； 
	(d) 使用最大似然估计（一种将零概率分配给未见字符串的方法）和概率平滑（将概率质量分配给未见字符串）进行训练 [6]。
重要的是，我们将三代 PCFG（Weir 等人[23]、Veras 等人[21] 和 Komanduri [12]）与最新的神经网络模型之一（Melicher 等人[16]）进行了比较。

我们的实验设置包括使用 RockYou 列表训练的语法，以及对从 LinkedIn 和 000webhost 泄露的密码进行测试的语法，以及使用相同数据的独立交叉验证设置。,此外，我们使用语言语法来定性研究最近三个密码泄露的模式：000webhost、Comcast 和 Mate1。,我们提出了这些泄漏的高级图形模型，讨论了语法规则的相似性，并进行了交叉泄漏破解实验。
总之，本文研究了多个参数对 PCFG 和神经网络模型猜测性能的影响，并对最近的密码泄漏进行了基于语法的定性分析。

# 语义 PCFG
## 文本处理流
将每个密码分解为令牌（即终端符号）并为其分配语言属性，从而产生形式的元组（令牌、POS、意义）。
1. 分词： Norvig 的统计算法 [18]，该算法选择具有最高联合概率的分词，其中每个标记的概率使用二元模型计算（来自 Google Web Trillion）词语料库）。
2. 词性标注是通过退避标注器完成的，该标注器由在布朗语料库和 WordNet 以及其他已知与密码相关的利基命名实体语料库（城市，给定）上训练的一般统计模型（三元组、二元组和一元组）组成。名和姓氏）。请注意，拼写错误（例如，passwrd）和替换（例如，passw0rd）不按词性语法和语义语法进行分类。将来可以添加将拼写错误的单词分类为语义类别的模块
3. 语义，见下

## 语义模型
语义模型主要关注单词的意义和语义关系，它利用WordNet等语义资源对单词进行语义标记，以便捕捉密码中的语义规律。
能够提供更详细的密码结构分析，有助于更好地理解密码样本中的模式和提供更可解释的密码强度建议。
语义模型在小样本训练和需要解释性较强的情况下显示出更好的猜测性能。
### 语义
该词的意义取自 WordNet 语料库 [17]，这是一种语言树结构，其中概念通过代表 IS-A 关系的边连接起来，就像狗 IS-A 动物 IS-A 哺乳动物 IS-A 生物一样。每个被词性标注器标注为名词或动词的字母字符串都会收到一个 WordNet 意义键形式的语义标签。单词可能有多种含义，因此我们选择 WordNet 频率最高的含义。
为了使词义具有泛化能力，需要建立映射，以便将低级词义分组为更广泛的类别。这可以通过选择由一组抽象类（内部树节点）组成的树切割来完成，每个抽象类代表其所有后代。因此，如果“运动”类是树木砍伐成员，则任何出现“棒球”的情况。都将在训练的语法中被标记为“sport”。这种映射具有扩大语法推理范围的效果，因为通过抽象类间接提高了未见过单词的概率。
在实践中，包含数据中频率相似的词义的 WordNet 子树往往会比包含异常值的子树映射到更抽象的含义。请注意，高频词更有可能映射到特定类别，通常意味着根本没有抽象（例如，love → love.n.01）。
## 词性模型
关注单词的语法属性，比如名词、动词、形容词等，它利用词性标记器对单词进行词性标记，以便捕捉密码中的语法规律。
词性模型则更适合在短时间内进行密码猜测，因为它能够更灵活地捕捉密码中的语法规律，尤其在初始猜测阶段表现更好。


## 终端平滑

 在 Weir 等人的 PCFG 和语义 PCF G 中，终端概率是通过最大似然（ML）来估计的。
在机器学习中，选择模型的参数是为了最大化给定模型的数据的概率；因此，不会将概率质量分配给看不见的字符串。从理论上讲，这会影响小样本的学习，
语义泛化的有效性取决于终端概率平滑。终端平滑需要两个决定：将哪些词汇添加到语法中以及如何为其分配概率。
1. Wordnet 涵盖了大量单词。我们称之为先验词汇，由以各种方式变形的每个 Wordnet 引理组成：名词以单数和复数形式出现，动词以所有词形变化形式出现。根据可用资源，可以通过分配给语义类别的附加单词列表来丰富先验词汇表（类似于我们处理名称的方式）。
2. 除了先验终端之外，后验词汇表还包括数据中观察到的每个终端。给定非终结符号的终结串为 θˆ i = xi + α N + αd ，
	1.  (1) 其中 xi 是观测频率；
	2. N 是非终结符号下观测频率之和；
	3. α 称为伪计数，可以被解释为假定先验观察字符串的次数（当 α = 0 时，默认为 ML）；
	4. d 是给定非终结符的词汇大小。
	该估计器 ( ˆθi ) 称为加性平滑或拉普拉斯平滑，当假设先验一致时，它相当于贝叶斯估计量 [15]。当词汇量非常大时，加法平滑可能不准确，就像三元组一样，在这种情况下，更复杂的估计量更合适，比如 Good -Komanduri 使用图灵估计器来训练 PCFG [12]。由于我们的词汇量约为数十万，拉普拉斯估计器就足够了，并且实现更简单。
##### 蒙特卡罗强度估计器
是一种用于测量密码破解成功率的方法。它通过计算测试集中每个语法的密码的概率，然后估计猜测次数。具体来说，猜测次数指的是在尝试所有语法中概率最高的密码之前需要尝试的次数。蒙特卡罗估计器允许我们在无限长度的会话中测量成功率，而无需进行大量的猜测枚举，这在计算上是非常昂贵的。因此，蒙特卡罗强度估计器是一种用于评估密码破解成功率的有效方法。
## 基于语义信息，各个数据集之间的关系？

基于语义信息，RockYou、Comcast、Mate1和000webhost泄露的密码列表之间存在一些相似之处。研究发现，RockYou和Mate1泄露的密码具有很大的语义和结构重叠，表明这两个泄露数据具有相似的语义模式。而在000webhost密码列表中，密码具有明显的统一结构，但在语义上却缺乏一致性，至少在英语语言语法中如此。此外，Comcast密码列表中出现了许多包含类别"worker"和"hacker"的模式，还有包含类别"defender"和"windows"的模式，以及服务名称本身的模式。这些发现揭示了密码泄露的语义偏好与服务的人口统计和主题之间的关联，以及密码政策对所选密码结构的影响。




（a）LinkedIn 密码缺乏强英语语义依赖性； (b) LinkedIn 具有较强的英语语义依赖性，但与 RockYou 中的不同； (c) 英文密码一般缺乏强语义依赖性。



# 总结
这篇文章主要研究了语义密码模型和密码中的语言模式，通过对不同语言模型的大规模分析，比如PCFG和神经网络模型，以及对RockYou，LinkedIn，Mate1，Comcast和000webhost等密码泄露数据进行定性分析和比较。研究发现，PCFG在猜测非随机密码方面表现出色，尤其是在小样本训练集上。此外，语义模型在特定情况下表现出更好的猜测性能。在对不同密码列表的语言模式进行比较时，研究发现了一些有趣的区别，比如Mate1和RockYou泄露数据中共享的语义模式。总的来说，这项研究提供了关于密码模型和语言模式的深入见解，特别是在不同类型的密码列表中的比较分析。


1. 重点是语义密码模型的参数，这是一个用词性和语义信息训练的 PCFG。
2. 未经概率平滑训练的语法往往会过度拟合，平滑可以为用小样本训练的 PCFG 提供强大的能力：仅用 1,000 个 RockYou 密码训练的语法就能够猜测近 500 万个 000webhost 密码，训练样本大小增加到超过 1000 万个密码时，收益递减。
3. 分离了有语义和没有语义的 POS 的影响，发现向语法中添加语义信息的好处与添加 POS 信息带来的收益相比很小，并且取决于训练数据的大小。（维拉斯等人。证明具有语义和词性信息的语法在很大程度上优于 Weir 等人的语法。）
4. 发现 Komanduri PCFG 比其他测试的 PCFG 具有更好的猜测能力，并且存在 Melicher 等人的神经模型的情况。比我们测试的 PCFG 的猜测能力更差。
5. 利用语义模型的解释能力来定性检查最近的密码泄露事件
	1. RockYou 和 Mate1 泄露事件在语义和结构上有很大的重叠，
	2. 而 000webhost 密码具有非常统一的结构，但语义统一性很小，至少从英语语法来看是这样。