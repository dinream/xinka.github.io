# 摘要

1. 本文使用去噪扩散模型；
2. 考虑到密码空间和文本空间的相似性，在输入阶段使用了字节级分词器，并通过修改源代码来优化采样过程。
3. 进行特殊字符编码使得 PassDiff 可以处理可变长度的输入并获得可变长度输出，无需手动截断。
4. 比 PassGAN 训练稳定，破解比例显著提高
5. 去噪步骤增加，能进一步提高破解比例。

# 引言
1. 传统的密码破解有三种：基于字典、基于概率统计模型、基于深度学习
	1. 基于字典：依赖字典和规则
	2. 基于概率统计：如马尔可夫和概率上下文无关文法（PCFG）
		概率上下文无关文法：用标识+个数形式表示密码的结构，然后进行响应的填充。
	3.  基于深度学习：不需要预知识，也不会被限制范围

# 贡献
1. 使用了扩散模型
2. 使用了字节级别的标记器编码输入向量
3. 通过调整代码优化了降噪过程，
# 背景知识以及相关工作
## GAN
1. 生成模型
2. 辨别模型
## DDPM
1. 构成：由两个马尔科夫链构成
	1. 前向链：扩散过程，添加噪声。
		目的：经常用于将原始分布转为先验分布
	2. 反向链：降噪过程，转换噪声恢复数据。
		目的：使用从深度神经网络学习的参数化转换内核来反转此过程
2. 去噪过程分两步不断生成新的数据点：首先从先验分布中采样随机数据，然后执行原始采样。
3. 数学过程
	1. 假设 x0 服从一个分布。
	2. 有一个向前传播转换链， 即 转换核心：q(xt|xt-1)，这个通常可以被自定义
	3. 计算得到了 x1，x2, x3,.... 的一个分布
	4. DDPM 一般会在向前传播时把分布转换为一个初始分布。
	5. 扩散过程不断用噪音破坏输入数据，直到丢失所有特征。
	6. 新建数据点：从先验分布中收养一个随机噪音点，构造一个规则逆向马尔可夫链从而逐渐排除噪声。
	7. 从 xT 得到 x0


# PassDiff
1. 标准扩散模型主要用于图像生成
2. Diffusion-LM  改进
	1. 用 transform 学习噪音分布
	2. 添加文本嵌入步骤
	3. 添加舍入步骤
	4. 文本作为输入，将文本嵌入为一个以为整形向量---使用单词级别的 令牌嵌入
	5. 扩散过程中， 这个整形向量被 转为 一维 浮点向量，
	6. 去噪过程的最后：舍入步骤会将这个 一维 浮点向量 转为 一维 整形 向量
	7. 
	8. 只能输出固定长度文本
3. 单词级别的令牌嵌入器 将本文分割为单词，
	1. 嵌入频率高能捕获语义信息，但是容易导致嵌入范围过大
4. 字节级别的令牌嵌入将文本识别为一系列的字节，连续嵌入单字节和多字节
	1. 单字节的语义信息很少
	2. 多字节是 单字节和 单词级别嵌入之间的妥协。
5. 密码空间和 文本空间相似，语义信息 在密码的字符之间比在语料库中弱，
6. 参考 Diffusion-LM 我们使用字符级别的嵌入器
7. 我们发现降噪过程的生成密码长度一致，引入随机因子生成各种长度。
8. 多字节嵌入没有比单字节有明显优势，为了简化，使用单字节。即 一个特殊字节和 95 个特殊字节。
	1. 特殊字节表示为0.
	2. 其余可见字节 按 ascill 顺序表 从 1  到  95 .
	3. 特殊字符的编码可以 处理可变长度的输入并且获取可变的输出，无序手动截断。
	4. Passdiff使用最少的去噪步骤也能产生高质量的输出，建议 5-50，可以将采样速度提高十倍！
	4.
![[Pasted image 20240229164854.png]]
# 实验配置
1. 实验环境：
	1. DELL Precision 5820工作站，128G内存，10个CPU核心
	2. NVIDIA GeForce RTX 3090显
	3. Win10和Ubuntu 22.04下进行的
	4. Win10上进行了PassGAN相关实验，使用rnnPassGAN的源代码[8,17]。与扩散模型相关的实验是 在Ubuntu 22.04上进行，源代码来自minimal-text-diffusion[16]。
2. 数据集
	1. 12306 CSDN RockYou
	2. 去除密码长度超过15，或者有不可见字符的密码，
	3. 8：2 训练集和测试集
3. 超参数
	1. 包括：训练轮次：批次大小：扩散步骤：去噪步骤，输入长度，输出长度，学习率
4. 实验结果
	1. CSDN和RockYou的破解率总体高于12306：重复率都高于12306
	2. CSDN和RockYou数据集的破解率逐渐稳定在40个去噪步骤左右，超过了12306所需的去噪步骤：：训练不足和数据量较大。
	3. 增加数量 训练轮数和批量大小都可以提高破解率。
	4. 随着去噪步数的增加，破解率首先逐渐上升到最大值，然后趋于最佳.
	5. 去噪步骤和训练轮次增加，重复率增加
	6. 重复率越高，生成独一无二的相同长度密码的概率越低
# 比较
1.  我们的PassDiff模型比PassGAN具有显着的优势。当生成108个密码时，我们的模型在12306、CSDN和RockYou数据集上的破解率分别比PassGAN高3.17%、6.33%和13.22%。 另外，这并不是我们在破解率方面最好的表现
2. 但是，我们的模型与传统的密码猜测模型（例如PCFG）之间仍然存在一些差距。
# 总结
本文通过优化扩散模型参数和增加训练轮数，提出了比 PassGAN 训练时间更短、训练过程更稳定的 PassDiff 模型。 但由于扩散模型采样速度较慢，导致本文采用的模型很难生成十亿级字典。扩散模型在构造密码猜测模型方面具有巨大潜力，理论上也能取得很大突破
在未来的工作中，我们将进一步优化参数并调试其他参数，例如扩散步长和学习率。我们计划使用其他神经网络从噪声中学习以提高破解率。我们还将尝试其他编码方法，例如编码两个以上的字符并尝试将它们与PCFG结合。
# 专业名词
