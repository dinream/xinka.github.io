### 监督学习与无监督学习
#### 监督学习
任务：学习一个映射函数，给定任意输入响应做一个好的预测输出。
本质：学习输入到输出的映射的统计规律。
常见情景：回归，分类，标注。（区别在于变量的取值类型）
（1）当输入变量和输出变量均为连续值变量时得到回归任务，它主要用于学习输入变量和输出变量之间的数值映射关系，常见的回归任务有价格预测、趋势预测等，处理回归任务时常用的机器学习模型有最小二乘回归、非线性回归等。
（2）无论其输入变量为离散值还是连续值，当输出变量为有限个离散值时得到分类任务，分类任务是被人们讨论和应用最广泛的任务，它通常用于分门别类，常见的分类任务有图片类别识别、用户分类、文本分类等，处理分类任务时常用的机器学习模型有：k近邻、朴素贝叶斯、决策树、逻辑斯蒂回归模型、支持向量机、神经网络等。
（3）当输入变量和输出变量均为变量序列时得到标注任务，它是分类问题的一种推广，用于学习输入序列和输出序列的映射关系，典型的标注任务有自然语言处理中的词性标注、信息抽取等，处理标注任务时常用的机器学习模型有隐马尔科夫模型和条件随机场等
##### 分类
监督学习是学习一个模型，然后利用该模型对给定的输入预测相应的输出，我们可将模型写成函数形式 Y=f(X) 或条件概率分布形式 P(Y|X) 。
###### 判别模型&生成模型：根据条件概率的计算方式
1. [[判别模型]]
	1. 建模方式：直接对 P(Y|X)  进行建模，它试图描述在给定输入特征 X 的情况下，标签信息 Y 的分布，
	2. 典型判别模型包括： 近邻法、感知机、决策树、逻辑回归和条件随机场等。
	3. 评价：判别模型对条件概率模型直接建模，无法反映训练数据本身的概率特性，但是以分类问题为例，判别模型在寻找最优分类面的过程中，学习了不同类别数据之间的差异。另外，判别模型可以对数据进行各种程度上的抽象、降维，因此可以简化学习问题，学习准确率更高。
2. [[生成模型]]
	1. 对数据特征 X 和标签 Y 的联合分布 p(X,Y) 进行建模，然后利用条件概率公式，即可计算 p(Y|X) ，如下所示:
		$p(Y|X) = \frac {p(X,Y)}{p(X)}$
		一般将其转换为易为计算的方式，如下所示
		$p(Y|X) = \frac {p(X|Y)*p(Y)}{p(X)}$
	2. 举例：朴素贝叶斯方法和隐马尔科夫模型等。
		1. 在朴素贝叶斯方法中，我们通过训练集学习到先验概率分布 p(Y) 和条件概率分布 p(Y|X)，则可得到联合概率分布 p(X,Y)；
		2. 隐马尔可夫模型中，我们通过训练集学习到初始概率分布、状态转移概率矩阵和观测概率矩阵，则得到了一个可以表示状态序列与观测序列联合分布的马尔可夫模型。
	3. 评价：生成模型直接学习联合分布，可以更好地表示数据的分布，更好反映同类数据的相似度。当样本数量比较大时，生成模型往往可以更好地收敛到真实模型上，其收敛速度快。另外，生成模型可以处理含有隐变量的情况，而判别模型对此无能为力。生成模型也可以通过计算边缘分布而检测某些异常值。但实践中，生成模型计算开销一般比较大，而且多数情况下其效果不如判别模型。


#### 无监督学习
和监督学习比较：
1. 无监督学习和监督学习最大的区别就是标签的有无。在监督学习中，训练模型的任务是学习输入特征到标签的映射，
2. 而无监督学习中只有样本的特征向量，故无监督学习的任务是对数据进行深入“挖掘”，其本质是学习数据中的统计规律或潜在结构。对于无监督学习的深入研究对深度学习的复兴上起到了关键的作用。
3. 相比于无监督学习除了拥有额外的标签信息外，还需要有测试样本。机器学习模型在训练集中学习“规律”，然后对测试集使用这种“规律”来评价模型的效果，而无监督学习不需要测试样本，整个过程只需要训练集的参与。
4. 另外，无监督学习相比于监督学习一般拥有更好的拓展性，它在完成训练目标的同时，通常还额外学习到了样本的表示，我们可以将这些表示直接用于其他的任务。
常见任务：降维、聚类、概率模型估计。
（1）降维任务主要用于处理数据的高维度问题，真实数据的特征维度过大容易造成模型的拟合度与可用性降低，我们可以通过降维算法对高维度数据进行“压缩”使之变成低维度向量，从而提高数据的可用性，常用的算法有主成分分析、因子分析、隐含狄利克雷分布等，包括早期的自编码器也可用于数据降维。
（2）聚类任务主要将样本依据一定的规则进行类别分配，即通过衡量样本之间的距离、密度等指标，将关系“近”的样本聚为同一类，以此实现样本的自动分类，常用的算法有层次聚类、k-means聚类、谱聚类等。
 （3）在概率模型估计任务中，对于一个可以生成样本的概率模型，我们使用样本对概率模型的结构、参数进行学习，使得概率模型生成的样本与训练样本最相似。其中一种比较简单的概率密度估计任务便是对随机变量的概率密度函数进行学习，常用的算法有极大似然估计、对抗生成网络、变分自编码器等，这部分内容非常丰富。
 
#### 半监督学习
 半监督学习是介于监督学习和无监督学习的一种方式，即只有小部分训练样本带有标签信息，而大多数训练样本的标签信息空缺。半监督学习包括直推和归纳两类模式，直推半监督学习只对给定的训练数据进行处理，它使用训练数据集中有类别标签和无类别标签的样本进行训练，预测其中无标签样本的标签信息；归纳半监督学习不仅预测训练数据集中无标签样本的标签，更主要的是预测未知样本的标签，两者的区别在于需要预测标签的样本是否出现在训练集中。半监督学习一般用于四类学习场景：半监督分类、半监督回归、半监督聚类、半监督降维等。
 

### 上下文无关语法
上下文无关语法（Context-Free Grammar）和概率上下文无关语法（Probabilistic Context-Free Grammar）的概念。

上下文无关语法是一种形式语言描述方法，用于定义一类语言的语法结构。它由一组产生式规则组成，每个规则包含一个非终结符和一个由非终结符和终结符组成的字符串。其中，α是一个单变量，表示非终结符，而β是由变量或最终值组成的字符串。这些产生式规则定义了从一个起始样本开始，通过替换非终结符，逐步生成包含所有最终值的字符串集合。上下文无关语法的特点是，无论α出现在哪个上下文中，都可以自由地用β替换，而不需要考虑α的上下文。

概率上下文无关语法是在上下文无关语法的基础上引入了概率特性。每个产生式规则都被赋予一个概率值，表示该规则被应用的概率。这样，概率上下文无关语法可以用于建模具有统计特性的语言。例如，在自然语言处理中，可以使用概率上下文无关语法来生成句子或解析句子的结构，并为每个规则分配适当的概率。

总结来说，上下文无关语法是一种用于描述语言的语法结构的方法，其中产生式规则定义了从起始样本开始生成所有最终值的字符串。概率上下文无关语法在上下文无关语法的基础上引入了概率特性，使其适用于建模具有统计特性的语言。

### 多视图学习
多视图学习（Multi-view Learning）是一种机器学习方法，旨在利用来自多个视图或多个特征表示的数据来改善学习性能。在多视图学习中，数据样本可以从不同的视角或特征空间中获取多个不同的表示。通过综合这些多个视图的信息，多视图学习可以提供更全面和准确的数据描述，从而改善模型的泛化能力和学习结果。

传统的机器学习方法通常假设数据特征是从单个视图或特征空间中提取的，因此忽略了不同视图之间的相关性和互补性。而多视图学习则通过融合多个视图的信息来克服这个限制。它可以应用于各种领域和任务，如模式识别、图像处理、文本分类、推荐系统等。

多视图学习的关键挑战是如何有效地利用不同视图之间的相关性。常见的多视图学习方法包括以下几种：

1. 基于特征融合的方法：将不同视图的特征进行融合，生成一个更综合和丰富的特征表示。常见的融合方法包括特征级融合、决策级融合和模型级融合等。
    
2. 基于共享表示学习的方法：通过学习一个共享的低维表示空间，将不同视图的数据映射到该共享空间中。这样可以使不同视图之间的相关性更加明显，便于后续的学习和推理。
    
3. 基于多示例学习的方法：将多个视图看作是一个示例的不同表示，通过多示例学习的方式来进行模型训练和预测。这种方法适用于存在不完全标注的数据集，其中每个示例可能有多个视图的表示。
    

多视图学习方法可以提供更全面和准确的数据建模，从而改善学习性能。它可以利用不同视图的互补信息，提取更丰富的特征表示，并减少数据表示的不确定性。这使得多视图学习成为处理复杂数据和提高模型性能的有效工具。

### 随机投影（SimHash）

TODO：[https://zhuanlan.zhihu.com/p/92155250](https://zhuanlan.zhihu.com/p/92155250)

1. **SimHash 算法**：SimHash 是一种用于计算文本或数据的哈希值的算法。它的主要思想是将文本或数据转换为二进制向量，其中相似的文本或数据会产生相似的哈希值。这种相似性哈希算法被广泛应用于文本去重、相似文档聚类和相似性搜索等任务。
    
2. **随机投影**：随机投影是一种降维技术，用于将高维数据映射到低维空间。在随机投影 SimHash 中，通过使用随机生成的投影矩阵将高维特征向量映射到低维二进制码。
    
3. **哈希函数**：随机投影 SimHash 使用哈希函数来将投影后的低维向量转换为二进制码。常用的哈希函数是符号哈希函数，它根据投影后的特征向量的符号（正负）来决定对应二进制码的取值（0 或 1）。
    
4. **相似性匹配**：通过计算 SimHash 值之间的汉明距离（Hamming Distance），可以判断文本或数据之间的相似性。汉明距离是指两个等长字符串之间相对位置不同的字符的个数。汉明距离越小，表示文本或数据之间越相似。
    

### 线性特征 & 非线性特征

1. 线性特征：特征和目标的关系可以用一条直线来拟合。
    
2. 非线性特征：特征和目标之间的关系不可以用一条直线来拟合
    

### 弱分类器 & 强分类器

1. 弱分类器：准确率在 60% ~80%之间，即：比随即预测好，但是准确率不高。e.g. CART（分类与回归树）
    
2. 强分类器：准确率在90%以上。
    

### 分类任务 & 回归任务

1. 分类任务（Classification）
    
    1. 目标：将输入实例分配到预定义的类别中。
        
    2. 过程：模型通过学习输入特征与响应类别之间的关系，来预测新的未知示例所属类别。
        
    3. 输出：输出是离散的，通常是表示类别的标签或类别的概率分布。
        
2. 回归任务（Regression）
    
    1. 目标：预测连续的数值输出。
        
    2. 过程：模型通过学习输入特征与响应输出值之间的关系，来预测新的未知示例的数值结果。
        
    3. 输出：这是一个连续的数值输出。
        

注意：有些机器学习算法可以同时用于分类和回归任务，例如决策树和支持向量机等。这些算法可以根据任务的要求进行适当的调整和配置。

### LR、DT、SVM的对比

1. 所谓分类问题就是在特征空间内寻找决策边界线。而三种算法决定了生成的边界线的不同形状。
    
2. 如何在多维特征空间中选择合适的算法：
    
    1. 先选逻辑回归，如果效果不怎么样，可以将它的结果作为基准来参考
        
    2. 试试决策树（随机森林）是否可以大幅度提升模型性能。即使没有把它当作最终模型，也可以使用随机森林来移除噪声变量。
        
    3. 如果特征的数量和观测样本特别多，那么当资源和时间充足时，使用SVM不失为一种选择。
        

### 逻辑回归（Logistic Regression）

1. 目的：解决分类问题。
    
2. 核心：特征权重的线性组合、sigmoid 函数的计算和损失函数的最小化。
    
3. 特点：逻辑回归的决策边界总是一条直线（或者一个平面，在更高维度上是超平面）。
    
4. 优势：
    
    1. 适用于处理接近线性可分的分类问题。
        
    2. 结果不是一个离散值或者确切的类别。而是一个与每个观测样本相关的概率列表，所以可以用不同的标准和常用的性能指标来分析这个概率分数，得到不同的分类结果。
        
    3. 时间和内存需求上相当高效。可以用于分布式数据，用较少的资源处理大型数据
        
        > 低内存消耗：逻辑回归模型只需要存储特征权重，而不需要存储大量的训练数据。相比之下，其他复杂的模型（如神经网络）可能需要存储大量的中间参数和计算图，导致更高的内存消耗。
        
    4. 对数据中小噪声的棒鲁性很好。
        
    5. 逻辑回归广泛应用于工业问题上。
        
5. 地位：解决工业规模问题最流行的算法
    
6. 缺点：
    
    1. 在效率和算法实现的易用性方面并不出众。
        
    2. 当特征数目很大并且还丢失了大部分数据时，逻辑回归就会表现的力不从心。
        
    3. 当类别变量过多时也会力不从心
        
    4. 对于非线性特征，需要进行转换。
        
    5. 依赖于全部数据。
        

### 决策树（Decisoin Trees）

1. 目的：解决分类问题 & 逻辑回归问题。
    
2. 结构：按照层次结构的规则生成的。
    
3. 特性：对单向变换或者非线性特征并不关心。(不需要变换来捕获数据中的非线性相关性，可以用他的划分方式自适应处理非线性关系)。
    
    > 单向变换：如指数、对数变换。
    
4. 优势：如果边界是非线性的，并且能通过不断将特征空间分为矩形来模拟，那么决策树是比逻辑回归更好的选择。
    
    1. 直观的决策规则；
        
    2. 可以处理非线性特征；
        
    3. 考虑了变量之间的相互作用；
        
5. 缺点：
    
    1. 训练集上的效果高于测试集，即过拟合【随机森林克服了此缺点】；
        
    2. 没有将排名分数作为直接结果；
        
6. 针对离散数据的分类决策树
    
    1. 定义：预测任务的输入和输出都是离散值
        
    2. 例子：ID3、C4.5
        
    3. 原始决策树：不断选择，优先选择信息熵最小的特征进行分组
        
        > 信息熵：越大，表示特征的信息量越大，越离散，按照这个特征分组之后，样本的混乱程度越大。e.g. 特征某个水平的值出现的概率与取对数的积和。
        
    4. ID3：使用信息增益来度量特征对分类的帮助大小
        
        > 信息增益：使用一个特征对数据进行分组之后各组样本的有序程度会更高，熵会降低，分组前后熵的差值就是这个特征带来的信息增益。信息增益越大，说明这个特征越有助于分组。分组之前算一次，分组之后算一次。
        
    5. C4.5 算法：在信息增益的基础上构造了一个新的特征质量度量指标：信息中增益比
        
        > 信息增益比：按照性别划分之后对成年的的信息增益/分组之前对性别的信息增益
        
    

### 支持向量机（Support Vector Machine,SVM）

1. 目的：解决分类问题 & 逻辑回归问题
    
2. 特点：依靠边界样本来建立需要的分离曲线。它可以处理非线性决策边界。（对边界依赖）
    
3. 结构：把特征空间映射到核空间，使得各个类别线性可分。把特征空间又增加一个维度。
    
    > 1. **核函数**：SVM使用核函数来将输入特征映射到高维特征空间，从而使得原本在低维空间中非线性可分的问题在高维空间中变得线性可分。核函数的作用是通过计算样本在高维空间中的内积来隐式地表示非线性特征之间的相互作用。常用的核函数包括多项式核函数、高斯核函数（径向基函数）等。
    >     
    > 2. **大间隔原则**：SVM的优化目标是找到一个最大间隔的超平面来划分不同类别的样本。通过最大化间隔，SVM能够在特征空间中找到一条边界，使得不同类别的样本尽可能分开。这种大间隔原则使得SVM对于非线性特征之间的相互作用更加鲁棒，能够更好地处理非线性关系。
    >     
    > 3. **非线性核函数**：除了线性核函数，SVM还可以使用非线性核函数，如多项式核函数和高斯核函数。这些核函数能够捕捉非线性特征之间的相互作用，将数据映射到高维特征空间中，并在高维空间中构建一个线性超平面来进行分类。这样，SVM能够处理非线性特征之间的相互作用，提高模型的表达能力。
    >     
    
4. 优点
    
    1. 能够处理大型特征空间
        
    2. 能够处理非线性特征之间的相互作用
        
    3. 无需依赖整个数据
        
5. 缺点：
    
    1. 当观测样本很多时，效率并不是很高
        
    2. 有时候很难找到一个合适的核函数
        

### 分类与回归树（Classification and Regression Tree,CART）

1. 概念：一种经典决策树，可以用来处理涉及连续数据的分类或者回归任务。
    
2. 思想：一些学者采用类似随机投影的思路，将自变量的取值空间切分为若干个碎块，并假设这个空间碎块内的所有样本的因变量取值接近(甚至相同)——在这种思想的指导下，出现了一种非常经典的回归模型，即CART回归树。
    
3. 由来：
    
    1. 特征为连续变量：不能直接使用特征取值，选择用于分割样本的特征取值
        
    2. 输出为连续变量：基尼系数和信息增益并不能作为分组质量的表征。使用！回归树！
        
4. 关键：设计一个标准，用来指导机器按照最有利于准确计算因变量的情况来切分特征空间。
    
    1. e.g.:切分特征空间的标准：MES
        
5. 代码：[https://github.com/lipengyuer/DataScience/blob/master/src/algoritm/CARTRegression.py](https://github.com/lipengyuer/DataScience/blob/master/src/algoritm/CARTRegression.py)
    

### 集成学习

概念：通过组合多个基本模型的预测结果，以获得更好的整体预测性能。

目的：组合多个弱分类器或者回归器来创建一个强分类器或者回归器。

1. bagging
    
    通过对原数据集的抽样，得到多份采样数据集，使用弱学习器分别在这多份采样数据集上学习， 而后使用集成策略将结果整合起来（e.g. 分类问题用投票法，回归问题用加权法） e.g. 随机森林（Random Forest）
    
2. stacking
    
    使用不同的学习方法学习同一份数据，得到多个学习器， 而后使用另一个学习器，学习以上多个学习器的输出到真实标签的映射 boosting 按序处理多个弱学习器，排在后的学习器重点学习排在前的学习器无法处理好的那些数据 e.g. Ada
    
3. Boost
    
    一个学习器学完后，根据其对数据集分类的正确与否，调整下一个学习器学习时，数据集各条数据被采样到的概率，达成调整数据集分布的作用。而后多个学习器按照各自的正确率集成在一
    

### 随机森林

1. 是决策树一个非常优秀的扩展，同时也剥夺了商业规则和易解释性。
    
    1. 树很多，使用多数投票规则使得模型变得更加复杂，
        
    2. 决策树变量之间也存在相互作用。
        


### 变分贝叶斯方法

参考：[Variational Bayesian methods](https://en.wikipedia.org/wiki/Variational_Bayesian_methods)
变分贝叶斯方法是一系列用于逼近贝叶斯推理和机器学习中出现的棘手积分的技术。它们通常用于由观察变量（通常称为“数据”）以及未知参数和潜在变量组成的复杂统计模型，这三种类型的随机变量之间具有各种关系，正如图形模型所描述的那样。正如贝叶斯推理中的典型情况一样，参数和潜在变量被分组为“未观察到的变量”。变分贝叶斯方法主要用于两个目的：
1. 为未观测变量的后验概率提供分析近似，以便对这些变量进行统计推断。
2. 导出观察数据的边际可能性（有时称为证据）的下限（即给定模型的数据的边际概率，对未观察的变量进行边缘化）。这通常用于执行模型选择，一般思想是给定模型的边际，可能性较高表明该模型对数据的拟合更好，因此所讨论的模型是生成数据的模型的概率更大。 （另请参阅贝叶斯因子文章。）
。。。。。

### 拉普拉斯平滑
（Laplace smoothing），也称为加一平滑（Add-One smoothing），是一种用于处理概率估计中的零概率问题的技术。它是一种简单而常用的平滑方法，可用于解决在计算概率时可能出现的数据稀疏性和零概率的情况。

在概率估计中，当我们根据样本数据计算事件的概率时，有时会遇到某些事件在样本中未出现的情况，导致概率估计为零。这在实际应用中可能不太合理，因为我们不能简单地认为未观察到的事件的概率为零。

拉普拉斯平滑通过在计算概率时为每个事件的计数值（或频率）增加一个常数（通常为1），来解决零概率问题。这个常数被称为平滑因子或平滑参数。通过这种方法，即使某个事件在样本中未出现，它的概率仍然会被估计为一个非零值。

拉普拉斯平滑的概率估计公式如下：  
P(x) = (count(x) + 1) / (N + V)

其中，P(x)表示事件x的平滑概率，count(x)表示在样本中观察到事件x的次数，N表示总观测次数，V表示事件的可能取值数量（即事件的种类数）。

应用方面，拉普拉斯平滑广泛用于自然语言处理（NLP）中的语言模型，特别是n-gram语言模型。在n-gram模型中，用于估计概率的数据通常是文本中的n个连续词语序列。拉普拉斯平滑可以解决在计算概率时可能出现的未观察到的n-gram序列的问题，提高语言模型的鲁棒性和泛化能力。

除了语言模型，拉普拉斯平滑还可以应用于其他概率估计问题，如朴素贝叶斯分类器、信息检索中的查询扩展和推荐系统等。它可以有效地处理数据稀疏性问题，并提供更合理的概率估计结果。

### 强化学习
当谈到强化学习（Reinforcement Learning，RL）时，我们在机器学习中讨论的是一种范例和方法。它主要用于描述和解决智能代理与环境交互的学习问题，目标是通过学习一种策略或行为序列来最大化累积的回报或实现特定目标。

在强化学习中，我们有一个智能代理（agent），它根据环境的状态（state）选择动作（action），并与环境进行交互。环境会根据代理采取的动作以及当前的状态，返回给代理一个奖励信号（reward）和下一个状态。代理的目标是通过与环境的交互，通过尝试和错误的方式来学习一个最佳策略，以使得长期累积的回报最大化。

在强化学习中，代理通过学习价值函数（value function）或策略函数（policy function）来指导其决策过程。价值函数可以评估给定状态或状态动作对的价值，而策略函数定义了在给定状态下选择动作的方式。代理通过与环境的交互不断更新这些函数，以改进其决策能力。

强化学习的一个重要概念是探索（exploration）与利用（exploitation）的权衡。探索是指代理通过尝试新的动作来发现更多的知识，而利用是指代理根据已知信息选择最优动作以获得最大回报。强化学习算法需要在探索和利用之间找到平衡，以达到最佳的学习效果。

总结起来，强化学习是一种机器学习方法，用于解决智能代理与环境交互的学习问题。代理通过学习策略或行为序列来最大化累积回报或实现特定目标。在这个过程中，代理通过与环境的交互不断更新价值函数和策略函数，以改进其决策能力。探索与利用的权衡是强化学习中需要解决的重要问题之一。



### 参考资料：

1. [https://www.jianshu.com/p/743cf2357b28](https://www.jianshu.com/p/743cf2357b28)
    
2. [https://zhuanlan.zhihu.com/p/53183016](https://zhuanlan.zhihu.com/p/53183016)
    
3. CART回归：[https://zhuanlan.zhihu.com/p/128472955](https://zhuanlan.zhihu.com/p/128472955)