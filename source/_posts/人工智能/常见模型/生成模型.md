# 参考
https://zhuanlan.zhihu.com/p/532402983


# 概念
指一类机器学习模型，其目标是学习数据的概率分布，并通过该概率分布生成新的样本数据。生成模型可以根据已知数据的统计特征，学习数据的分布模式，然后使用这个模式生成新的数据样本。生成模型被广泛应用于数据生成、图像合成、文本生成等领域。

# 分类
## 按照概率密度函数的处理方式分类
![[Pasted image 20240412152711.png]]
## 按照是否有监督
1. 有监督的生成模型。
2. 无监督的生成模型。
	1. [[扩散模型]]

# 基本任务
1. 生成样本，例如生成逼真的人脸图片、生成高质量的语音等；
2. 也可以通过改进生成模型从而实现样本之间的映射转换，例如图像风格迁移、语音增强等。

## 原理：生成样本
### 整体流程
生成模型接受随机噪声 z 作为输入，然后产生输出样本 x
### 训练和推理过程
**分析**
1. 由 N 个样本构成的集合，假设它们是彼此独立都采样来源于某个未知的概率分布 q(X)；
2. 问题：如何在不知道 q(X) 的情况下产生一个模型使得，生成的样本在分布中。
3. 解决：构建生成模型 p(X,θ)，通过 N 个样本来学习到最好的参数 θ，使得 p(X,θ)=q(X)
**两个问题**
1. 如何设计模型
	不同的模型有各自的考虑，比如 玻尔兹曼机 使用基于能量的模型，完全可见置信网络对模型进行的链式解析等等。
2. 如何训练
	显式生成模型使用的训练准则为极大似然估计。这里有分两种情况：
	1. 对似然函数本身直接进行优化的精确推断方法。（例如流模型，自回归模型）
	2. 对似然函数近似值进行优化的近似推断方法。（例如VAE和玻尔兹曼机）
	隐式生成模型首先使用两类样本学习到了 p(X,θ) 和 q(X)  的距离，然后再以减少距离为目标训练生成模型。

### 潜变量生成模型 
潜变量生成模型（Latent Variable Generative Model）是一种统计模型，用于描述数据的生成过程。它假设存在一组潜在的变量（也称为隐藏变量或潜变量），这些变量无法直接观测到，但对生成数据起到重要作用。

潜变量生成模型的基本思想是，通过学习数据中隐藏的潜在结构和变量，可以生成与观测数据相似的新样本。这种生成过程通常基于概率分布模型，如高斯混合模型（Gaussian Mixture Model，GMM）、隐马尔可夫模型（Hidden Markov Model，HMM）、变分自编码器（Variational Autoencoder，VAE）等。

在潜变量生成模型中，潜变量表示了数据中的潜在特征或隐含结构，它们对生成数据的分布产生影响。通过对潜变量和观测变量之间的关系进行建模，生成模型可以通过给定潜变量的取值来生成对应的观测数据。

潜变量生成模型的应用广泛，包括图像生成、文本生成、语音生成等。通过学习和探索数据中的潜在结构，潜变量生成模型可以生成具有多样性和创造性的新样本，进而用于数据增强、生成对抗网络（GAN）的训练、数据压缩和降维等任务。

总而言之，潜变量生成模型是一种通过建模潜在变量与观测数据之间的关系来生成数据的统计模型。它利用隐藏的潜在结构和变量来模拟数据的生成过程，并可用于生成新样本和数据分析中的其他任务。